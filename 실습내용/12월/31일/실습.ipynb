{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/student/Desktop/깃/TIL/datas/실습/input/딥러닝 실습')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root_path = Path.cwd().parent.parent.parent\n",
    "goal_path = root_path / 'datas/실습/input/딥러닝 실습/'\n",
    "goal_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0 오차= 108.66269 정확률(평균)= 0.3242\n",
      "Epoch= 500 오차= 57.58866 정확률(평균)= 0.8904\n",
      "Epoch= 1000 오차= 45.02092 정확률(평균)= 0.898\n",
      "Epoch= 1500 오차= 41.65434 정확률(평균)= 0.9566\n",
      "Epoch= 2000 오차= 34.664024 정확률(평균)= 0.943\n",
      "Epoch= 2500 오차= 34.287025 정확률(평균)= 0.9674\n",
      "Epoch= 3000 오차= 26.880764 정확률(평균)= 0.9726\n",
      "Epoch= 3500 오차= 29.59067 정확률(평균)= 0.9728\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(goal_path/'bmi.csv')\n",
    "\n",
    "# 키와 몸무게 정규화\n",
    "df['height'] /= 200\n",
    "df['weight'] /= 100\n",
    "\n",
    "\n",
    "# label 컬럼 변환 - thin[1, 0, 0]/normal[0, 1, 0]/fat [0, 0, 1]\n",
    "bclass = {\"thin\": [1, 0, 0] , \"normal\":[0, 1, 0], \"fat\": [0, 0, 1]}\n",
    "df[\"label_pat\"] = df[\"label\"].apply(lambda x: np.array(bclass[x]))\n",
    "\n",
    "# 학습데이터와 테스트 데이터 분류\n",
    "test_df = df[15000:20000]\n",
    "test_pat= test_df[[\"weight\", \"height\"]]\n",
    "test_ans = list(test_df[\"label_pat\"])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2]) #키, 몸부게 데이터 담을 placeholder  선언\n",
    "Y = tf.placeholder(tf.float32, [None, 3])   #정답 레이블 데이터 담을 placeholder  선언\n",
    "\n",
    "W = tf.Variable(tf.zeros([2, 3])) \n",
    "b = tf.Variable(tf.zeros([3])) \n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(X, W) + b)  #소프트맥스 회귀 정의\n",
    "cross_entropy = -tf.reduce_sum(Y * tf.log(y))  #오차함수 - 교차 엔트로피\n",
    "train= tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)  #경사하강법으로 학습\n",
    " \n",
    "# 예측값, 정답률 계산\n",
    "predict = tf.equal(tf.argmax(y, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) \n",
    "for step in range(3501):\n",
    "    i = (step*100) % 14000\n",
    "    rows = df[i+1:i+1+100]\n",
    "    x_pat = rows[[\"weight\", \"height\"]]\n",
    "    y_ans =  list(rows[\"label_pat\"])\n",
    "    sess.run(train, feed_dict={X: x_pat  , Y: y_ans })\n",
    "    if step%500  == 0 :\n",
    "        cre = sess.run(cross_entropy, feed_dict={X: x_pat  , Y: y_ans })\n",
    "        acc = sess.run(accuracy , feed_dict={X: test_pat  , Y: test_ans })\n",
    "        print(\"Epoch=\", step, \"오차=\", cre, \"정확률(평균)=\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from keras) (1.13.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from keras) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from keras) (1.4.1)\n",
      "Collecting pyyaml\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/90/18ad46adf73fd4d7c4fe18e90189a69d00006d7e61849d88d1bce89b1744/PyYAML-5.2-cp37-cp37m-win_amd64.whl (215kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.3.1 pyyaml-5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\.conda\\envs\\test\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "13500/13500 [==============================] - 1s 95us/step - loss: 0.5198 - accuracy: 0.7910 - val_loss: 0.2893 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "13500/13500 [==============================] - 1s 72us/step - loss: 0.2497 - accuracy: 0.9030 - val_loss: 0.1769 - val_accuracy: 0.9373\n",
      "Epoch 3/20\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1945 - accuracy: 0.9205 - val_loss: 0.1277 - val_accuracy: 0.9580\n",
      "Epoch 4/20\n",
      "13500/13500 [==============================] - 1s 77us/step - loss: 0.1659 - accuracy: 0.9276 - val_loss: 0.1389 - val_accuracy: 0.9380\n",
      "Epoch 5/20\n",
      "13500/13500 [==============================] - 1s 70us/step - loss: 0.1544 - accuracy: 0.9341 - val_loss: 0.1633 - val_accuracy: 0.9167\n",
      "4999/4999 [==============================] - 0s 43us/step\n",
      "loss= 0.16440339221921438\n",
      "accuracy= 0.911382257938385\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "df = pd.read_csv(goal_path/'bmi.csv')\n",
    "\n",
    "#키와 몸무게 정규화\n",
    "df[\"height\"] /= 200\n",
    "df[\"weight\"] /= 100\n",
    "\n",
    "X = df[[\"weight\", \"height\"]].as_matrix()\n",
    "\n",
    "#label 컬럼 변환 - thin[1, 0, 0]/normal[0, 1, 0]/fat [0, 0, 1]\n",
    "bclass = {\"thin\": [1, 0, 0] , \"normal\":[0, 1, 0], \"fat\": [0, 0, 1]}\n",
    "Y = np.empty((20000, 3))\n",
    "for i, v in enumerate(df[\"label\"]):\n",
    "    Y[i] = bclass[v]\n",
    " \n",
    "#학습데인터 , 테스트 데이터 분리\n",
    "X_train, Y_train = X[1:15001], Y[1:15001]\n",
    "X_test, Y_test = X[15001:20001], Y[15001:20001]\n",
    "\n",
    "model = Sequential()  #모델 객체 생성\n",
    "model.add(Dense(512, input_shape=(2, )))    #Dense(노드 수 , ....) 층을 의미하는 객체\n",
    "model.add(Activation('relu'))   # 활성화 함수\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=100, epochs=20, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=2)], verbose=1)\n",
    "                    \n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"loss=\", score[0])\n",
    "print(\"accuracy=\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 0s 507us/step - loss: 0.8003 - accuracy: 0.1894\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.6898 - accuracy: 0.2936\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 76us/step - loss: 0.1780 - accuracy: 0.8128\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 80us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 98us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 74us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 80us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 72us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 78us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 78us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "470/470 [==============================] - 0s 201us/step\n",
      "\n",
      " Accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# 준비된 수술 환자 데이터를 불러들입니다.\n",
    "Data_set = numpy.loadtxt(goal_path/'ThoraricSurgery.csv', delimiter=',')\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장합니다.\n",
    "X = Data_set[:,0:17]\n",
    "Y = Data_set[:,17]\n",
    "\n",
    "# 딥러닝 구조를 결정합니다(모델을 설정하고 실행).\n",
    "model = Sequential()   \n",
    "# 첫 번째 은닉층에 input_dim을 적어 줌으로써 첫 번째 Dense가 은닉층 + 입력층의 역할을 겸합니다.\n",
    "# 데이터에서 17개의 값을 받아 은닉층의 30개 노드로 보낸다 \n",
    "model.add(Dense(30, input_dim=17, activation='relu'))  #activation : 출력층으로 전달할 때 사용할 활성화 함수\n",
    "model.add(Dense(1, activation='sigmoid'))  #출력층의 노드 수는 1개, 최종 출력 값에 사용될 활성화 함수\n",
    "\n",
    "# 딥러닝을 실행합니다. (오차 함수 :  평균 제곱 오차 함수 사용)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=30, batch_size=10)\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print('\\n Accuracy: %.4f'% (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\.conda\\envs\\test\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/200\n",
      "768/768 [==============================] - 0s 483us/step - loss: 2.4394 - accuracy: 0.5130\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.9124 - accuracy: 0.6367\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.7963 - accuracy: 0.6393\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.7416 - accuracy: 0.6107\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6802 - accuracy: 0.6406\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6489 - accuracy: 0.6289\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6379 - accuracy: 0.6471\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6384 - accuracy: 0.6250\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6306 - accuracy: 0.6341\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.6214 - accuracy: 0.6497\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6267 - accuracy: 0.6497\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6180 - accuracy: 0.6380\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.6080 - accuracy: 0.6549\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6135 - accuracy: 0.6458\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6076 - accuracy: 0.6745\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6044 - accuracy: 0.6562\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6004 - accuracy: 0.6628\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5837 - accuracy: 0.6927\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5983 - accuracy: 0.6849\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5931 - accuracy: 0.6992\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5869 - accuracy: 0.6875\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5983 - accuracy: 0.6888\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5797 - accuracy: 0.6953\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.6041 - accuracy: 0.6758\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5782 - accuracy: 0.6940\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5783 - accuracy: 0.7005\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5704 - accuracy: 0.6966\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5759 - accuracy: 0.6914\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5563 - accuracy: 0.7174\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5654 - accuracy: 0.7044\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5694 - accuracy: 0.7109\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5713 - accuracy: 0.7174\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5783 - accuracy: 0.7083\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5639 - accuracy: 0.7070\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5569 - accuracy: 0.7096\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5589 - accuracy: 0.7161\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5596 - accuracy: 0.7253\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5599 - accuracy: 0.7240\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5447 - accuracy: 0.7240\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5733 - accuracy: 0.7148\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5496 - accuracy: 0.7083\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5425 - accuracy: 0.7266\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5364 - accuracy: 0.7292\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5480 - accuracy: 0.7253\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5456 - accuracy: 0.7331\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5362 - accuracy: 0.7331\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5702 - accuracy: 0.7109\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5476 - accuracy: 0.7083\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5388 - accuracy: 0.7318\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5324 - accuracy: 0.7331\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5353 - accuracy: 0.7292\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5289 - accuracy: 0.7292\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5311 - accuracy: 0.7227\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5295 - accuracy: 0.7318\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5310 - accuracy: 0.7305\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5304 - accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5292 - accuracy: 0.7227\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5218 - accuracy: 0.7370\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5407 - accuracy: 0.7188\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5512 - accuracy: 0.7214\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5357 - accuracy: 0.7305\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5302 - accuracy: 0.7357\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5256 - accuracy: 0.7357\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5217 - accuracy: 0.7409\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5233 - accuracy: 0.7344\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5264 - accuracy: 0.7305\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5180 - accuracy: 0.7396\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5234 - accuracy: 0.7435\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5236 - accuracy: 0.7435\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5197 - accuracy: 0.7396\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5347 - accuracy: 0.7344\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5168 - accuracy: 0.7422\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5253 - accuracy: 0.7279\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5269 - accuracy: 0.7422\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5147 - accuracy: 0.7448\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5198 - accuracy: 0.7474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5174 - accuracy: 0.7422\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5119 - accuracy: 0.7383\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5138 - accuracy: 0.7591\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5088 - accuracy: 0.7513\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5185 - accuracy: 0.7474\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5032 - accuracy: 0.7552\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5218 - accuracy: 0.7357\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5052 - accuracy: 0.7422\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5030 - accuracy: 0.7474\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5113 - accuracy: 0.7513\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5118 - accuracy: 0.7539\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5107 - accuracy: 0.7305\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5051 - accuracy: 0.7617\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5034 - accuracy: 0.7474\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5009 - accuracy: 0.7630\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5086 - accuracy: 0.7409\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.4998 - accuracy: 0.7552\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4984 - accuracy: 0.7578\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5021 - accuracy: 0.7513\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4999 - accuracy: 0.7526\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4990 - accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5039 - accuracy: 0.7474\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4953 - accuracy: 0.7617\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4998 - accuracy: 0.7539\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4966 - accuracy: 0.7513\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5054 - accuracy: 0.7396\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5038 - accuracy: 0.7643\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.4906 - accuracy: 0.7539\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4960 - accuracy: 0.7695\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5064 - accuracy: 0.7448\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.4954 - accuracy: 0.7539\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4950 - accuracy: 0.7578\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4883 - accuracy: 0.7643\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4935 - accuracy: 0.7630\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4949 - accuracy: 0.7695\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4859 - accuracy: 0.7630\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5053 - accuracy: 0.7539\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.76 - 0s 99us/step - loss: 0.4901 - accuracy: 0.7604\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.4863 - accuracy: 0.7604\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5090 - accuracy: 0.7461\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4883 - accuracy: 0.7643\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4924 - accuracy: 0.7565\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4835 - accuracy: 0.7591\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4900 - accuracy: 0.7617\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4895 - accuracy: 0.7552\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4852 - accuracy: 0.7669\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4844 - accuracy: 0.7656\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4943 - accuracy: 0.7513\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4868 - accuracy: 0.7487\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4851 - accuracy: 0.7617\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4932 - accuracy: 0.7630\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.4914 - accuracy: 0.7604\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4862 - accuracy: 0.7630\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4870 - accuracy: 0.7539\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4846 - accuracy: 0.7617\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4805 - accuracy: 0.7643\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4827 - accuracy: 0.7591\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4764 - accuracy: 0.7604\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4883 - accuracy: 0.7695\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4779 - accuracy: 0.7656\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4831 - accuracy: 0.7591\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4878 - accuracy: 0.7643\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4894 - accuracy: 0.7682\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4877 - accuracy: 0.7552\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4717 - accuracy: 0.7617\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4854 - accuracy: 0.7630\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4808 - accuracy: 0.7630\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4780 - accuracy: 0.7786\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4777 - accuracy: 0.7578\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4792 - accuracy: 0.7617\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4755 - accuracy: 0.7682\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4984 - accuracy: 0.7565\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4756 - accuracy: 0.7747\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4736 - accuracy: 0.7682\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4799 - accuracy: 0.7799\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4761 - accuracy: 0.7630\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4762 - accuracy: 0.7669\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4727 - accuracy: 0.7643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4739 - accuracy: 0.7695\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4744 - accuracy: 0.7630\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4821 - accuracy: 0.7773\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4717 - accuracy: 0.7708\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4729 - accuracy: 0.7630\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4783 - accuracy: 0.7630\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4740 - accuracy: 0.7695\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4694 - accuracy: 0.7760\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4663 - accuracy: 0.7682\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4723 - accuracy: 0.7721\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4761 - accuracy: 0.7617\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4708 - accuracy: 0.7669\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4737 - accuracy: 0.7513\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4660 - accuracy: 0.7708\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4731 - accuracy: 0.7643\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4674 - accuracy: 0.7682\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4701 - accuracy: 0.7695\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4688 - accuracy: 0.7682\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4753 - accuracy: 0.7708\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4667 - accuracy: 0.7721\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4690 - accuracy: 0.7643\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4666 - accuracy: 0.7708\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4627 - accuracy: 0.7682\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4724 - accuracy: 0.7747\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4649 - accuracy: 0.7826\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4593 - accuracy: 0.7734\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4676 - accuracy: 0.7812\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4696 - accuracy: 0.7695\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4675 - accuracy: 0.7682\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4603 - accuracy: 0.7852\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4598 - accuracy: 0.7839\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4746 - accuracy: 0.7643\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4700 - accuracy: 0.7721\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4697 - accuracy: 0.7682\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4671 - accuracy: 0.7747\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4616 - accuracy: 0.7760\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4554 - accuracy: 0.7708\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4571 - accuracy: 0.7786\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4578 - accuracy: 0.7760\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4628 - accuracy: 0.7786\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4686 - accuracy: 0.7669\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.4653 - accuracy: 0.7799\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4654 - accuracy: 0.7812\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4640 - accuracy: 0.7839\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4702 - accuracy: 0.7747\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4642 - accuracy: 0.7695\n",
      "768/768 [==============================] - 0s 165us/step\n",
      "\n",
      " Accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)                   # seed 값 생성\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "dataset = numpy.loadtxt(goal_path/'pima-indians-diabets.csv', delimiter=',')               # 데이터 로드\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "model = Sequential()                                                # 모델의 설정\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',   optimizer='adam',      metrics=['accuracy'])   # 모델 컴파일\n",
    "model.fit(X, Y, epochs=200, batch_size=10)                                # 모델 실행\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))                # 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 823.5x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6259 - accuracy: 0.3267\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 778us/step - loss: 1.1404 - accuracy: 0.4867\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 831us/step - loss: 0.9411 - accuracy: 0.4600\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 745us/step - loss: 0.7898 - accuracy: 0.7467\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 804us/step - loss: 0.6669 - accuracy: 0.7267\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.5636 - accuracy: 0.8800\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 725us/step - loss: 0.5080 - accuracy: 0.8267\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.4558 - accuracy: 0.9333\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.4287 - accuracy: 0.8867\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.4070 - accuracy: 0.8867\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 711us/step - loss: 0.3852 - accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.3677 - accuracy: 0.9467\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 831us/step - loss: 0.3505 - accuracy: 0.9467\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.3368 - accuracy: 0.9067\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.3265 - accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 791us/step - loss: 0.3136 - accuracy: 0.9533\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 831us/step - loss: 0.3060 - accuracy: 0.9533\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 732us/step - loss: 0.2965 - accuracy: 0.9667\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.2854 - accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 791us/step - loss: 0.2761 - accuracy: 0.9600\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.2678 - accuracy: 0.9733\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 731us/step - loss: 0.2609 - accuracy: 0.9667\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.2529 - accuracy: 0.9467\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 744us/step - loss: 0.2437 - accuracy: 0.9600\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 758us/step - loss: 0.2361 - accuracy: 0.9733\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 911us/step - loss: 0.2340 - accuracy: 0.9667\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 751us/step - loss: 0.2194 - accuracy: 0.9867\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 751us/step - loss: 0.2207 - accuracy: 0.9467\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 758us/step - loss: 0.2142 - accuracy: 0.9667\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 858us/step - loss: 0.2000 - accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 758us/step - loss: 0.2000 - accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 745us/step - loss: 0.1971 - accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 731us/step - loss: 0.1882 - accuracy: 0.9733\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 725us/step - loss: 0.1807 - accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.1852 - accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 725us/step - loss: 0.1743 - accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 705us/step - loss: 0.1685 - accuracy: 0.9733\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 731us/step - loss: 0.1646 - accuracy: 0.9733\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 711us/step - loss: 0.1622 - accuracy: 0.9733\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 738us/step - loss: 0.1561 - accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 725us/step - loss: 0.1564 - accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.1526 - accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 798us/step - loss: 0.1435 - accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.1443 - accuracy: 0.9533\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 725us/step - loss: 0.1419 - accuracy: 0.9800\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 725us/step - loss: 0.1450 - accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 784us/step - loss: 0.1350 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.1351 - accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.1332 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 731us/step - loss: 0.1284 - accuracy: 0.9667\n",
      "150/150 [==============================] - 0s 725us/step\n",
      "\n",
      " Accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(goal_path/'iris.csv', names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "print(df.head())\n",
    "\n",
    "sns.pairplot(df, hue='species')  #속성별 연관성 파악\n",
    "plt.show()\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y_obj = dataset[:,4]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder     \n",
    "e = LabelEncoder()     # array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])가 array([1,2,3])로 변환\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "# array([1,2,3])가 다시 array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])로 원-핫 인코딩(one-hot-encoding) 변환\n",
    "Y_encoded = np_utils.to_categorical(Y)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed) # seed 값 설정\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "model = Sequential() # 모델의 설정\n",
    "model.add(Dense(16, input_dim=4, activation='relu'))\n",
    "#최종 출력 값이 3개 중 하나여야 하므로 출력층에 해당하는 Dense의 노드 수를 3으로 설정\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일(다중 분류에 적절한 오차 함수인 categorical_crossentropy를 사용, 최적화 함수로 adam 사용)\n",
    "model.compile(loss='categorical_crossentropy',    optimizer='adam',    metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행(한 번에 입력되는 값은 1개, 전체 샘플이 50회 반복될 때까지 실험을 진행\n",
    "model.fit(X, Y_encoded, epochs=50, batch_size=1)   \n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y_encoded)[1]))   # 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/10/1dd2e3436e13402cc2b16c61b5f7407fb2e8057dcc18461db0d8e3523202/scikit_learn-0.22-cp37-cp37m-win_amd64.whl (6.2MB)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from scikit-learn->sklearn) (1.17.4)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\student\\.conda\\envs\\test\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1321 sha256=02ef9e9847d8d48627c6327356755ac844fd729e45ebdc1e99e4e1a7c864317d\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\76\\03\\bb\\589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.4519\n",
      "Epoch 2/200\n",
      "208/208 [==============================] - 0s 216us/step - loss: 0.2459 - accuracy: 0.5385\n",
      "Epoch 3/200\n",
      "208/208 [==============================] - 0s 173us/step - loss: 0.2427 - accuracy: 0.5433\n",
      "Epoch 4/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.2393 - accuracy: 0.5481\n",
      "Epoch 5/200\n",
      "208/208 [==============================] - 0s 216us/step - loss: 0.2329 - accuracy: 0.5529\n",
      "Epoch 6/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.2240 - accuracy: 0.5913\n",
      "Epoch 7/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.2156 - accuracy: 0.6587\n",
      "Epoch 8/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.2112 - accuracy: 0.6587\n",
      "Epoch 9/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1965 - accuracy: 0.7308\n",
      "Epoch 10/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1867 - accuracy: 0.7596\n",
      "Epoch 11/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1792 - accuracy: 0.7644\n",
      "Epoch 12/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1710 - accuracy: 0.7596\n",
      "Epoch 13/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1666 - accuracy: 0.8125\n",
      "Epoch 14/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.1623 - accuracy: 0.7548\n",
      "Epoch 15/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.1575 - accuracy: 0.7885\n",
      "Epoch 16/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1525 - accuracy: 0.7885\n",
      "Epoch 17/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.1475 - accuracy: 0.7933\n",
      "Epoch 18/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.1440 - accuracy: 0.8077\n",
      "Epoch 19/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1423 - accuracy: 0.8125\n",
      "Epoch 20/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1414 - accuracy: 0.8173\n",
      "Epoch 21/200\n",
      "208/208 [==============================] - 0s 307us/step - loss: 0.1343 - accuracy: 0.8077\n",
      "Epoch 22/200\n",
      "208/208 [==============================] - 0s 225us/step - loss: 0.1303 - accuracy: 0.8221\n",
      "Epoch 23/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.1307 - accuracy: 0.8173\n",
      "Epoch 24/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1302 - accuracy: 0.8269\n",
      "Epoch 25/200\n",
      "208/208 [==============================] - 0s 259us/step - loss: 0.1241 - accuracy: 0.8413\n",
      "Epoch 26/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1208 - accuracy: 0.8413\n",
      "Epoch 27/200\n",
      "208/208 [==============================] - 0s 283us/step - loss: 0.1205 - accuracy: 0.8365\n",
      "Epoch 28/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1206 - accuracy: 0.8317\n",
      "Epoch 29/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.1198 - accuracy: 0.8462\n",
      "Epoch 30/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.1173 - accuracy: 0.8413\n",
      "Epoch 31/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.1129 - accuracy: 0.8462\n",
      "Epoch 32/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1088 - accuracy: 0.8654\n",
      "Epoch 33/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.1099 - accuracy: 0.8510\n",
      "Epoch 34/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.1084 - accuracy: 0.8558\n",
      "Epoch 35/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.1084 - accuracy: 0.8462\n",
      "Epoch 36/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1066 - accuracy: 0.8462\n",
      "Epoch 37/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1030 - accuracy: 0.8702\n",
      "Epoch 38/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.1020 - accuracy: 0.8606\n",
      "Epoch 39/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.1000 - accuracy: 0.8654\n",
      "Epoch 40/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0967 - accuracy: 0.8750\n",
      "Epoch 41/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0964 - accuracy: 0.8750\n",
      "Epoch 42/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0949 - accuracy: 0.8750\n",
      "Epoch 43/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0941 - accuracy: 0.8750\n",
      "Epoch 44/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0907 - accuracy: 0.8894\n",
      "Epoch 45/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0888 - accuracy: 0.8990\n",
      "Epoch 46/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0866 - accuracy: 0.9087\n",
      "Epoch 47/200\n",
      "208/208 [==============================] - 0s 225us/step - loss: 0.0851 - accuracy: 0.8942\n",
      "Epoch 48/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0863 - accuracy: 0.9038\n",
      "Epoch 49/200\n",
      "208/208 [==============================] - 0s 264us/step - loss: 0.0831 - accuracy: 0.9135\n",
      "Epoch 50/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0870 - accuracy: 0.9038\n",
      "Epoch 51/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0818 - accuracy: 0.8846\n",
      "Epoch 52/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0809 - accuracy: 0.9038\n",
      "Epoch 53/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0779 - accuracy: 0.9135\n",
      "Epoch 54/200\n",
      "208/208 [==============================] - 0s 240us/step - loss: 0.0778 - accuracy: 0.9279\n",
      "Epoch 55/200\n",
      "208/208 [==============================] - 0s 240us/step - loss: 0.0751 - accuracy: 0.9087\n",
      "Epoch 56/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0741 - accuracy: 0.9231\n",
      "Epoch 57/200\n",
      "208/208 [==============================] - 0s 221us/step - loss: 0.0719 - accuracy: 0.9231\n",
      "Epoch 58/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0722 - accuracy: 0.9279\n",
      "Epoch 59/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0716 - accuracy: 0.9279\n",
      "Epoch 60/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0719 - accuracy: 0.9183\n",
      "Epoch 61/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0726 - accuracy: 0.9183\n",
      "Epoch 62/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0682 - accuracy: 0.9231\n",
      "Epoch 63/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0658 - accuracy: 0.9279\n",
      "Epoch 64/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0653 - accuracy: 0.9423\n",
      "Epoch 65/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0638 - accuracy: 0.9471\n",
      "Epoch 66/200\n",
      "208/208 [==============================] - 0s 240us/step - loss: 0.0644 - accuracy: 0.9423\n",
      "Epoch 67/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0657 - accuracy: 0.9087\n",
      "Epoch 68/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0607 - accuracy: 0.9471\n",
      "Epoch 69/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0599 - accuracy: 0.9423\n",
      "Epoch 70/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0588 - accuracy: 0.9375\n",
      "Epoch 71/200\n",
      "208/208 [==============================] - 0s 211us/step - loss: 0.0583 - accuracy: 0.9471\n",
      "Epoch 72/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0644 - accuracy: 0.9183\n",
      "Epoch 73/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0594 - accuracy: 0.9423\n",
      "Epoch 74/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0576 - accuracy: 0.9471\n",
      "Epoch 75/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0550 - accuracy: 0.9423\n",
      "Epoch 76/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0545 - accuracy: 0.9471\n",
      "Epoch 77/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0518 - accuracy: 0.9519\n",
      "Epoch 78/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0510 - accuracy: 0.9471\n",
      "Epoch 79/200\n",
      "208/208 [==============================] - 0s 225us/step - loss: 0.0509 - accuracy: 0.9519\n",
      "Epoch 80/200\n",
      "208/208 [==============================] - 0s 249us/step - loss: 0.0510 - accuracy: 0.9567\n",
      "Epoch 81/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0493 - accuracy: 0.9567\n",
      "Epoch 82/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0479 - accuracy: 0.9471\n",
      "Epoch 83/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0472 - accuracy: 0.9519\n",
      "Epoch 84/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0466 - accuracy: 0.9567\n",
      "Epoch 85/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0464 - accuracy: 0.9567\n",
      "Epoch 86/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0454 - accuracy: 0.9519\n",
      "Epoch 87/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0434 - accuracy: 0.9471\n",
      "Epoch 88/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0411 - accuracy: 0.9615\n",
      "Epoch 89/200\n",
      "208/208 [==============================] - 0s 288us/step - loss: 0.0423 - accuracy: 0.9615\n",
      "Epoch 90/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0419 - accuracy: 0.9663\n",
      "Epoch 91/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0402 - accuracy: 0.9615\n",
      "Epoch 92/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0443 - accuracy: 0.9567\n",
      "Epoch 93/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0388 - accuracy: 0.9712\n",
      "Epoch 94/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0406 - accuracy: 0.9615\n",
      "Epoch 95/200\n",
      "208/208 [==============================] - 0s 173us/step - loss: 0.0375 - accuracy: 0.9615\n",
      "Epoch 96/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0363 - accuracy: 0.9760\n",
      "Epoch 97/200\n",
      "208/208 [==============================] - 0s 235us/step - loss: 0.0361 - accuracy: 0.9712\n",
      "Epoch 98/200\n",
      "208/208 [==============================] - 0s 216us/step - loss: 0.0341 - accuracy: 0.9760\n",
      "Epoch 99/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0330 - accuracy: 0.9760\n",
      "Epoch 100/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0318 - accuracy: 0.9760\n",
      "Epoch 101/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0321 - accuracy: 0.9760\n",
      "Epoch 102/200\n",
      "208/208 [==============================] - 0s 230us/step - loss: 0.0298 - accuracy: 0.9760\n",
      "Epoch 103/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0285 - accuracy: 0.9808\n",
      "Epoch 104/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0296 - accuracy: 0.9760\n",
      "Epoch 105/200\n",
      "208/208 [==============================] - 0s 206us/step - loss: 0.0282 - accuracy: 0.9760\n",
      "Epoch 106/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0303 - accuracy: 0.9808\n",
      "Epoch 107/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0302 - accuracy: 0.9712\n",
      "Epoch 108/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0293 - accuracy: 0.9808\n",
      "Epoch 109/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0279 - accuracy: 0.9760\n",
      "Epoch 110/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0279 - accuracy: 0.9760\n",
      "Epoch 111/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0283 - accuracy: 0.9760\n",
      "Epoch 112/200\n",
      "208/208 [==============================] - 0s 264us/step - loss: 0.0258 - accuracy: 0.9760\n",
      "Epoch 113/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0242 - accuracy: 0.9808\n",
      "Epoch 114/200\n",
      "208/208 [==============================] - 0s 245us/step - loss: 0.0238 - accuracy: 0.9856\n",
      "Epoch 115/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0243 - accuracy: 0.9808\n",
      "Epoch 116/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0219 - accuracy: 0.9808\n",
      "Epoch 117/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0227 - accuracy: 0.9856\n",
      "Epoch 118/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0234 - accuracy: 0.9856\n",
      "Epoch 119/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0217 - accuracy: 0.9808\n",
      "Epoch 120/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0208 - accuracy: 0.9856\n",
      "Epoch 121/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0232 - accuracy: 0.9808\n",
      "Epoch 122/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0206 - accuracy: 0.9856\n",
      "Epoch 123/200\n",
      "208/208 [==============================] - 0s 173us/step - loss: 0.0199 - accuracy: 0.9904\n",
      "Epoch 124/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0194 - accuracy: 0.9856\n",
      "Epoch 125/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0205 - accuracy: 0.9904\n",
      "Epoch 126/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0222 - accuracy: 0.9760\n",
      "Epoch 127/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0224 - accuracy: 0.9856\n",
      "Epoch 128/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0186 - accuracy: 0.9856\n",
      "Epoch 129/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0161 - accuracy: 0.9904\n",
      "Epoch 130/200\n",
      "208/208 [==============================] - 0s 211us/step - loss: 0.0154 - accuracy: 0.9904\n",
      "Epoch 131/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 132/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 133/200\n",
      "208/208 [==============================] - 0s 307us/step - loss: 0.0144 - accuracy: 0.9904\n",
      "Epoch 134/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0137 - accuracy: 0.9952\n",
      "Epoch 135/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 136/200\n",
      "208/208 [==============================] - 0s 211us/step - loss: 0.0128 - accuracy: 0.9952\n",
      "Epoch 137/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0123 - accuracy: 0.9952\n",
      "Epoch 138/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0119 - accuracy: 0.9952\n",
      "Epoch 139/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0121 - accuracy: 0.9952\n",
      "Epoch 140/200\n",
      "208/208 [==============================] - 0s 206us/step - loss: 0.0119 - accuracy: 0.9952\n",
      "Epoch 141/200\n",
      "208/208 [==============================] - 0s 201us/step - loss: 0.0116 - accuracy: 0.9952\n",
      "Epoch 142/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0106 - accuracy: 0.9952\n",
      "Epoch 143/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0102 - accuracy: 0.9952\n",
      "Epoch 144/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0133 - accuracy: 0.9952\n",
      "Epoch 145/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0116 - accuracy: 0.9952\n",
      "Epoch 146/200\n",
      "208/208 [==============================] - 0s 225us/step - loss: 0.0109 - accuracy: 0.9952\n",
      "Epoch 147/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0097 - accuracy: 0.9952\n",
      "Epoch 148/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0098 - accuracy: 0.9952\n",
      "Epoch 149/200\n",
      "208/208 [==============================] - 0s 173us/step - loss: 0.0103 - accuracy: 0.9952\n",
      "Epoch 150/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0095 - accuracy: 0.9952\n",
      "Epoch 151/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0092 - accuracy: 0.9952\n",
      "Epoch 152/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0089 - accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "208/208 [==============================] - 0s 173us/step - loss: 0.0089 - accuracy: 0.9952\n",
      "Epoch 154/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0093 - accuracy: 0.9952\n",
      "Epoch 155/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0087 - accuracy: 0.9952\n",
      "Epoch 156/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0086 - accuracy: 0.9952\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 187us/step - loss: 0.0086 - accuracy: 0.9952\n",
      "Epoch 158/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0117 - accuracy: 0.9952\n",
      "Epoch 159/200\n",
      "208/208 [==============================] - 0s 225us/step - loss: 0.0086 - accuracy: 0.9952\n",
      "Epoch 160/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0096 - accuracy: 0.9952\n",
      "Epoch 161/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0087 - accuracy: 0.9952\n",
      "Epoch 162/200\n",
      "208/208 [==============================] - 0s 216us/step - loss: 0.0080 - accuracy: 0.9952\n",
      "Epoch 163/200\n",
      "208/208 [==============================] - 0s 206us/step - loss: 0.0071 - accuracy: 0.9952\n",
      "Epoch 164/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0065 - accuracy: 0.9952\n",
      "Epoch 165/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0065 - accuracy: 0.9952\n",
      "Epoch 166/200\n",
      "208/208 [==============================] - 0s 326us/step - loss: 0.0075 - accuracy: 0.9952\n",
      "Epoch 167/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0054 - accuracy: 0.9952\n",
      "Epoch 168/200\n",
      "208/208 [==============================] - 0s 211us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0061 - accuracy: 0.9952\n",
      "Epoch 170/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0051 - accuracy: 0.9952\n",
      "Epoch 171/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0044 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "208/208 [==============================] - 0s 206us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "208/208 [==============================] - 0s 192us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "208/208 [==============================] - 0s 216us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "208/208 [==============================] - 0s 245us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "208/208 [==============================] - 0s 225us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "208/208 [==============================] - 0s 245us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "208/208 [==============================] - 0s 197us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "208/208 [==============================] - 0s 206us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "208/208 [==============================] - 0s 240us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "208/208 [==============================] - 0s 316us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "208/208 [==============================] - 0s 187us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "208/208 [==============================] - 0s 177us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "208/208 [==============================] - 0s 182us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "208/208 [==============================] - 0s 163us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "208/208 [==============================] - 0s 590us/step\n",
      "\n",
      " Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)        # seed 값 설정\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "df = pd.read_csv(goal_path/'sonar.csv', header=None)           # 데이터 입력\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60]\n",
    "Y_obj = dataset[:,60]\n",
    "#print(Y_obj.unique())\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)            # 문자열 변환\n",
    "\n",
    "model = Sequential()              # 모델 설정\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',   optimizer='adam',    metrics=['accuracy'])  # 모델 컴파일\n",
    "\n",
    "hist = model.fit(X, Y, epochs=200, batch_size=5)                      # 모델 실행\n",
    "# print(hist)\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))     # 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.5241\n",
      "Epoch 2/130\n",
      "145/145 [==============================] - 0s 447us/step - loss: 0.2465 - accuracy: 0.5172\n",
      "Epoch 3/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.2441 - accuracy: 0.5310\n",
      "Epoch 4/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.2423 - accuracy: 0.5379\n",
      "Epoch 5/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.2392 - accuracy: 0.5517\n",
      "Epoch 6/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.2360 - accuracy: 0.6138\n",
      "Epoch 7/130\n",
      "145/145 [==============================] - 0s 165us/step - loss: 0.2315 - accuracy: 0.6138\n",
      "Epoch 8/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.2271 - accuracy: 0.6552\n",
      "Epoch 9/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.2204 - accuracy: 0.6759\n",
      "Epoch 10/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.2133 - accuracy: 0.6828\n",
      "Epoch 11/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.2054 - accuracy: 0.7034\n",
      "Epoch 12/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1997 - accuracy: 0.7379\n",
      "Epoch 13/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.1887 - accuracy: 0.7103\n",
      "Epoch 14/130\n",
      "145/145 [==============================] - 0s 378us/step - loss: 0.1788 - accuracy: 0.7379\n",
      "Epoch 15/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1736 - accuracy: 0.7517\n",
      "Epoch 16/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1673 - accuracy: 0.7793\n",
      "Epoch 17/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1633 - accuracy: 0.7655\n",
      "Epoch 18/130\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.80 - 0s 193us/step - loss: 0.1580 - accuracy: 0.8000\n",
      "Epoch 19/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1554 - accuracy: 0.8276\n",
      "Epoch 20/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1510 - accuracy: 0.8276\n",
      "Epoch 21/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1489 - accuracy: 0.8000\n",
      "Epoch 22/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1453 - accuracy: 0.8276\n",
      "Epoch 23/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.1445 - accuracy: 0.8138\n",
      "Epoch 24/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1383 - accuracy: 0.8414\n",
      "Epoch 25/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1367 - accuracy: 0.8345\n",
      "Epoch 26/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1369 - accuracy: 0.8483\n",
      "Epoch 27/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.1323 - accuracy: 0.8345\n",
      "Epoch 28/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1342 - accuracy: 0.8276\n",
      "Epoch 29/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.1290 - accuracy: 0.8621\n",
      "Epoch 30/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1357 - accuracy: 0.8207\n",
      "Epoch 31/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1264 - accuracy: 0.8483\n",
      "Epoch 32/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1287 - accuracy: 0.8552\n",
      "Epoch 33/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1227 - accuracy: 0.8552\n",
      "Epoch 34/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1233 - accuracy: 0.8621\n",
      "Epoch 35/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.1215 - accuracy: 0.8621\n",
      "Epoch 36/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1200 - accuracy: 0.8552\n",
      "Epoch 37/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.1211 - accuracy: 0.8414\n",
      "Epoch 38/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1125 - accuracy: 0.8897\n",
      "Epoch 39/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1143 - accuracy: 0.8690\n",
      "Epoch 40/130\n",
      "145/145 [==============================] - 0s 213us/step - loss: 0.1124 - accuracy: 0.8690\n",
      "Epoch 41/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1115 - accuracy: 0.8552\n",
      "Epoch 42/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1095 - accuracy: 0.8690\n",
      "Epoch 43/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.1082 - accuracy: 0.8759\n",
      "Epoch 44/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1071 - accuracy: 0.8897\n",
      "Epoch 45/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1069 - accuracy: 0.8759\n",
      "Epoch 46/130\n",
      "145/145 [==============================] - 0s 227us/step - loss: 0.1066 - accuracy: 0.8483\n",
      "Epoch 47/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.1070 - accuracy: 0.8828\n",
      "Epoch 48/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.1015 - accuracy: 0.8828\n",
      "Epoch 49/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1021 - accuracy: 0.8690\n",
      "Epoch 50/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1029 - accuracy: 0.8552\n",
      "Epoch 51/130\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.0986 - accuracy: 0.8966\n",
      "Epoch 52/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.1009 - accuracy: 0.8828\n",
      "Epoch 53/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0950 - accuracy: 0.8897\n",
      "Epoch 54/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.0936 - accuracy: 0.8966\n",
      "Epoch 55/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0945 - accuracy: 0.8966\n",
      "Epoch 56/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0929 - accuracy: 0.8897\n",
      "Epoch 57/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0911 - accuracy: 0.9034\n",
      "Epoch 58/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0889 - accuracy: 0.8897\n",
      "Epoch 59/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0901 - accuracy: 0.9034\n",
      "Epoch 60/130\n",
      "145/145 [==============================] - 0s 241us/step - loss: 0.0881 - accuracy: 0.8828\n",
      "Epoch 61/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.0850 - accuracy: 0.9103\n",
      "Epoch 62/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0833 - accuracy: 0.9034\n",
      "Epoch 63/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0928 - accuracy: 0.8621\n",
      "Epoch 64/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0889 - accuracy: 0.8897\n",
      "Epoch 65/130\n",
      "145/145 [==============================] - 0s 344us/step - loss: 0.0852 - accuracy: 0.9034\n",
      "Epoch 66/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0828 - accuracy: 0.8966\n",
      "Epoch 67/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0799 - accuracy: 0.9034\n",
      "Epoch 68/130\n",
      "145/145 [==============================] - 0s 254us/step - loss: 0.0795 - accuracy: 0.9172\n",
      "Epoch 69/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.0751 - accuracy: 0.9103\n",
      "Epoch 70/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0760 - accuracy: 0.9310\n",
      "Epoch 71/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.0741 - accuracy: 0.9172\n",
      "Epoch 72/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.0756 - accuracy: 0.9172\n",
      "Epoch 73/130\n",
      "145/145 [==============================] - 0s 227us/step - loss: 0.0712 - accuracy: 0.9103\n",
      "Epoch 74/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.0722 - accuracy: 0.9034\n",
      "Epoch 75/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.0705 - accuracy: 0.9172\n",
      "Epoch 76/130\n",
      "145/145 [==============================] - 0s 227us/step - loss: 0.0714 - accuracy: 0.9241\n",
      "Epoch 77/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.0688 - accuracy: 0.9241\n",
      "Epoch 78/130\n",
      "145/145 [==============================] - 0s 213us/step - loss: 0.0664 - accuracy: 0.9310\n",
      "Epoch 79/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.0635 - accuracy: 0.9448\n",
      "Epoch 80/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0666 - accuracy: 0.9172\n",
      "Epoch 81/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0639 - accuracy: 0.9379\n",
      "Epoch 82/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0611 - accuracy: 0.9379\n",
      "Epoch 83/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0614 - accuracy: 0.9379\n",
      "Epoch 84/130\n",
      "145/145 [==============================] - 0s 213us/step - loss: 0.0593 - accuracy: 0.9379\n",
      "Epoch 85/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0589 - accuracy: 0.9448\n",
      "Epoch 86/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.0566 - accuracy: 0.9517\n",
      "Epoch 87/130\n",
      "145/145 [==============================] - 0s 268us/step - loss: 0.0546 - accuracy: 0.9448\n",
      "Epoch 88/130\n",
      "145/145 [==============================] - 0s 227us/step - loss: 0.0566 - accuracy: 0.9517\n",
      "Epoch 89/130\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.0522 - accuracy: 0.9517\n",
      "Epoch 90/130\n",
      "145/145 [==============================] - 0s 475us/step - loss: 0.0525 - accuracy: 0.9586\n",
      "Epoch 91/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.0593 - accuracy: 0.9379\n",
      "Epoch 92/130\n",
      "145/145 [==============================] - 0s 234us/step - loss: 0.0519 - accuracy: 0.9586\n",
      "Epoch 93/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.0514 - accuracy: 0.9517\n",
      "Epoch 94/130\n",
      "145/145 [==============================] - 0s 213us/step - loss: 0.0499 - accuracy: 0.9586\n",
      "Epoch 95/130\n",
      "145/145 [==============================] - 0s 234us/step - loss: 0.0477 - accuracy: 0.9586\n",
      "Epoch 96/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.0493 - accuracy: 0.9448\n",
      "Epoch 97/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0448 - accuracy: 0.9655\n",
      "Epoch 98/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.0450 - accuracy: 0.9517\n",
      "Epoch 99/130\n",
      "145/145 [==============================] - 0s 206us/step - loss: 0.0441 - accuracy: 0.9586\n",
      "Epoch 100/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0443 - accuracy: 0.9724\n",
      "Epoch 101/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0459 - accuracy: 0.9655\n",
      "Epoch 102/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0440 - accuracy: 0.9517\n",
      "Epoch 103/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.0446 - accuracy: 0.9517\n",
      "Epoch 104/130\n",
      "145/145 [==============================] - 0s 220us/step - loss: 0.0440 - accuracy: 0.9517\n",
      "Epoch 105/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0428 - accuracy: 0.9655\n",
      "Epoch 106/130\n",
      "145/145 [==============================] - 0s 323us/step - loss: 0.0441 - accuracy: 0.9724\n",
      "Epoch 107/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0385 - accuracy: 0.9655\n",
      "Epoch 108/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0414 - accuracy: 0.9724\n",
      "Epoch 109/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0438 - accuracy: 0.9724\n",
      "Epoch 110/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0383 - accuracy: 0.9655\n",
      "Epoch 111/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.0362 - accuracy: 0.9724\n",
      "Epoch 112/130\n",
      "145/145 [==============================] - 0s 254us/step - loss: 0.0366 - accuracy: 0.9517\n",
      "Epoch 113/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0364 - accuracy: 0.9793\n",
      "Epoch 114/130\n",
      "145/145 [==============================] - 0s 172us/step - loss: 0.0385 - accuracy: 0.9655\n",
      "Epoch 115/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0351 - accuracy: 0.9793\n",
      "Epoch 116/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0336 - accuracy: 0.9724\n",
      "Epoch 117/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0318 - accuracy: 0.9862\n",
      "Epoch 118/130\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.0316 - accuracy: 0.9724\n",
      "Epoch 119/130\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0316 - accuracy: 0.9793\n",
      "Epoch 120/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0321 - accuracy: 0.9793\n",
      "Epoch 121/130\n",
      "145/145 [==============================] - 0s 186us/step - loss: 0.0320 - accuracy: 0.9793\n",
      "Epoch 122/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0320 - accuracy: 0.9724\n",
      "Epoch 123/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0290 - accuracy: 0.9862\n",
      "Epoch 124/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0309 - accuracy: 0.9793\n",
      "Epoch 125/130\n",
      "145/145 [==============================] - 0s 165us/step - loss: 0.0274 - accuracy: 0.9931\n",
      "Epoch 126/130\n",
      "145/145 [==============================] - 0s 179us/step - loss: 0.0288 - accuracy: 0.9862\n",
      "Epoch 127/130\n",
      "145/145 [==============================] - 0s 199us/step - loss: 0.0260 - accuracy: 0.9931\n",
      "Epoch 128/130\n",
      "145/145 [==============================] - 0s 193us/step - loss: 0.0268 - accuracy: 0.9931\n",
      "Epoch 129/130\n",
      "145/145 [==============================] - 0s 227us/step - loss: 0.0288 - accuracy: 0.9793\n",
      "Epoch 130/130\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.0237 - accuracy: 0.9931\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "\n",
      " Test Accuracy: 0.8254\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터와 테스트 데이터가 중복되면 과적합이 발생합니다.#########################################\n",
    "#데이터를 7:3의 비율로 랜덤하게 학습 데이터와 테스트 데이터로 분리해서 모델을 학습시키고 정확도를 측정합니다.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)        # seed 값 설정\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "df = pd.read_csv(goal_path/'sonar.csv', header=None)           # 데이터 입력\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60]\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)            # 문자열 변환\n",
    "\n",
    "# 학습셋과 테스트셋의 구분\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',   optimizer='adam',     metrics=['accuracy'])\n",
    "#학습 데이터로 학습 \n",
    "model.fit(X_train, Y_train, epochs=130, batch_size=5)   \n",
    "\n",
    "# 테스트셋에 모델 적용 평가\n",
    "print('\\n Test Accuracy: %.4f' % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.4920\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 474us/step - loss: 0.2445 - accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.2405 - accuracy: 0.5348\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.2336 - accuracy: 0.5348\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.2285 - accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.2180 - accuracy: 0.5829\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.2069 - accuracy: 0.6684\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1950 - accuracy: 0.6952\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.1841 - accuracy: 0.7594\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 346us/step - loss: 0.1743 - accuracy: 0.7647\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1703 - accuracy: 0.7540\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1577 - accuracy: 0.7807\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1498 - accuracy: 0.7968\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1413 - accuracy: 0.8075\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1412 - accuracy: 0.8075\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.1345 - accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1351 - accuracy: 0.8021\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1304 - accuracy: 0.8021\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.1377 - accuracy: 0.7754\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.1238 - accuracy: 0.8075\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 250us/step - loss: 0.1229 - accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1179 - accuracy: 0.8289\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1211 - accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1168 - accuracy: 0.8235\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1228 - accuracy: 0.8342\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1103 - accuracy: 0.8449\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 299us/step - loss: 0.1179 - accuracy: 0.8342\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1102 - accuracy: 0.8503\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1085 - accuracy: 0.8449\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1040 - accuracy: 0.8610\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1034 - accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1050 - accuracy: 0.8396\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 176us/step - loss: 0.1055 - accuracy: 0.8877\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 336us/step - loss: 0.1005 - accuracy: 0.8610\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1008 - accuracy: 0.8610\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1027 - accuracy: 0.8824\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 176us/step - loss: 0.1003 - accuracy: 0.8663\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0954 - accuracy: 0.8770\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0956 - accuracy: 0.9037\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0922 - accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 325us/step - loss: 0.0978 - accuracy: 0.8770\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0946 - accuracy: 0.8877\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.0932 - accuracy: 0.8877\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0934 - accuracy: 0.8717\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0939 - accuracy: 0.8824\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 186us/step - loss: 0.0901 - accuracy: 0.8770\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0918 - accuracy: 0.8717\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0876 - accuracy: 0.9037\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 207us/step - loss: 0.0883 - accuracy: 0.8770\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0860 - accuracy: 0.8770\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0864 - accuracy: 0.8770\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 186us/step - loss: 0.0889 - accuracy: 0.8824\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0887 - accuracy: 0.8717\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0832 - accuracy: 0.8984\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 207us/step - loss: 0.0817 - accuracy: 0.8984\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0860 - accuracy: 0.8824\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0813 - accuracy: 0.8984\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0840 - accuracy: 0.8930\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0783 - accuracy: 0.9037\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0793 - accuracy: 0.8930\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0780 - accuracy: 0.8984\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0788 - accuracy: 0.9037\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0777 - accuracy: 0.9037\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0808 - accuracy: 0.8930\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0826 - accuracy: 0.8930\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.0802 - accuracy: 0.8877\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0766 - accuracy: 0.9037\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0814 - accuracy: 0.8930\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0799 - accuracy: 0.8930\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 186us/step - loss: 0.0721 - accuracy: 0.8930\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0724 - accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0715 - accuracy: 0.9091\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0714 - accuracy: 0.9144\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0673 - accuracy: 0.9037\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0713 - accuracy: 0.9144\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0676 - accuracy: 0.9144\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.0782 - accuracy: 0.9037\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0712 - accuracy: 0.9037\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0645 - accuracy: 0.9198\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0693 - accuracy: 0.9198\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0659 - accuracy: 0.9091\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 336us/step - loss: 0.0658 - accuracy: 0.9144\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0623 - accuracy: 0.9251\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0677 - accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.0626 - accuracy: 0.9198\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.0618 - accuracy: 0.9198\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0607 - accuracy: 0.9198\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0624 - accuracy: 0.9198\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0603 - accuracy: 0.9358\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 352us/step - loss: 0.0601 - accuracy: 0.9198\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0574 - accuracy: 0.9412\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 453us/step - loss: 0.0622 - accuracy: 0.9358\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0580 - accuracy: 0.9358\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0628 - accuracy: 0.9251\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0601 - accuracy: 0.9091\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 299us/step - loss: 0.0571 - accuracy: 0.9305\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.0548 - accuracy: 0.9358\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0544 - accuracy: 0.9358\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0520 - accuracy: 0.9358\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.0544 - accuracy: 0.9412\n",
      "21/21 [==============================] - 0s 6ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.5080\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 389us/step - loss: 0.2416 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 266us/step - loss: 0.2325 - accuracy: 0.6524\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.2251 - accuracy: 0.6738\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.2148 - accuracy: 0.6738\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.2074 - accuracy: 0.6845\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1951 - accuracy: 0.7647\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1982 - accuracy: 0.6952\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1808 - accuracy: 0.7861\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1725 - accuracy: 0.7701\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.1666 - accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1615 - accuracy: 0.7540\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1547 - accuracy: 0.7807\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1500 - accuracy: 0.8021\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1553 - accuracy: 0.7754\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1467 - accuracy: 0.8128\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1423 - accuracy: 0.8021\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 363us/step - loss: 0.1367 - accuracy: 0.8021\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1344 - accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 191us/step - loss: 0.1316 - accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1313 - accuracy: 0.7861\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 298us/step - loss: 0.1309 - accuracy: 0.7914\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 309us/step - loss: 0.1242 - accuracy: 0.8396\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1216 - accuracy: 0.8449\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1183 - accuracy: 0.8396\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1161 - accuracy: 0.8342\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 191us/step - loss: 0.1160 - accuracy: 0.8449\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 325us/step - loss: 0.1114 - accuracy: 0.8396\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.1189 - accuracy: 0.8342\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1138 - accuracy: 0.8556\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1081 - accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1058 - accuracy: 0.8610\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0996 - accuracy: 0.8663\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0998 - accuracy: 0.8556\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1007 - accuracy: 0.8717\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0959 - accuracy: 0.8824\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0941 - accuracy: 0.8717\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0973 - accuracy: 0.8877\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0956 - accuracy: 0.8877\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0887 - accuracy: 0.8984\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0889 - accuracy: 0.8984\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 193us/step - loss: 0.0856 - accuracy: 0.8930\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 182us/step - loss: 0.0837 - accuracy: 0.9091\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.0798 - accuracy: 0.9037\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0798 - accuracy: 0.9091\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0758 - accuracy: 0.9037\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0736 - accuracy: 0.9251\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0784 - accuracy: 0.9091\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0704 - accuracy: 0.9305\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 331us/step - loss: 0.0725 - accuracy: 0.9198\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0737 - accuracy: 0.9198\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0689 - accuracy: 0.9144\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 283us/step - loss: 0.0677 - accuracy: 0.9305\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0730 - accuracy: 0.9198\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0659 - accuracy: 0.9305\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0609 - accuracy: 0.9358\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 197us/step - loss: 0.0676 - accuracy: 0.9305\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 230us/step - loss: 0.0633 - accuracy: 0.9305\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0567 - accuracy: 0.9572\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0545 - accuracy: 0.9465\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0575 - accuracy: 0.9412\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0541 - accuracy: 0.9519\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0548 - accuracy: 0.9465\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0557 - accuracy: 0.9465\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 331us/step - loss: 0.0507 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0480 - accuracy: 0.9572\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0478 - accuracy: 0.9572\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0445 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0496 - accuracy: 0.9519\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0447 - accuracy: 0.9572\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0454 - accuracy: 0.9626\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0457 - accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0427 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0403 - accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 321us/step - loss: 0.0380 - accuracy: 0.9733\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 336us/step - loss: 0.0413 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0432 - accuracy: 0.9626\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0367 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0369 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0405 - accuracy: 0.9626\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0336 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0336 - accuracy: 0.9679\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0316 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.0291 - accuracy: 0.9840\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0300 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 347us/step - loss: 0.0288 - accuracy: 0.9786\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0286 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 230us/step - loss: 0.0279 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0269 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 299us/step - loss: 0.0253 - accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0279 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0285 - accuracy: 0.9786\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0253 - accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0293 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0244 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 309us/step - loss: 0.0225 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0207 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.0199 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0192 - accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0194 - accuracy: 0.9893\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.5561\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 241us/step - loss: 0.2287 - accuracy: 0.6417\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.2200 - accuracy: 0.6791\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.2099 - accuracy: 0.7059\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.2014 - accuracy: 0.7059\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.1949 - accuracy: 0.7540\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.1853 - accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1773 - accuracy: 0.7594\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1754 - accuracy: 0.7594\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.1687 - accuracy: 0.7647\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.1634 - accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1565 - accuracy: 0.7914\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 325us/step - loss: 0.1561 - accuracy: 0.8128\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1505 - accuracy: 0.7914\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1429 - accuracy: 0.7914\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1447 - accuracy: 0.7914\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.1413 - accuracy: 0.7968\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1349 - accuracy: 0.8075\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1303 - accuracy: 0.8289\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.1306 - accuracy: 0.8235\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 358us/step - loss: 0.1216 - accuracy: 0.8503\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1207 - accuracy: 0.8717\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1206 - accuracy: 0.8396\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.1198 - accuracy: 0.8449\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.1128 - accuracy: 0.8503\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.1125 - accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 261us/step - loss: 0.1121 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1074 - accuracy: 0.8770\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1045 - accuracy: 0.8770\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1046 - accuracy: 0.8877\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.0999 - accuracy: 0.8877\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1006 - accuracy: 0.8717\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 315us/step - loss: 0.1015 - accuracy: 0.8717\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0957 - accuracy: 0.8717\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0979 - accuracy: 0.8824\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0944 - accuracy: 0.8824\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0962 - accuracy: 0.8930\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0997 - accuracy: 0.8663\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0907 - accuracy: 0.8930\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 384us/step - loss: 0.0855 - accuracy: 0.8984\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0868 - accuracy: 0.8824\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0860 - accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0842 - accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0777 - accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0852 - accuracy: 0.9037\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0791 - accuracy: 0.9037\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0762 - accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0759 - accuracy: 0.9037\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0759 - accuracy: 0.9198\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0714 - accuracy: 0.9198\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0694 - accuracy: 0.9358\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0678 - accuracy: 0.9251\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0674 - accuracy: 0.9251\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0662 - accuracy: 0.9251\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 304us/step - loss: 0.0685 - accuracy: 0.9305\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0669 - accuracy: 0.9305\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 207us/step - loss: 0.0646 - accuracy: 0.9251\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0636 - accuracy: 0.9251\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 336us/step - loss: 0.0638 - accuracy: 0.9144\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0604 - accuracy: 0.9412\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0599 - accuracy: 0.9305\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0592 - accuracy: 0.9305\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 250us/step - loss: 0.0585 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0537 - accuracy: 0.9305\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0529 - accuracy: 0.9465\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 331us/step - loss: 0.0564 - accuracy: 0.9198\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0533 - accuracy: 0.9519\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0511 - accuracy: 0.9358\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0518 - accuracy: 0.9412\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 182us/step - loss: 0.0485 - accuracy: 0.9519\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0499 - accuracy: 0.9412\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0443 - accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0463 - accuracy: 0.9572\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0431 - accuracy: 0.9572\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0440 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0418 - accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0398 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0425 - accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0409 - accuracy: 0.9679\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0379 - accuracy: 0.9733\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0382 - accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0365 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0366 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0379 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0363 - accuracy: 0.9679\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0373 - accuracy: 0.9679\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0337 - accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.0322 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0308 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0299 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0296 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0302 - accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0275 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0304 - accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 207us/step - loss: 0.0276 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 191us/step - loss: 0.0264 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0247 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0254 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0291 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0258 - accuracy: 0.9840\n",
      "21/21 [==============================] - 0s 6ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.5134\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 277us/step - loss: 0.2352 - accuracy: 0.6578\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 363us/step - loss: 0.2218 - accuracy: 0.7166\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.2077 - accuracy: 0.7326\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 315us/step - loss: 0.1902 - accuracy: 0.7647\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1797 - accuracy: 0.7701\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1689 - accuracy: 0.8075\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 272us/step - loss: 0.1580 - accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1549 - accuracy: 0.8128\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 304us/step - loss: 0.1456 - accuracy: 0.8235\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.1411 - accuracy: 0.8342\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 261us/step - loss: 0.1381 - accuracy: 0.8075\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 288us/step - loss: 0.1371 - accuracy: 0.8021\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1283 - accuracy: 0.8449\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1265 - accuracy: 0.8449\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.1243 - accuracy: 0.8503\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1210 - accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1170 - accuracy: 0.8556\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.1137 - accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1163 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1117 - accuracy: 0.8556\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.1078 - accuracy: 0.8610\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.1106 - accuracy: 0.8342\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1042 - accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1016 - accuracy: 0.8770\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0974 - accuracy: 0.8610\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0949 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.0919 - accuracy: 0.8877\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.8877\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0920 - accuracy: 0.8663\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0894 - accuracy: 0.9037\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0841 - accuracy: 0.9037\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0827 - accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0832 - accuracy: 0.9198\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 181us/step - loss: 0.0805 - accuracy: 0.9037\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.0773 - accuracy: 0.9144\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0761 - accuracy: 0.9037\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0756 - accuracy: 0.9198\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0733 - accuracy: 0.9144\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0775 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 368us/step - loss: 0.0816 - accuracy: 0.8930\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0697 - accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0678 - accuracy: 0.9198\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0676 - accuracy: 0.9305\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 277us/step - loss: 0.0605 - accuracy: 0.9519\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0597 - accuracy: 0.9519\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 352us/step - loss: 0.0585 - accuracy: 0.9519\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0563 - accuracy: 0.9519\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0604 - accuracy: 0.9465\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0552 - accuracy: 0.9572\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0504 - accuracy: 0.9679\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0503 - accuracy: 0.9572\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0486 - accuracy: 0.9626\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0472 - accuracy: 0.9626\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0508 - accuracy: 0.9519\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 310us/step - loss: 0.0450 - accuracy: 0.9679\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0437 - accuracy: 0.9679\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0433 - accuracy: 0.9679\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0448 - accuracy: 0.9626\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0450 - accuracy: 0.9679\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0484 - accuracy: 0.9198\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0477 - accuracy: 0.9572\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0424 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0377 - accuracy: 0.9679\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0364 - accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 304us/step - loss: 0.0348 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0356 - accuracy: 0.9679\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0376 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0361 - accuracy: 0.9733\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0340 - accuracy: 0.9733\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0308 - accuracy: 0.9786\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0287 - accuracy: 0.9786\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0282 - accuracy: 0.9733\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0293 - accuracy: 0.9786\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0276 - accuracy: 0.9786\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0323 - accuracy: 0.9733\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0275 - accuracy: 0.9786\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.0238 - accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0234 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 357us/step - loss: 0.0224 - accuracy: 0.9840\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0227 - accuracy: 0.9840\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0260 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 209us/step - loss: 0.0236 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0202 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0196 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0175 - accuracy: 0.9893\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0198 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 368us/step - loss: 0.0168 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0155 - accuracy: 0.9840\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0145 - accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0156 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0149 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0124 - accuracy: 0.9947\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0135 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0117 - accuracy: 0.9947\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0131 - accuracy: 0.9947\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0106 - accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 186us/step - loss: 0.0097 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0092 - accuracy: 0.9947\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 277us/step - loss: 0.2353 - accuracy: 0.6150\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 373us/step - loss: 0.2245 - accuracy: 0.6524\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 299us/step - loss: 0.2143 - accuracy: 0.7540\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.2015 - accuracy: 0.8235\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.1878 - accuracy: 0.7914\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1771 - accuracy: 0.8021\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1670 - accuracy: 0.8075\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 299us/step - loss: 0.1583 - accuracy: 0.8235\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 315us/step - loss: 0.1548 - accuracy: 0.8235\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1559 - accuracy: 0.7647\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 320us/step - loss: 0.1377 - accuracy: 0.8556\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1380 - accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1261 - accuracy: 0.8449\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1294 - accuracy: 0.8342\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1179 - accuracy: 0.8663\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1165 - accuracy: 0.8717\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 298us/step - loss: 0.1141 - accuracy: 0.8503\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1093 - accuracy: 0.8717\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1051 - accuracy: 0.8770\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.1032 - accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.0972 - accuracy: 0.8930\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.1000 - accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0938 - accuracy: 0.8984\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 230us/step - loss: 0.0899 - accuracy: 0.8717\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 207us/step - loss: 0.0980 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0865 - accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0808 - accuracy: 0.8984\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0820 - accuracy: 0.9091\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0808 - accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 191us/step - loss: 0.0769 - accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.0801 - accuracy: 0.9037\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0709 - accuracy: 0.9144\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0715 - accuracy: 0.9037\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0676 - accuracy: 0.9305\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0667 - accuracy: 0.9251\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0672 - accuracy: 0.9144\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0610 - accuracy: 0.9358\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 309us/step - loss: 0.0721 - accuracy: 0.9305\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0616 - accuracy: 0.9144\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0592 - accuracy: 0.9358\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0549 - accuracy: 0.9572\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0540 - accuracy: 0.9465\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 352us/step - loss: 0.0514 - accuracy: 0.9626\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0544 - accuracy: 0.9251\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 207us/step - loss: 0.0485 - accuracy: 0.9626\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0437 - accuracy: 0.9786\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 278us/step - loss: 0.0454 - accuracy: 0.9519\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0476 - accuracy: 0.9572\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 325us/step - loss: 0.0432 - accuracy: 0.9786\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0392 - accuracy: 0.9786\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0443 - accuracy: 0.9465\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0431 - accuracy: 0.9733\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0361 - accuracy: 0.9786\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0377 - accuracy: 0.9679\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.0368 - accuracy: 0.9679\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0353 - accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0301 - accuracy: 0.9840\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0307 - accuracy: 0.9840\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 262us/step - loss: 0.0306 - accuracy: 0.9786\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0289 - accuracy: 0.9893\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0273 - accuracy: 0.9840\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0280 - accuracy: 0.9893\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0277 - accuracy: 0.9893\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0266 - accuracy: 0.9893\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0248 - accuracy: 0.9840\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0255 - accuracy: 0.9893\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 193us/step - loss: 0.0227 - accuracy: 0.9893\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 197us/step - loss: 0.0281 - accuracy: 0.9679\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 261us/step - loss: 0.0215 - accuracy: 0.9893\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0205 - accuracy: 0.9893\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.0199 - accuracy: 0.9893\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0208 - accuracy: 0.9893\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0245 - accuracy: 0.9786\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0214 - accuracy: 0.9947\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0209 - accuracy: 0.9893\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 261us/step - loss: 0.0183 - accuracy: 0.9840\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 325us/step - loss: 0.0174 - accuracy: 0.9893\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0162 - accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 352us/step - loss: 0.0152 - accuracy: 0.9893\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 363us/step - loss: 0.0162 - accuracy: 0.9893\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0152 - accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0152 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 266us/step - loss: 0.0137 - accuracy: 0.9947\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0132 - accuracy: 0.9893\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 246us/step - loss: 0.0128 - accuracy: 0.9947\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 304us/step - loss: 0.0141 - accuracy: 0.9893\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 230us/step - loss: 0.0129 - accuracy: 0.9947\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0122 - accuracy: 0.9947\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 261us/step - loss: 0.0113 - accuracy: 0.9947\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.0114 - accuracy: 0.9947\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 347us/step - loss: 0.0116 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0113 - accuracy: 0.9947\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0103 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0115 - accuracy: 0.9947\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0110 - accuracy: 0.9947\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0111 - accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0100 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.0112 - accuracy: 0.9947\n",
      "21/21 [==============================] - 0s 7ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.4652\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.2467 - accuracy: 0.5241\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.2431 - accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.2394 - accuracy: 0.5936\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.2327 - accuracy: 0.7059\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.2189 - accuracy: 0.7433\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.2092 - accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1968 - accuracy: 0.7594\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.1876 - accuracy: 0.7433\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1739 - accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1686 - accuracy: 0.7540\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1601 - accuracy: 0.8021\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.1506 - accuracy: 0.7807\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1466 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.1380 - accuracy: 0.8235\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.1329 - accuracy: 0.8289\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.1310 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.1280 - accuracy: 0.8396\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.1217 - accuracy: 0.8556\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.1203 - accuracy: 0.8556\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.1130 - accuracy: 0.8663\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 304us/step - loss: 0.1123 - accuracy: 0.8663\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.1130 - accuracy: 0.8556\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.1110 - accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.1053 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.1045 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0977 - accuracy: 0.8877\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1013 - accuracy: 0.8610\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0965 - accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0938 - accuracy: 0.9037\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0926 - accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0890 - accuracy: 0.8984\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0877 - accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0927 - accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0829 - accuracy: 0.9198\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0828 - accuracy: 0.9251\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0848 - accuracy: 0.8930\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0836 - accuracy: 0.9037\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0808 - accuracy: 0.9251\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0787 - accuracy: 0.8984\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0745 - accuracy: 0.9412\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 272us/step - loss: 0.0736 - accuracy: 0.9412\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0729 - accuracy: 0.9144\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.0717 - accuracy: 0.9251\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0670 - accuracy: 0.9519\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0658 - accuracy: 0.9519\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0640 - accuracy: 0.9519\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 293us/step - loss: 0.0644 - accuracy: 0.9465\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0624 - accuracy: 0.9572\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0607 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0641 - accuracy: 0.9465\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0689 - accuracy: 0.9251\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0564 - accuracy: 0.9412\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.0573 - accuracy: 0.9358\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0550 - accuracy: 0.9572\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0527 - accuracy: 0.9626\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0513 - accuracy: 0.9519\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0503 - accuracy: 0.9572\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0495 - accuracy: 0.9572\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0484 - accuracy: 0.9572\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0500 - accuracy: 0.9519\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 187us/step - loss: 0.0497 - accuracy: 0.9519\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0498 - accuracy: 0.9465\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0444 - accuracy: 0.9733\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 298us/step - loss: 0.0502 - accuracy: 0.9626\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0438 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0411 - accuracy: 0.9733\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0402 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0399 - accuracy: 0.9733\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.0397 - accuracy: 0.9786\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 257us/step - loss: 0.0361 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0401 - accuracy: 0.9733\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.0468 - accuracy: 0.9733\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0372 - accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0370 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0331 - accuracy: 0.9786\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 298us/step - loss: 0.0340 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0315 - accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.0362 - accuracy: 0.9679\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0355 - accuracy: 0.9679\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 229us/step - loss: 0.0348 - accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 230us/step - loss: 0.0314 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.0289 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0295 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0274 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0269 - accuracy: 0.9786\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0284 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0271 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0279 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0266 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0250 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0252 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0243 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0228 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0289 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0262 - accuracy: 0.9840\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0222 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0226 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0233 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 234us/step - loss: 0.0216 - accuracy: 0.9786\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5134\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.2432 - accuracy: 0.5401\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.2357 - accuracy: 0.6203\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 223us/step - loss: 0.2259 - accuracy: 0.6417\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 218us/step - loss: 0.2193 - accuracy: 0.7059\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.2092 - accuracy: 0.6684\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.2016 - accuracy: 0.7594\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.1964 - accuracy: 0.7112\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1868 - accuracy: 0.7701\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1795 - accuracy: 0.7754\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.1776 - accuracy: 0.7968\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1677 - accuracy: 0.7968\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1634 - accuracy: 0.7861\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1604 - accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1550 - accuracy: 0.7968\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1551 - accuracy: 0.7701\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1471 - accuracy: 0.7968\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 267us/step - loss: 0.1450 - accuracy: 0.8075\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.1411 - accuracy: 0.8235\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 278us/step - loss: 0.1400 - accuracy: 0.8235\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.1369 - accuracy: 0.8021\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.1350 - accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.1308 - accuracy: 0.8289\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.1283 - accuracy: 0.8449\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 203us/step - loss: 0.1271 - accuracy: 0.8289\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1240 - accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1225 - accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.1194 - accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.1180 - accuracy: 0.8556\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1137 - accuracy: 0.8556\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1231 - accuracy: 0.8289\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1150 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1096 - accuracy: 0.8770\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1088 - accuracy: 0.8610\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1071 - accuracy: 0.8610\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1067 - accuracy: 0.8610\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 250us/step - loss: 0.1057 - accuracy: 0.8556\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 256us/step - loss: 0.1020 - accuracy: 0.8663\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 251us/step - loss: 0.1016 - accuracy: 0.8717\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 257us/step - loss: 0.1008 - accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0922 - accuracy: 0.8930\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.1031 - accuracy: 0.8717\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0933 - accuracy: 0.8877\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0911 - accuracy: 0.8930\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.0904 - accuracy: 0.9091\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0890 - accuracy: 0.8877\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0905 - accuracy: 0.9037\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0837 - accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0838 - accuracy: 0.8930\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0947 - accuracy: 0.8770\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0855 - accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0806 - accuracy: 0.9091\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0866 - accuracy: 0.8984\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0773 - accuracy: 0.9251\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0797 - accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0829 - accuracy: 0.8930\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0757 - accuracy: 0.9251\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0811 - accuracy: 0.9091\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0772 - accuracy: 0.9198\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0691 - accuracy: 0.9305\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0769 - accuracy: 0.9198\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0723 - accuracy: 0.9198\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0685 - accuracy: 0.9144\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0663 - accuracy: 0.9358\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0658 - accuracy: 0.9358\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0678 - accuracy: 0.9251\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0625 - accuracy: 0.9412\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0638 - accuracy: 0.9412\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0597 - accuracy: 0.9412\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0663 - accuracy: 0.9305\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0585 - accuracy: 0.9412\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 395us/step - loss: 0.0573 - accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 272us/step - loss: 0.0632 - accuracy: 0.9198\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 245us/step - loss: 0.0564 - accuracy: 0.9519\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 239us/step - loss: 0.0539 - accuracy: 0.9412\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0548 - accuracy: 0.9358\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 246us/step - loss: 0.0526 - accuracy: 0.9519\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0535 - accuracy: 0.9412\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0513 - accuracy: 0.9572\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 224us/step - loss: 0.0502 - accuracy: 0.9412\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0508 - accuracy: 0.9519\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0491 - accuracy: 0.9519\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0482 - accuracy: 0.9519\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0460 - accuracy: 0.9519\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 193us/step - loss: 0.0502 - accuracy: 0.9358\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0438 - accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0451 - accuracy: 0.9465\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0464 - accuracy: 0.9572\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0411 - accuracy: 0.9519\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0402 - accuracy: 0.9519\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0434 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0392 - accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0392 - accuracy: 0.9572\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0373 - accuracy: 0.9626\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0379 - accuracy: 0.9626\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0396 - accuracy: 0.9679\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0349 - accuracy: 0.9626\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0339 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.0352 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 235us/step - loss: 0.0337 - accuracy: 0.9733\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.4866 \n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 213us/step - loss: 0.2477 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.2398 - accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.2268 - accuracy: 0.7059\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.2212 - accuracy: 0.6898\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.2099 - accuracy: 0.6952\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1963 - accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1875 - accuracy: 0.7914\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1817 - accuracy: 0.7219\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1724 - accuracy: 0.7594\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1637 - accuracy: 0.7914\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1578 - accuracy: 0.7861\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.1492 - accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1449 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1395 - accuracy: 0.8342\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1377 - accuracy: 0.7861\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1321 - accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1260 - accuracy: 0.8717\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1251 - accuracy: 0.8503\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.1187 - accuracy: 0.8610\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1165 - accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1114 - accuracy: 0.8877\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.1084 - accuracy: 0.8877\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.1081 - accuracy: 0.8984\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1030 - accuracy: 0.9037\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0985 - accuracy: 0.8824\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.1017 - accuracy: 0.8877\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0953 - accuracy: 0.9144\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.1009 - accuracy: 0.8877\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0920 - accuracy: 0.9144\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 219us/step - loss: 0.0902 - accuracy: 0.9198\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 214us/step - loss: 0.0845 - accuracy: 0.9144\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 209us/step - loss: 0.0836 - accuracy: 0.9251\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0837 - accuracy: 0.9091\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0839 - accuracy: 0.8984\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0788 - accuracy: 0.9251\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0848 - accuracy: 0.9251\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0797 - accuracy: 0.8930\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0801 - accuracy: 0.9305\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0732 - accuracy: 0.9305\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 1.00 - 0s 208us/step - loss: 0.0700 - accuracy: 0.9251\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0701 - accuracy: 0.9251\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0675 - accuracy: 0.9305\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0660 - accuracy: 0.9412\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0635 - accuracy: 0.9465\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 196us/step - loss: 0.0642 - accuracy: 0.9305\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0671 - accuracy: 0.9144\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0652 - accuracy: 0.9465\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0692 - accuracy: 0.9091\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0588 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0676 - accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0601 - accuracy: 0.9305\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0563 - accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0530 - accuracy: 0.9572\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0527 - accuracy: 0.9572\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0513 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0504 - accuracy: 0.9572\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0514 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0506 - accuracy: 0.9358\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0471 - accuracy: 0.9626\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 208us/step - loss: 0.0487 - accuracy: 0.9358\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0479 - accuracy: 0.9626\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0453 - accuracy: 0.9465\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0496 - accuracy: 0.9358\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0464 - accuracy: 0.9519\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0425 - accuracy: 0.9572\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0471 - accuracy: 0.9572\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0440 - accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0436 - accuracy: 0.9626\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0377 - accuracy: 0.9679\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0379 - accuracy: 0.9679\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0404 - accuracy: 0.9626\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0374 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0357 - accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0352 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0349 - accuracy: 0.9840\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0335 - accuracy: 0.9679\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0319 - accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0323 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0299 - accuracy: 0.9786\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 202us/step - loss: 0.0302 - accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 240us/step - loss: 0.0305 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0298 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0275 - accuracy: 0.9840\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 202us/step - loss: 0.0275 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0304 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 198us/step - loss: 0.0253 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0258 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0232 - accuracy: 0.9840\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0220 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 0s 192us/step - loss: 0.0234 - accuracy: 0.9840\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0225 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 202us/step - loss: 0.0219 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0222 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0227 - accuracy: 0.9893\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - ETA: 0s - loss: 6.4762e-04 - accuracy: 1.00 - 0s 197us/step - loss: 0.0190 - accuracy: 0.9840\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0236 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0184 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 0s 203us/step - loss: 0.0179 - accuracy: 0.9840\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 197us/step - loss: 0.0164 - accuracy: 0.9893\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.5691\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 217us/step - loss: 0.2239 - accuracy: 0.6596\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.2150 - accuracy: 0.7234\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.2058 - accuracy: 0.7021\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1983 - accuracy: 0.7074\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.1898 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1789 - accuracy: 0.7606\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1731 - accuracy: 0.8085\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1650 - accuracy: 0.7553\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1572 - accuracy: 0.7926\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.1522 - accuracy: 0.8085\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 217us/step - loss: 0.1481 - accuracy: 0.8032\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1443 - accuracy: 0.8191\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.1376 - accuracy: 0.8351\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1346 - accuracy: 0.8298\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1311 - accuracy: 0.8245\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1273 - accuracy: 0.8404\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 223us/step - loss: 0.1294 - accuracy: 0.8191\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 218us/step - loss: 0.1357 - accuracy: 0.8085\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 234us/step - loss: 0.1247 - accuracy: 0.8245\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1297 - accuracy: 0.8351\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1146 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.1123 - accuracy: 0.8670\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.1117 - accuracy: 0.8511\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1101 - accuracy: 0.8777\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1070 - accuracy: 0.8511\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.1078 - accuracy: 0.8404\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.1043 - accuracy: 0.8830\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1178 - accuracy: 0.8245\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1074 - accuracy: 0.8617\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 197us/step - loss: 0.0978 - accuracy: 0.8883\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0971 - accuracy: 0.8883\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0992 - accuracy: 0.8564\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0931 - accuracy: 0.8989\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0928 - accuracy: 0.8830\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 0s 239us/step - loss: 0.0933 - accuracy: 0.8830\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 197us/step - loss: 0.0916 - accuracy: 0.8777\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0866 - accuracy: 0.9202\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0864 - accuracy: 0.9202\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 0s 197us/step - loss: 0.0898 - accuracy: 0.8777\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0835 - accuracy: 0.9096\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0924 - accuracy: 0.8883\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 192us/step - loss: 0.0836 - accuracy: 0.9043\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0798 - accuracy: 0.9255\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0806 - accuracy: 0.9362\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0788 - accuracy: 0.9202\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 197us/step - loss: 0.0737 - accuracy: 0.9202\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0761 - accuracy: 0.9202\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0731 - accuracy: 0.9309\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0716 - accuracy: 0.9149\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 213us/step - loss: 0.0695 - accuracy: 0.9255\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0690 - accuracy: 0.9255\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0695 - accuracy: 0.9309\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0681 - accuracy: 0.9255\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0660 - accuracy: 0.9309\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0682 - accuracy: 0.9255\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0676 - accuracy: 0.9149\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0665 - accuracy: 0.9255\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0651 - accuracy: 0.9202\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0601 - accuracy: 0.9309\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0606 - accuracy: 0.9415\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0588 - accuracy: 0.9255\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0592 - accuracy: 0.9362\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0547 - accuracy: 0.9468\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0595 - accuracy: 0.9309\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0594 - accuracy: 0.9362\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0533 - accuracy: 0.9468\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0523 - accuracy: 0.9415\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0502 - accuracy: 0.9521\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0515 - accuracy: 0.9468\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0520 - accuracy: 0.9521\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0531 - accuracy: 0.9574\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0477 - accuracy: 0.9521\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0478 - accuracy: 0.9574\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0459 - accuracy: 0.9574\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 0s 197us/step - loss: 0.0444 - accuracy: 0.9521\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0436 - accuracy: 0.9574\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0477 - accuracy: 0.9521\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0442 - accuracy: 0.9628\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0419 - accuracy: 0.9628\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0420 - accuracy: 0.9574\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0390 - accuracy: 0.9681\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0410 - accuracy: 0.9521\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0384 - accuracy: 0.9681\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0390 - accuracy: 0.9574\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0377 - accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0365 - accuracy: 0.9628\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0333 - accuracy: 0.9734\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0343 - accuracy: 0.9681\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 191us/step - loss: 0.0338 - accuracy: 0.9787\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0361 - accuracy: 0.9628\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0333 - accuracy: 0.9734\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0350 - accuracy: 0.9628\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0331 - accuracy: 0.9787\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 0s 196us/step - loss: 0.0321 - accuracy: 0.9681\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0299 - accuracy: 0.9681\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0311 - accuracy: 0.9734\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0300 - accuracy: 0.9681\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0289 - accuracy: 0.9734\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0275 - accuracy: 0.9787\n",
      "20/20 [==============================] - 0s 9ms/step\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5585\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.2369 - accuracy: 0.7128\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 0s 228us/step - loss: 0.2286 - accuracy: 0.7340\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.2169 - accuracy: 0.7766\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.2065 - accuracy: 0.7287\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1957 - accuracy: 0.7287\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1833 - accuracy: 0.7553\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1756 - accuracy: 0.7766\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1648 - accuracy: 0.7872\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1557 - accuracy: 0.8191\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1518 - accuracy: 0.8245\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1472 - accuracy: 0.8138\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.1406 - accuracy: 0.8404\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1325 - accuracy: 0.8404\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 228us/step - loss: 0.1327 - accuracy: 0.8191\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.1323 - accuracy: 0.8085\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1271 - accuracy: 0.8138\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1267 - accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1194 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.1205 - accuracy: 0.8404\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.1172 - accuracy: 0.8511\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1142 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1122 - accuracy: 0.8777\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.1122 - accuracy: 0.8404\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.1111 - accuracy: 0.8670\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.1038 - accuracy: 0.8511\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.1035 - accuracy: 0.8511\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 218us/step - loss: 0.1007 - accuracy: 0.8777\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.1002 - accuracy: 0.8617\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0972 - accuracy: 0.8723\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 217us/step - loss: 0.1005 - accuracy: 0.8777\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0993 - accuracy: 0.8564\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0955 - accuracy: 0.8830\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0916 - accuracy: 0.8936\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0906 - accuracy: 0.8883\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 207us/step - loss: 0.0895 - accuracy: 0.9043\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0929 - accuracy: 0.9043\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 213us/step - loss: 0.0857 - accuracy: 0.8936\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0809 - accuracy: 0.9309\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0849 - accuracy: 0.8989\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0905 - accuracy: 0.8830\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0807 - accuracy: 0.9202\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 217us/step - loss: 0.0823 - accuracy: 0.9309\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0772 - accuracy: 0.8989\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 0s 233us/step - loss: 0.0760 - accuracy: 0.9362\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0769 - accuracy: 0.9149\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0730 - accuracy: 0.9255\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0716 - accuracy: 0.9149\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0686 - accuracy: 0.9202\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0674 - accuracy: 0.9309\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0664 - accuracy: 0.9309\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0674 - accuracy: 0.9309\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0617 - accuracy: 0.9362\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0734 - accuracy: 0.8989\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0641 - accuracy: 0.9255\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0593 - accuracy: 0.9362\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0624 - accuracy: 0.9149\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 213us/step - loss: 0.0613 - accuracy: 0.9202\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0580 - accuracy: 0.9415\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0642 - accuracy: 0.9255\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0779 - accuracy: 0.8883\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0676 - accuracy: 0.9202\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0591 - accuracy: 0.9202\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 213us/step - loss: 0.0541 - accuracy: 0.9521\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 0s 218us/step - loss: 0.0554 - accuracy: 0.9415\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 0s 217us/step - loss: 0.0519 - accuracy: 0.9574\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0549 - accuracy: 0.9309\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0526 - accuracy: 0.9415\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0540 - accuracy: 0.9468\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0504 - accuracy: 0.9362\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0496 - accuracy: 0.9415\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0449 - accuracy: 0.9521\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0473 - accuracy: 0.9468\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0507 - accuracy: 0.9468\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0432 - accuracy: 0.9628\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0443 - accuracy: 0.9521\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0500 - accuracy: 0.9255\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0419 - accuracy: 0.9521\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0450 - accuracy: 0.9574\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0404 - accuracy: 0.9521\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0393 - accuracy: 0.9574\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0381 - accuracy: 0.9628\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0415 - accuracy: 0.9574\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0393 - accuracy: 0.9521\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0377 - accuracy: 0.9574\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0379 - accuracy: 0.9574\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 206us/step - loss: 0.0369 - accuracy: 0.9681\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 218us/step - loss: 0.0397 - accuracy: 0.9521\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0371 - accuracy: 0.9468\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 213us/step - loss: 0.0335 - accuracy: 0.9681\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0350 - accuracy: 0.9574\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 0s 201us/step - loss: 0.0337 - accuracy: 0.9734\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0344 - accuracy: 0.9681\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0405 - accuracy: 0.9681\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0336 - accuracy: 0.9628\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0268 - accuracy: 0.9787\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0272 - accuracy: 0.9787\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 202us/step - loss: 0.0245 - accuracy: 0.9894\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 0s 212us/step - loss: 0.0245 - accuracy: 0.9840\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 207us/step - loss: 0.0246 - accuracy: 0.9840\n",
      "20/20 [==============================] - 0s 9ms/step\n",
      "\n",
      " 10 fold accuracy: ['0.7143', '0.6667', '0.7619', '0.9524', '0.8095', '0.8571', '0.9048', '0.8571', '0.9500', '0.8500']\n"
     ]
    }
   ],
   "source": [
    "# 10개의 파일로 쪼개 테스트하는?10-fold cross validation을 실시하도록?n_fold의 값을 10으로 설정한 뒤?StratifiedKFold()?함수에 적용했습니다. 그런 다음 모델을 만들고 실행하는 부분을?for?구문으로 묶어?n_fold만큼 반복되게 합니다.\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)        # seed 값 설정\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "df = pd.read_csv(goal_path/'sonar.csv', header=None)           # 데이터 입력\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60]\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)            # 문자열 변환\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_fold = 10  #10겹 \n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "accuracy = []  # 빈 accuracy 배열\n",
    "\n",
    "for train, test in skf.split(X, Y):  # 모델의 설정, 컴파일, 실행\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error',  optimizer='adam',   metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n",
    "    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n %.f fold accuracy:\" % n_fold, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 653 samples, validate on 322 samples\n",
      "Epoch 1/3500\n",
      "653/653 [==============================] - 1s 976us/step - loss: 0.5533 - accuracy: 0.7596 - val_loss: 0.4723 - val_accuracy: 0.7826\n",
      "Epoch 2/3500\n",
      "653/653 [==============================] - 0s 63us/step - loss: 0.4956 - accuracy: 0.7596 - val_loss: 0.4377 - val_accuracy: 0.7826\n",
      "Epoch 3/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.4585 - accuracy: 0.7580 - val_loss: 0.4168 - val_accuracy: 0.7764\n",
      "Epoch 4/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.4312 - accuracy: 0.7596 - val_loss: 0.4066 - val_accuracy: 0.7702\n",
      "Epoch 5/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.4147 - accuracy: 0.7534 - val_loss: 0.3915 - val_accuracy: 0.7795\n",
      "Epoch 6/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.3958 - accuracy: 0.7642 - val_loss: 0.3725 - val_accuracy: 0.7919\n",
      "Epoch 7/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.3810 - accuracy: 0.7779 - val_loss: 0.3607 - val_accuracy: 0.7919\n",
      "Epoch 8/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.3724 - accuracy: 0.7841 - val_loss: 0.3535 - val_accuracy: 0.8012\n",
      "Epoch 9/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.3665 - accuracy: 0.7933 - val_loss: 0.3465 - val_accuracy: 0.8168\n",
      "Epoch 10/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.3593 - accuracy: 0.7994 - val_loss: 0.3408 - val_accuracy: 0.8261\n",
      "Epoch 11/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.3520 - accuracy: 0.8147 - val_loss: 0.3372 - val_accuracy: 0.8385\n",
      "Epoch 12/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.3474 - accuracy: 0.8270 - val_loss: 0.3334 - val_accuracy: 0.8540\n",
      "Epoch 13/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.3426 - accuracy: 0.8423 - val_loss: 0.3246 - val_accuracy: 0.8571\n",
      "Epoch 14/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.3359 - accuracy: 0.8469 - val_loss: 0.3172 - val_accuracy: 0.8602\n",
      "Epoch 15/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.3305 - accuracy: 0.8499 - val_loss: 0.3110 - val_accuracy: 0.8634\n",
      "Epoch 16/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.3253 - accuracy: 0.8530 - val_loss: 0.3035 - val_accuracy: 0.8665\n",
      "Epoch 17/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.3188 - accuracy: 0.8591 - val_loss: 0.2969 - val_accuracy: 0.8758\n",
      "Epoch 18/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.3108 - accuracy: 0.8714 - val_loss: 0.2909 - val_accuracy: 0.8789\n",
      "Epoch 19/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.3047 - accuracy: 0.8744 - val_loss: 0.2856 - val_accuracy: 0.8851\n",
      "Epoch 20/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2986 - accuracy: 0.8821 - val_loss: 0.2816 - val_accuracy: 0.8944\n",
      "Epoch 21/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.2926 - accuracy: 0.8928 - val_loss: 0.2784 - val_accuracy: 0.9037\n",
      "Epoch 22/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.2871 - accuracy: 0.8913 - val_loss: 0.2693 - val_accuracy: 0.9068\n",
      "Epoch 23/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.2784 - accuracy: 0.8959 - val_loss: 0.2613 - val_accuracy: 0.9037\n",
      "Epoch 24/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2724 - accuracy: 0.8974 - val_loss: 0.2566 - val_accuracy: 0.9068\n",
      "Epoch 25/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.2677 - accuracy: 0.8974 - val_loss: 0.2517 - val_accuracy: 0.9130\n",
      "Epoch 26/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.2602 - accuracy: 0.9051 - val_loss: 0.2554 - val_accuracy: 0.9224\n",
      "Epoch 27/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2601 - accuracy: 0.9158 - val_loss: 0.2515 - val_accuracy: 0.9224\n",
      "Epoch 28/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.2560 - accuracy: 0.9204 - val_loss: 0.2430 - val_accuracy: 0.9255\n",
      "Epoch 29/3500\n",
      "653/653 [==============================] - 0s 92us/step - loss: 0.2483 - accuracy: 0.9173 - val_loss: 0.2373 - val_accuracy: 0.9255\n",
      "Epoch 30/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.2439 - accuracy: 0.9158 - val_loss: 0.2351 - val_accuracy: 0.9255\n",
      "Epoch 31/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.2421 - accuracy: 0.9142 - val_loss: 0.2319 - val_accuracy: 0.9255\n",
      "Epoch 32/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.2376 - accuracy: 0.9173 - val_loss: 0.2304 - val_accuracy: 0.9286\n",
      "Epoch 33/3500\n",
      "653/653 [==============================] - 0s 64us/step - loss: 0.2355 - accuracy: 0.9204 - val_loss: 0.2329 - val_accuracy: 0.9441\n",
      "Epoch 34/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.2362 - accuracy: 0.9219 - val_loss: 0.2274 - val_accuracy: 0.9379\n",
      "Epoch 35/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2307 - accuracy: 0.9219 - val_loss: 0.2231 - val_accuracy: 0.9286\n",
      "Epoch 36/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.2293 - accuracy: 0.9204 - val_loss: 0.2232 - val_accuracy: 0.9224\n",
      "Epoch 37/3500\n",
      "653/653 [==============================] - 0s 83us/step - loss: 0.2281 - accuracy: 0.9204 - val_loss: 0.2195 - val_accuracy: 0.9317\n",
      "Epoch 38/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2240 - accuracy: 0.9234 - val_loss: 0.2198 - val_accuracy: 0.9472\n",
      "Epoch 39/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.2238 - accuracy: 0.9234 - val_loss: 0.2185 - val_accuracy: 0.9441\n",
      "Epoch 40/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.2215 - accuracy: 0.9219 - val_loss: 0.2152 - val_accuracy: 0.9317\n",
      "Epoch 41/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.2203 - accuracy: 0.9265 - val_loss: 0.2199 - val_accuracy: 0.9255\n",
      "Epoch 42/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.2245 - accuracy: 0.9234 - val_loss: 0.2154 - val_accuracy: 0.9286\n",
      "Epoch 43/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2190 - accuracy: 0.9219 - val_loss: 0.2126 - val_accuracy: 0.9441\n",
      "Epoch 44/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.2162 - accuracy: 0.9250 - val_loss: 0.2173 - val_accuracy: 0.9472\n",
      "Epoch 45/3500\n",
      "653/653 [==============================] - 0s 61us/step - loss: 0.2199 - accuracy: 0.9296 - val_loss: 0.2114 - val_accuracy: 0.9472\n",
      "Epoch 46/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2147 - accuracy: 0.9280 - val_loss: 0.2083 - val_accuracy: 0.9379\n",
      "Epoch 47/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.2125 - accuracy: 0.9250 - val_loss: 0.2098 - val_accuracy: 0.9317\n",
      "Epoch 48/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2141 - accuracy: 0.9265 - val_loss: 0.2075 - val_accuracy: 0.9379\n",
      "Epoch 49/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.2113 - accuracy: 0.9265 - val_loss: 0.2046 - val_accuracy: 0.9441\n",
      "Epoch 50/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.2097 - accuracy: 0.9250 - val_loss: 0.2064 - val_accuracy: 0.9503\n",
      "Epoch 51/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.2109 - accuracy: 0.9311 - val_loss: 0.2031 - val_accuracy: 0.9503\n",
      "Epoch 52/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.2093 - accuracy: 0.9280 - val_loss: 0.2013 - val_accuracy: 0.9441\n",
      "Epoch 53/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.2066 - accuracy: 0.9250 - val_loss: 0.2003 - val_accuracy: 0.9441\n",
      "Epoch 54/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.2055 - accuracy: 0.9250 - val_loss: 0.1992 - val_accuracy: 0.9441\n",
      "Epoch 55/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.2047 - accuracy: 0.9296 - val_loss: 0.1983 - val_accuracy: 0.9441\n",
      "Epoch 56/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.2037 - accuracy: 0.9296 - val_loss: 0.1974 - val_accuracy: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.2027 - accuracy: 0.9296 - val_loss: 0.1966 - val_accuracy: 0.9441\n",
      "Epoch 58/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.2023 - accuracy: 0.9280 - val_loss: 0.1957 - val_accuracy: 0.9441\n",
      "Epoch 59/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.2016 - accuracy: 0.9280 - val_loss: 0.1952 - val_accuracy: 0.9503\n",
      "Epoch 60/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.2012 - accuracy: 0.9280 - val_loss: 0.1943 - val_accuracy: 0.9503\n",
      "Epoch 61/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.2006 - accuracy: 0.9280 - val_loss: 0.1942 - val_accuracy: 0.9441\n",
      "Epoch 62/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1994 - accuracy: 0.9296 - val_loss: 0.1933 - val_accuracy: 0.9472\n",
      "Epoch 63/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.1991 - accuracy: 0.9280 - val_loss: 0.1929 - val_accuracy: 0.9472\n",
      "Epoch 64/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.1979 - accuracy: 0.9296 - val_loss: 0.1945 - val_accuracy: 0.9441\n",
      "Epoch 65/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1994 - accuracy: 0.9280 - val_loss: 0.1965 - val_accuracy: 0.9441\n",
      "Epoch 66/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.1996 - accuracy: 0.9265 - val_loss: 0.1918 - val_accuracy: 0.9472\n",
      "Epoch 67/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1960 - accuracy: 0.9296 - val_loss: 0.1923 - val_accuracy: 0.9472\n",
      "Epoch 68/3500\n",
      "653/653 [==============================] - 0s 69us/step - loss: 0.1979 - accuracy: 0.9296 - val_loss: 0.1934 - val_accuracy: 0.9472\n",
      "Epoch 69/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1989 - accuracy: 0.9326 - val_loss: 0.1899 - val_accuracy: 0.9472\n",
      "Epoch 70/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.1950 - accuracy: 0.9311 - val_loss: 0.1920 - val_accuracy: 0.9441\n",
      "Epoch 71/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1964 - accuracy: 0.9280 - val_loss: 0.1924 - val_accuracy: 0.9441\n",
      "Epoch 72/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1958 - accuracy: 0.9280 - val_loss: 0.1887 - val_accuracy: 0.9503\n",
      "Epoch 73/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.1941 - accuracy: 0.9296 - val_loss: 0.1880 - val_accuracy: 0.9472\n",
      "Epoch 74/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1936 - accuracy: 0.9311 - val_loss: 0.1874 - val_accuracy: 0.9472\n",
      "Epoch 75/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.1925 - accuracy: 0.9311 - val_loss: 0.1870 - val_accuracy: 0.9472\n",
      "Epoch 76/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1926 - accuracy: 0.9326 - val_loss: 0.1865 - val_accuracy: 0.9472\n",
      "Epoch 77/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1916 - accuracy: 0.9296 - val_loss: 0.1874 - val_accuracy: 0.9472\n",
      "Epoch 78/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.1915 - accuracy: 0.9311 - val_loss: 0.1873 - val_accuracy: 0.9472\n",
      "Epoch 79/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1912 - accuracy: 0.9311 - val_loss: 0.1857 - val_accuracy: 0.9472\n",
      "Epoch 80/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1898 - accuracy: 0.9311 - val_loss: 0.1854 - val_accuracy: 0.9472\n",
      "Epoch 81/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1907 - accuracy: 0.9326 - val_loss: 0.1869 - val_accuracy: 0.9472\n",
      "Epoch 82/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1926 - accuracy: 0.9326 - val_loss: 0.1844 - val_accuracy: 0.9472\n",
      "Epoch 83/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1890 - accuracy: 0.9311 - val_loss: 0.1903 - val_accuracy: 0.9441\n",
      "Epoch 84/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1931 - accuracy: 0.9296 - val_loss: 0.1900 - val_accuracy: 0.9441\n",
      "Epoch 85/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1912 - accuracy: 0.9326 - val_loss: 0.1836 - val_accuracy: 0.9472\n",
      "Epoch 86/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1878 - accuracy: 0.9326 - val_loss: 0.1859 - val_accuracy: 0.9503\n",
      "Epoch 87/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1916 - accuracy: 0.9326 - val_loss: 0.1837 - val_accuracy: 0.9472\n",
      "Epoch 88/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1887 - accuracy: 0.9311 - val_loss: 0.1833 - val_accuracy: 0.9441\n",
      "Epoch 89/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1882 - accuracy: 0.9326 - val_loss: 0.1845 - val_accuracy: 0.9472\n",
      "Epoch 90/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1870 - accuracy: 0.9326 - val_loss: 0.1818 - val_accuracy: 0.9472\n",
      "Epoch 91/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.1856 - accuracy: 0.9342 - val_loss: 0.1818 - val_accuracy: 0.9472\n",
      "Epoch 92/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.1869 - accuracy: 0.9357 - val_loss: 0.1812 - val_accuracy: 0.9472\n",
      "Epoch 93/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.1858 - accuracy: 0.9296 - val_loss: 0.1827 - val_accuracy: 0.9472\n",
      "Epoch 94/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1854 - accuracy: 0.9326 - val_loss: 0.1818 - val_accuracy: 0.9441\n",
      "Epoch 95/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.1846 - accuracy: 0.9342 - val_loss: 0.1801 - val_accuracy: 0.9472\n",
      "Epoch 96/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1846 - accuracy: 0.9326 - val_loss: 0.1798 - val_accuracy: 0.9472\n",
      "Epoch 97/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1841 - accuracy: 0.9342 - val_loss: 0.1807 - val_accuracy: 0.9441\n",
      "Epoch 98/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1836 - accuracy: 0.9326 - val_loss: 0.1792 - val_accuracy: 0.9472\n",
      "Epoch 99/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1821 - accuracy: 0.9372 - val_loss: 0.1809 - val_accuracy: 0.9503\n",
      "Epoch 100/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1868 - accuracy: 0.9342 - val_loss: 0.1801 - val_accuracy: 0.9503\n",
      "Epoch 101/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1854 - accuracy: 0.9342 - val_loss: 0.1788 - val_accuracy: 0.9441\n",
      "Epoch 102/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.1813 - accuracy: 0.9342 - val_loss: 0.1816 - val_accuracy: 0.9472\n",
      "Epoch 103/3500\n",
      "653/653 [==============================] - 0s 136us/step - loss: 0.1837 - accuracy: 0.9342 - val_loss: 0.1804 - val_accuracy: 0.9472\n",
      "Epoch 104/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1823 - accuracy: 0.9326 - val_loss: 0.1770 - val_accuracy: 0.9472\n",
      "Epoch 105/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1814 - accuracy: 0.9311 - val_loss: 0.1767 - val_accuracy: 0.9472\n",
      "Epoch 106/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.1804 - accuracy: 0.9372 - val_loss: 0.1779 - val_accuracy: 0.9441\n",
      "Epoch 107/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1805 - accuracy: 0.9342 - val_loss: 0.1830 - val_accuracy: 0.9472\n",
      "Epoch 108/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.1835 - accuracy: 0.9342 - val_loss: 0.1799 - val_accuracy: 0.9472\n",
      "Epoch 109/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1802 - accuracy: 0.9342 - val_loss: 0.1752 - val_accuracy: 0.9472\n",
      "Epoch 110/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1797 - accuracy: 0.9372 - val_loss: 0.1781 - val_accuracy: 0.9503\n",
      "Epoch 111/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.1843 - accuracy: 0.9342 - val_loss: 0.1753 - val_accuracy: 0.9503\n",
      "Epoch 112/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1795 - accuracy: 0.9372 - val_loss: 0.1759 - val_accuracy: 0.9441\n",
      "Epoch 113/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.1780 - accuracy: 0.9326 - val_loss: 0.1830 - val_accuracy: 0.9472\n",
      "Epoch 114/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1831 - accuracy: 0.9342 - val_loss: 0.1843 - val_accuracy: 0.9441\n",
      "Epoch 115/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1835 - accuracy: 0.9342 - val_loss: 0.1789 - val_accuracy: 0.9472\n",
      "Epoch 116/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1787 - accuracy: 0.9342 - val_loss: 0.1735 - val_accuracy: 0.9503\n",
      "Epoch 117/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.1768 - accuracy: 0.9387 - val_loss: 0.1763 - val_accuracy: 0.9503\n",
      "Epoch 118/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1820 - accuracy: 0.9357 - val_loss: 0.1737 - val_accuracy: 0.9503\n",
      "Epoch 119/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.1773 - accuracy: 0.9372 - val_loss: 0.1757 - val_accuracy: 0.9441\n",
      "Epoch 120/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1780 - accuracy: 0.9326 - val_loss: 0.1800 - val_accuracy: 0.9472\n",
      "Epoch 121/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.1793 - accuracy: 0.9342 - val_loss: 0.1730 - val_accuracy: 0.9441\n",
      "Epoch 122/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1743 - accuracy: 0.9372 - val_loss: 0.1764 - val_accuracy: 0.9472\n",
      "Epoch 123/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1842 - accuracy: 0.9342 - val_loss: 0.1740 - val_accuracy: 0.9503\n",
      "Epoch 124/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.1779 - accuracy: 0.9342 - val_loss: 0.1744 - val_accuracy: 0.9441\n",
      "Epoch 125/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1772 - accuracy: 0.9342 - val_loss: 0.1847 - val_accuracy: 0.9441\n",
      "Epoch 126/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1828 - accuracy: 0.9311 - val_loss: 0.1774 - val_accuracy: 0.9472\n",
      "Epoch 127/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1763 - accuracy: 0.9326 - val_loss: 0.1697 - val_accuracy: 0.9503\n",
      "Epoch 128/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1751 - accuracy: 0.9418 - val_loss: 0.1721 - val_accuracy: 0.9503\n",
      "Epoch 129/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1792 - accuracy: 0.9342 - val_loss: 0.1694 - val_accuracy: 0.9503\n",
      "Epoch 130/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1740 - accuracy: 0.9403 - val_loss: 0.1694 - val_accuracy: 0.9441\n",
      "Epoch 131/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1742 - accuracy: 0.9326 - val_loss: 0.1722 - val_accuracy: 0.9441\n",
      "Epoch 132/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1735 - accuracy: 0.9326 - val_loss: 0.1694 - val_accuracy: 0.9441\n",
      "Epoch 133/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1724 - accuracy: 0.9357 - val_loss: 0.1678 - val_accuracy: 0.9472\n",
      "Epoch 134/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1714 - accuracy: 0.9357 - val_loss: 0.1677 - val_accuracy: 0.9472\n",
      "Epoch 135/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1710 - accuracy: 0.9342 - val_loss: 0.1684 - val_accuracy: 0.9441\n",
      "Epoch 136/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1709 - accuracy: 0.9326 - val_loss: 0.1684 - val_accuracy: 0.9441\n",
      "Epoch 137/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1707 - accuracy: 0.9326 - val_loss: 0.1672 - val_accuracy: 0.9441\n",
      "Epoch 138/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.1701 - accuracy: 0.9326 - val_loss: 0.1667 - val_accuracy: 0.9472\n",
      "Epoch 139/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1696 - accuracy: 0.9342 - val_loss: 0.1668 - val_accuracy: 0.9441\n",
      "Epoch 140/3500\n",
      "653/653 [==============================] - 0s 81us/step - loss: 0.1692 - accuracy: 0.9311 - val_loss: 0.1673 - val_accuracy: 0.9441\n",
      "Epoch 141/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.1691 - accuracy: 0.9326 - val_loss: 0.1670 - val_accuracy: 0.9441\n",
      "Epoch 142/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1691 - accuracy: 0.9326 - val_loss: 0.1651 - val_accuracy: 0.9472\n",
      "Epoch 143/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1687 - accuracy: 0.9357 - val_loss: 0.1641 - val_accuracy: 0.9503\n",
      "Epoch 144/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.1690 - accuracy: 0.9403 - val_loss: 0.1636 - val_accuracy: 0.9472\n",
      "Epoch 145/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1680 - accuracy: 0.9403 - val_loss: 0.1638 - val_accuracy: 0.9472\n",
      "Epoch 146/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.1668 - accuracy: 0.9342 - val_loss: 0.1634 - val_accuracy: 0.9472\n",
      "Epoch 147/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1664 - accuracy: 0.9342 - val_loss: 0.1625 - val_accuracy: 0.9503\n",
      "Epoch 148/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1663 - accuracy: 0.9372 - val_loss: 0.1622 - val_accuracy: 0.9503\n",
      "Epoch 149/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1659 - accuracy: 0.9357 - val_loss: 0.1625 - val_accuracy: 0.9472\n",
      "Epoch 150/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.1652 - accuracy: 0.9342 - val_loss: 0.1621 - val_accuracy: 0.9472\n",
      "Epoch 151/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1648 - accuracy: 0.9342 - val_loss: 0.1619 - val_accuracy: 0.9472\n",
      "Epoch 152/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.1646 - accuracy: 0.9342 - val_loss: 0.1616 - val_accuracy: 0.9472\n",
      "Epoch 153/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.1642 - accuracy: 0.9357 - val_loss: 0.1620 - val_accuracy: 0.9441\n",
      "Epoch 154/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1643 - accuracy: 0.9357 - val_loss: 0.1610 - val_accuracy: 0.9503\n",
      "Epoch 155/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.1641 - accuracy: 0.9357 - val_loss: 0.1596 - val_accuracy: 0.9503\n",
      "Epoch 156/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1630 - accuracy: 0.9372 - val_loss: 0.1596 - val_accuracy: 0.9503\n",
      "Epoch 157/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1625 - accuracy: 0.9357 - val_loss: 0.1594 - val_accuracy: 0.9503\n",
      "Epoch 158/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1626 - accuracy: 0.9357 - val_loss: 0.1603 - val_accuracy: 0.9441\n",
      "Epoch 159/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1619 - accuracy: 0.9342 - val_loss: 0.1638 - val_accuracy: 0.9441\n",
      "Epoch 160/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1641 - accuracy: 0.9326 - val_loss: 0.1631 - val_accuracy: 0.9441\n",
      "Epoch 161/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1635 - accuracy: 0.9326 - val_loss: 0.1578 - val_accuracy: 0.9503\n",
      "Epoch 162/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1616 - accuracy: 0.9372 - val_loss: 0.1567 - val_accuracy: 0.9503\n",
      "Epoch 163/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.1602 - accuracy: 0.9403 - val_loss: 0.1580 - val_accuracy: 0.9503\n",
      "Epoch 164/3500\n",
      "653/653 [==============================] - 0s 64us/step - loss: 0.1601 - accuracy: 0.9357 - val_loss: 0.1586 - val_accuracy: 0.9472\n",
      "Epoch 165/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.1600 - accuracy: 0.9342 - val_loss: 0.1569 - val_accuracy: 0.9503\n",
      "Epoch 166/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1591 - accuracy: 0.9357 - val_loss: 0.1547 - val_accuracy: 0.9503\n",
      "Epoch 167/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1597 - accuracy: 0.9433 - val_loss: 0.1542 - val_accuracy: 0.9503\n",
      "Epoch 168/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.1602 - accuracy: 0.9449 - val_loss: 0.1543 - val_accuracy: 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1577 - accuracy: 0.9403 - val_loss: 0.1570 - val_accuracy: 0.9441\n",
      "Epoch 170/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1589 - accuracy: 0.9326 - val_loss: 0.1573 - val_accuracy: 0.9441\n",
      "Epoch 171/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1581 - accuracy: 0.9326 - val_loss: 0.1536 - val_accuracy: 0.9503\n",
      "Epoch 172/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1577 - accuracy: 0.9387 - val_loss: 0.1530 - val_accuracy: 0.9503\n",
      "Epoch 173/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1562 - accuracy: 0.9387 - val_loss: 0.1557 - val_accuracy: 0.9472\n",
      "Epoch 174/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1564 - accuracy: 0.9326 - val_loss: 0.1607 - val_accuracy: 0.9503\n",
      "Epoch 175/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1605 - accuracy: 0.9342 - val_loss: 0.1600 - val_accuracy: 0.9503\n",
      "Epoch 176/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.1583 - accuracy: 0.9342 - val_loss: 0.1516 - val_accuracy: 0.9503\n",
      "Epoch 177/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1547 - accuracy: 0.9433 - val_loss: 0.1518 - val_accuracy: 0.9472\n",
      "Epoch 178/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1590 - accuracy: 0.9418 - val_loss: 0.1506 - val_accuracy: 0.9503\n",
      "Epoch 179/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.1567 - accuracy: 0.9433 - val_loss: 0.1515 - val_accuracy: 0.9503\n",
      "Epoch 180/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1548 - accuracy: 0.9342 - val_loss: 0.1542 - val_accuracy: 0.9503\n",
      "Epoch 181/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1549 - accuracy: 0.9326 - val_loss: 0.1514 - val_accuracy: 0.9503\n",
      "Epoch 182/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1532 - accuracy: 0.9387 - val_loss: 0.1489 - val_accuracy: 0.9503\n",
      "Epoch 183/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1536 - accuracy: 0.9449 - val_loss: 0.1485 - val_accuracy: 0.9503\n",
      "Epoch 184/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1549 - accuracy: 0.9418 - val_loss: 0.1487 - val_accuracy: 0.9503\n",
      "Epoch 185/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1518 - accuracy: 0.9372 - val_loss: 0.1567 - val_accuracy: 0.9503\n",
      "Epoch 186/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1560 - accuracy: 0.9342 - val_loss: 0.1569 - val_accuracy: 0.9503\n",
      "Epoch 187/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.1553 - accuracy: 0.9342 - val_loss: 0.1489 - val_accuracy: 0.9534\n",
      "Epoch 188/3500\n",
      "653/653 [==============================] - 0s 48us/step - loss: 0.1507 - accuracy: 0.9433 - val_loss: 0.1471 - val_accuracy: 0.9534\n",
      "Epoch 189/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.1527 - accuracy: 0.9433 - val_loss: 0.1469 - val_accuracy: 0.9503\n",
      "Epoch 190/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1521 - accuracy: 0.9433 - val_loss: 0.1477 - val_accuracy: 0.9534\n",
      "Epoch 191/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1494 - accuracy: 0.9326 - val_loss: 0.1533 - val_accuracy: 0.9472\n",
      "Epoch 192/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1522 - accuracy: 0.9342 - val_loss: 0.1546 - val_accuracy: 0.9472\n",
      "Epoch 193/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1527 - accuracy: 0.9342 - val_loss: 0.1489 - val_accuracy: 0.9503\n",
      "Epoch 194/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1480 - accuracy: 0.9326 - val_loss: 0.1451 - val_accuracy: 0.9503\n",
      "Epoch 195/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1523 - accuracy: 0.9449 - val_loss: 0.1472 - val_accuracy: 0.9503\n",
      "Epoch 196/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.1545 - accuracy: 0.9449 - val_loss: 0.1456 - val_accuracy: 0.9534\n",
      "Epoch 197/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1462 - accuracy: 0.9342 - val_loss: 0.1590 - val_accuracy: 0.9534\n",
      "Epoch 198/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1554 - accuracy: 0.9357 - val_loss: 0.1643 - val_accuracy: 0.9503\n",
      "Epoch 199/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.1582 - accuracy: 0.9387 - val_loss: 0.1494 - val_accuracy: 0.9472\n",
      "Epoch 200/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.1495 - accuracy: 0.9372 - val_loss: 0.1439 - val_accuracy: 0.9503\n",
      "Epoch 201/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1515 - accuracy: 0.9464 - val_loss: 0.1429 - val_accuracy: 0.9503\n",
      "Epoch 202/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.1475 - accuracy: 0.9449 - val_loss: 0.1469 - val_accuracy: 0.9503\n",
      "Epoch 203/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1478 - accuracy: 0.9342 - val_loss: 0.1559 - val_accuracy: 0.9534\n",
      "Epoch 204/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1521 - accuracy: 0.9357 - val_loss: 0.1470 - val_accuracy: 0.9472\n",
      "Epoch 205/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.1474 - accuracy: 0.9372 - val_loss: 0.1408 - val_accuracy: 0.9503\n",
      "Epoch 206/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1469 - accuracy: 0.9433 - val_loss: 0.1404 - val_accuracy: 0.9503\n",
      "Epoch 207/3500\n",
      "653/653 [==============================] - 0s 33us/step - loss: 0.1465 - accuracy: 0.9418 - val_loss: 0.1414 - val_accuracy: 0.9534\n",
      "Epoch 208/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.1439 - accuracy: 0.9372 - val_loss: 0.1440 - val_accuracy: 0.9503\n",
      "Epoch 209/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1447 - accuracy: 0.9326 - val_loss: 0.1439 - val_accuracy: 0.9503\n",
      "Epoch 210/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.1443 - accuracy: 0.9326 - val_loss: 0.1406 - val_accuracy: 0.9534\n",
      "Epoch 211/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1428 - accuracy: 0.9372 - val_loss: 0.1386 - val_accuracy: 0.9534\n",
      "Epoch 212/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1432 - accuracy: 0.9418 - val_loss: 0.1382 - val_accuracy: 0.9503\n",
      "Epoch 213/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1442 - accuracy: 0.9433 - val_loss: 0.1378 - val_accuracy: 0.9503\n",
      "Epoch 214/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1432 - accuracy: 0.9433 - val_loss: 0.1385 - val_accuracy: 0.9534\n",
      "Epoch 215/3500\n",
      "653/653 [==============================] - 0s 33us/step - loss: 0.1410 - accuracy: 0.9372 - val_loss: 0.1439 - val_accuracy: 0.9472\n",
      "Epoch 216/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1437 - accuracy: 0.9357 - val_loss: 0.1455 - val_accuracy: 0.9472\n",
      "Epoch 217/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.1435 - accuracy: 0.9357 - val_loss: 0.1379 - val_accuracy: 0.9534\n",
      "Epoch 218/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1396 - accuracy: 0.9387 - val_loss: 0.1375 - val_accuracy: 0.9503\n",
      "Epoch 219/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1476 - accuracy: 0.9464 - val_loss: 0.1356 - val_accuracy: 0.9503\n",
      "Epoch 220/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1417 - accuracy: 0.9418 - val_loss: 0.1435 - val_accuracy: 0.9472\n",
      "Epoch 221/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1445 - accuracy: 0.9357 - val_loss: 0.1454 - val_accuracy: 0.9503\n",
      "Epoch 222/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1431 - accuracy: 0.9372 - val_loss: 0.1357 - val_accuracy: 0.9534\n",
      "Epoch 223/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1381 - accuracy: 0.9372 - val_loss: 0.1352 - val_accuracy: 0.9503\n",
      "Epoch 224/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1438 - accuracy: 0.9464 - val_loss: 0.1347 - val_accuracy: 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.1421 - accuracy: 0.9495 - val_loss: 0.1362 - val_accuracy: 0.9534\n",
      "Epoch 226/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1377 - accuracy: 0.9372 - val_loss: 0.1425 - val_accuracy: 0.9503\n",
      "Epoch 227/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.1407 - accuracy: 0.9372 - val_loss: 0.1407 - val_accuracy: 0.9503\n",
      "Epoch 228/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.1386 - accuracy: 0.9372 - val_loss: 0.1336 - val_accuracy: 0.9534\n",
      "Epoch 229/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.1371 - accuracy: 0.9418 - val_loss: 0.1337 - val_accuracy: 0.9503\n",
      "Epoch 230/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1420 - accuracy: 0.9464 - val_loss: 0.1320 - val_accuracy: 0.9503\n",
      "Epoch 231/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1380 - accuracy: 0.9449 - val_loss: 0.1340 - val_accuracy: 0.9534\n",
      "Epoch 232/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.1358 - accuracy: 0.9372 - val_loss: 0.1369 - val_accuracy: 0.9503\n",
      "Epoch 233/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1380 - accuracy: 0.9387 - val_loss: 0.1330 - val_accuracy: 0.9534\n",
      "Epoch 234/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1368 - accuracy: 0.9387 - val_loss: 0.1305 - val_accuracy: 0.9503\n",
      "Epoch 235/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1372 - accuracy: 0.9449 - val_loss: 0.1307 - val_accuracy: 0.9534\n",
      "Epoch 236/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1339 - accuracy: 0.9449 - val_loss: 0.1366 - val_accuracy: 0.9503\n",
      "Epoch 237/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.1374 - accuracy: 0.9387 - val_loss: 0.1372 - val_accuracy: 0.9534\n",
      "Epoch 238/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1348 - accuracy: 0.9372 - val_loss: 0.1290 - val_accuracy: 0.9534\n",
      "Epoch 239/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.1351 - accuracy: 0.9433 - val_loss: 0.1297 - val_accuracy: 0.9503\n",
      "Epoch 240/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1393 - accuracy: 0.9449 - val_loss: 0.1281 - val_accuracy: 0.9534\n",
      "Epoch 241/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1331 - accuracy: 0.9403 - val_loss: 0.1336 - val_accuracy: 0.9503\n",
      "Epoch 242/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1345 - accuracy: 0.9387 - val_loss: 0.1334 - val_accuracy: 0.9503\n",
      "Epoch 243/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1332 - accuracy: 0.9387 - val_loss: 0.1263 - val_accuracy: 0.9534\n",
      "Epoch 244/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1343 - accuracy: 0.9449 - val_loss: 0.1257 - val_accuracy: 0.9503\n",
      "Epoch 245/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1343 - accuracy: 0.9510 - val_loss: 0.1284 - val_accuracy: 0.9503\n",
      "Epoch 246/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.1319 - accuracy: 0.9403 - val_loss: 0.1404 - val_accuracy: 0.9534\n",
      "Epoch 247/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1384 - accuracy: 0.9387 - val_loss: 0.1355 - val_accuracy: 0.9503\n",
      "Epoch 248/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1341 - accuracy: 0.9372 - val_loss: 0.1251 - val_accuracy: 0.9503\n",
      "Epoch 249/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1307 - accuracy: 0.9433 - val_loss: 0.1251 - val_accuracy: 0.9503\n",
      "Epoch 250/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1345 - accuracy: 0.9510 - val_loss: 0.1244 - val_accuracy: 0.9503\n",
      "Epoch 251/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1312 - accuracy: 0.9433 - val_loss: 0.1282 - val_accuracy: 0.9503\n",
      "Epoch 252/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1299 - accuracy: 0.9403 - val_loss: 0.1279 - val_accuracy: 0.9503\n",
      "Epoch 253/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.1295 - accuracy: 0.9403 - val_loss: 0.1242 - val_accuracy: 0.9534\n",
      "Epoch 254/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1288 - accuracy: 0.9433 - val_loss: 0.1226 - val_accuracy: 0.9503\n",
      "Epoch 255/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1298 - accuracy: 0.9479 - val_loss: 0.1227 - val_accuracy: 0.9503\n",
      "Epoch 256/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1288 - accuracy: 0.9433 - val_loss: 0.1236 - val_accuracy: 0.9534\n",
      "Epoch 257/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1277 - accuracy: 0.9449 - val_loss: 0.1242 - val_accuracy: 0.9534\n",
      "Epoch 258/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1289 - accuracy: 0.9387 - val_loss: 0.1230 - val_accuracy: 0.9534\n",
      "Epoch 259/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1267 - accuracy: 0.9449 - val_loss: 0.1209 - val_accuracy: 0.9503\n",
      "Epoch 260/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1306 - accuracy: 0.9479 - val_loss: 0.1210 - val_accuracy: 0.9503\n",
      "Epoch 261/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1279 - accuracy: 0.9464 - val_loss: 0.1277 - val_accuracy: 0.9565\n",
      "Epoch 262/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1286 - accuracy: 0.9387 - val_loss: 0.1266 - val_accuracy: 0.9565\n",
      "Epoch 263/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1274 - accuracy: 0.9372 - val_loss: 0.1207 - val_accuracy: 0.9534\n",
      "Epoch 264/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1257 - accuracy: 0.9449 - val_loss: 0.1192 - val_accuracy: 0.9503\n",
      "Epoch 265/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1271 - accuracy: 0.9479 - val_loss: 0.1195 - val_accuracy: 0.9534\n",
      "Epoch 266/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1254 - accuracy: 0.9464 - val_loss: 0.1230 - val_accuracy: 0.9534\n",
      "Epoch 267/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.1267 - accuracy: 0.9403 - val_loss: 0.1237 - val_accuracy: 0.9503\n",
      "Epoch 268/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1252 - accuracy: 0.9403 - val_loss: 0.1199 - val_accuracy: 0.9503\n",
      "Epoch 269/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1256 - accuracy: 0.9479 - val_loss: 0.1198 - val_accuracy: 0.9534\n",
      "Epoch 270/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1248 - accuracy: 0.9449 - val_loss: 0.1223 - val_accuracy: 0.9534\n",
      "Epoch 271/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1241 - accuracy: 0.9403 - val_loss: 0.1206 - val_accuracy: 0.9534\n",
      "Epoch 272/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.1238 - accuracy: 0.9433 - val_loss: 0.1185 - val_accuracy: 0.9534\n",
      "Epoch 273/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1234 - accuracy: 0.9433 - val_loss: 0.1187 - val_accuracy: 0.9534\n",
      "Epoch 274/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.1226 - accuracy: 0.9449 - val_loss: 0.1193 - val_accuracy: 0.9534\n",
      "Epoch 275/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1228 - accuracy: 0.9449 - val_loss: 0.1192 - val_accuracy: 0.9534\n",
      "Epoch 276/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1218 - accuracy: 0.9449 - val_loss: 0.1169 - val_accuracy: 0.9534\n",
      "Epoch 277/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.1224 - accuracy: 0.9449 - val_loss: 0.1165 - val_accuracy: 0.9534\n",
      "Epoch 278/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.1220 - accuracy: 0.9433 - val_loss: 0.1184 - val_accuracy: 0.9534\n",
      "Epoch 279/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1211 - accuracy: 0.9464 - val_loss: 0.1198 - val_accuracy: 0.9534\n",
      "Epoch 280/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1213 - accuracy: 0.9403 - val_loss: 0.1201 - val_accuracy: 0.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1209 - accuracy: 0.9403 - val_loss: 0.1166 - val_accuracy: 0.9534\n",
      "Epoch 282/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1218 - accuracy: 0.9495 - val_loss: 0.1161 - val_accuracy: 0.9534\n",
      "Epoch 283/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1202 - accuracy: 0.9449 - val_loss: 0.1203 - val_accuracy: 0.9534\n",
      "Epoch 284/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1206 - accuracy: 0.9403 - val_loss: 0.1210 - val_accuracy: 0.9534\n",
      "Epoch 285/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1209 - accuracy: 0.9403 - val_loss: 0.1172 - val_accuracy: 0.9534\n",
      "Epoch 286/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1190 - accuracy: 0.9418 - val_loss: 0.1139 - val_accuracy: 0.9534\n",
      "Epoch 287/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1203 - accuracy: 0.9464 - val_loss: 0.1136 - val_accuracy: 0.9534\n",
      "Epoch 288/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1208 - accuracy: 0.9495 - val_loss: 0.1168 - val_accuracy: 0.9565\n",
      "Epoch 289/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.1187 - accuracy: 0.9449 - val_loss: 0.1284 - val_accuracy: 0.9503\n",
      "Epoch 290/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1256 - accuracy: 0.9387 - val_loss: 0.1245 - val_accuracy: 0.9534\n",
      "Epoch 291/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.1219 - accuracy: 0.9403 - val_loss: 0.1144 - val_accuracy: 0.9534\n",
      "Epoch 292/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1173 - accuracy: 0.9449 - val_loss: 0.1131 - val_accuracy: 0.9596\n",
      "Epoch 293/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1209 - accuracy: 0.9495 - val_loss: 0.1127 - val_accuracy: 0.9503\n",
      "Epoch 294/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.1164 - accuracy: 0.9479 - val_loss: 0.1201 - val_accuracy: 0.9565\n",
      "Epoch 295/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.1193 - accuracy: 0.9418 - val_loss: 0.1272 - val_accuracy: 0.9503\n",
      "Epoch 296/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1236 - accuracy: 0.9403 - val_loss: 0.1190 - val_accuracy: 0.9534\n",
      "Epoch 297/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1186 - accuracy: 0.9433 - val_loss: 0.1120 - val_accuracy: 0.9503\n",
      "Epoch 298/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1166 - accuracy: 0.9510 - val_loss: 0.1113 - val_accuracy: 0.9534\n",
      "Epoch 299/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.1162 - accuracy: 0.9510 - val_loss: 0.1135 - val_accuracy: 0.9534\n",
      "Epoch 300/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1156 - accuracy: 0.9433 - val_loss: 0.1164 - val_accuracy: 0.9565\n",
      "Epoch 301/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1166 - accuracy: 0.9403 - val_loss: 0.1135 - val_accuracy: 0.9565\n",
      "Epoch 302/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1153 - accuracy: 0.9418 - val_loss: 0.1112 - val_accuracy: 0.9534\n",
      "Epoch 303/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1145 - accuracy: 0.9479 - val_loss: 0.1098 - val_accuracy: 0.9534\n",
      "Epoch 304/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.1147 - accuracy: 0.9479 - val_loss: 0.1097 - val_accuracy: 0.9534\n",
      "Epoch 305/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1139 - accuracy: 0.9479 - val_loss: 0.1122 - val_accuracy: 0.9565\n",
      "Epoch 306/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1142 - accuracy: 0.9479 - val_loss: 0.1129 - val_accuracy: 0.9565\n",
      "Epoch 307/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1144 - accuracy: 0.9464 - val_loss: 0.1094 - val_accuracy: 0.9534\n",
      "Epoch 308/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1129 - accuracy: 0.9510 - val_loss: 0.1080 - val_accuracy: 0.9596\n",
      "Epoch 309/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1168 - accuracy: 0.9525 - val_loss: 0.1082 - val_accuracy: 0.9534\n",
      "Epoch 310/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1131 - accuracy: 0.9510 - val_loss: 0.1161 - val_accuracy: 0.9565\n",
      "Epoch 311/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.1152 - accuracy: 0.9418 - val_loss: 0.1172 - val_accuracy: 0.9565\n",
      "Epoch 312/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1154 - accuracy: 0.9403 - val_loss: 0.1108 - val_accuracy: 0.9565\n",
      "Epoch 313/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.1127 - accuracy: 0.9479 - val_loss: 0.1070 - val_accuracy: 0.9596\n",
      "Epoch 314/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.1129 - accuracy: 0.9495 - val_loss: 0.1075 - val_accuracy: 0.9534\n",
      "Epoch 315/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1111 - accuracy: 0.9495 - val_loss: 0.1126 - val_accuracy: 0.9565\n",
      "Epoch 316/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1133 - accuracy: 0.9418 - val_loss: 0.1147 - val_accuracy: 0.9565\n",
      "Epoch 317/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9433 - val_loss: 0.1083 - val_accuracy: 0.9534\n",
      "Epoch 318/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.1112 - accuracy: 0.9479 - val_loss: 0.1073 - val_accuracy: 0.9596\n",
      "Epoch 319/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.1113 - accuracy: 0.9495 - val_loss: 0.1078 - val_accuracy: 0.9534\n",
      "Epoch 320/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1106 - accuracy: 0.9495 - val_loss: 0.1078 - val_accuracy: 0.9534\n",
      "Epoch 321/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.1098 - accuracy: 0.9464 - val_loss: 0.1101 - val_accuracy: 0.9565\n",
      "Epoch 322/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1102 - accuracy: 0.9433 - val_loss: 0.1067 - val_accuracy: 0.9534\n",
      "Epoch 323/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.1088 - accuracy: 0.9495 - val_loss: 0.1043 - val_accuracy: 0.9596\n",
      "Epoch 324/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.1111 - accuracy: 0.9525 - val_loss: 0.1051 - val_accuracy: 0.9596\n",
      "Epoch 325/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1110 - accuracy: 0.9495 - val_loss: 0.1093 - val_accuracy: 0.9565\n",
      "Epoch 326/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1099 - accuracy: 0.9449 - val_loss: 0.1065 - val_accuracy: 0.9565\n",
      "Epoch 327/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.1083 - accuracy: 0.9495 - val_loss: 0.1067 - val_accuracy: 0.9565\n",
      "Epoch 328/3500\n",
      "653/653 [==============================] - 0s 98us/step - loss: 0.1081 - accuracy: 0.9464 - val_loss: 0.1080 - val_accuracy: 0.9565\n",
      "Epoch 329/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.1086 - accuracy: 0.9449 - val_loss: 0.1064 - val_accuracy: 0.9565\n",
      "Epoch 330/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1074 - accuracy: 0.9464 - val_loss: 0.1028 - val_accuracy: 0.9596\n",
      "Epoch 331/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1085 - accuracy: 0.9556 - val_loss: 0.1025 - val_accuracy: 0.9627\n",
      "Epoch 332/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1085 - accuracy: 0.9556 - val_loss: 0.1044 - val_accuracy: 0.9596\n",
      "Epoch 333/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.1065 - accuracy: 0.9495 - val_loss: 0.1089 - val_accuracy: 0.9565\n",
      "Epoch 334/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1078 - accuracy: 0.9433 - val_loss: 0.1082 - val_accuracy: 0.9565\n",
      "Epoch 335/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.1074 - accuracy: 0.9464 - val_loss: 0.1048 - val_accuracy: 0.9627\n",
      "Epoch 336/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1061 - accuracy: 0.9495 - val_loss: 0.1026 - val_accuracy: 0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1065 - accuracy: 0.9525 - val_loss: 0.1030 - val_accuracy: 0.9627\n",
      "Epoch 338/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1117 - accuracy: 0.9587 - val_loss: 0.1021 - val_accuracy: 0.9627\n",
      "Epoch 339/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1078 - accuracy: 0.9571 - val_loss: 0.1056 - val_accuracy: 0.9565\n",
      "Epoch 340/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1066 - accuracy: 0.9479 - val_loss: 0.1107 - val_accuracy: 0.9534\n",
      "Epoch 341/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1076 - accuracy: 0.9433 - val_loss: 0.1031 - val_accuracy: 0.9627\n",
      "Epoch 342/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.1042 - accuracy: 0.9525 - val_loss: 0.1006 - val_accuracy: 0.9627\n",
      "Epoch 343/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1077 - accuracy: 0.9587 - val_loss: 0.1006 - val_accuracy: 0.9627\n",
      "Epoch 344/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.1044 - accuracy: 0.9510 - val_loss: 0.1074 - val_accuracy: 0.9565\n",
      "Epoch 345/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.1064 - accuracy: 0.9449 - val_loss: 0.1054 - val_accuracy: 0.9565\n",
      "Epoch 346/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.1042 - accuracy: 0.9464 - val_loss: 0.0979 - val_accuracy: 0.9627\n",
      "Epoch 347/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1060 - accuracy: 0.9571 - val_loss: 0.0972 - val_accuracy: 0.9627\n",
      "Epoch 348/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1063 - accuracy: 0.9541 - val_loss: 0.1006 - val_accuracy: 0.9627\n",
      "Epoch 349/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1038 - accuracy: 0.9479 - val_loss: 0.1023 - val_accuracy: 0.9565\n",
      "Epoch 350/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1034 - accuracy: 0.9495 - val_loss: 0.0980 - val_accuracy: 0.9627\n",
      "Epoch 351/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1029 - accuracy: 0.9571 - val_loss: 0.0970 - val_accuracy: 0.9627\n",
      "Epoch 352/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1035 - accuracy: 0.9571 - val_loss: 0.0985 - val_accuracy: 0.9658\n",
      "Epoch 353/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.1018 - accuracy: 0.9587 - val_loss: 0.1022 - val_accuracy: 0.9565\n",
      "Epoch 354/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1033 - accuracy: 0.9495 - val_loss: 0.1016 - val_accuracy: 0.9596\n",
      "Epoch 355/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1018 - accuracy: 0.9525 - val_loss: 0.0972 - val_accuracy: 0.9627\n",
      "Epoch 356/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1025 - accuracy: 0.9571 - val_loss: 0.0972 - val_accuracy: 0.9627\n",
      "Epoch 357/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1027 - accuracy: 0.9602 - val_loss: 0.0994 - val_accuracy: 0.9658\n",
      "Epoch 358/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1015 - accuracy: 0.9525 - val_loss: 0.1004 - val_accuracy: 0.9627\n",
      "Epoch 359/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.1006 - accuracy: 0.9525 - val_loss: 0.0974 - val_accuracy: 0.9627\n",
      "Epoch 360/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1010 - accuracy: 0.9556 - val_loss: 0.0968 - val_accuracy: 0.9627\n",
      "Epoch 361/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.1021 - accuracy: 0.9617 - val_loss: 0.0993 - val_accuracy: 0.9658\n",
      "Epoch 362/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0994 - accuracy: 0.9587 - val_loss: 0.1085 - val_accuracy: 0.9534\n",
      "Epoch 363/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.1045 - accuracy: 0.9449 - val_loss: 0.1079 - val_accuracy: 0.9565\n",
      "Epoch 364/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.1034 - accuracy: 0.9449 - val_loss: 0.0997 - val_accuracy: 0.9596\n",
      "Epoch 365/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0989 - accuracy: 0.9571 - val_loss: 0.0960 - val_accuracy: 0.9627\n",
      "Epoch 366/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.1017 - accuracy: 0.9617 - val_loss: 0.0962 - val_accuracy: 0.9627\n",
      "Epoch 367/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0992 - accuracy: 0.9587 - val_loss: 0.1025 - val_accuracy: 0.9596\n",
      "Epoch 368/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1005 - accuracy: 0.9449 - val_loss: 0.1047 - val_accuracy: 0.9565\n",
      "Epoch 369/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.1021 - accuracy: 0.9464 - val_loss: 0.0981 - val_accuracy: 0.9596\n",
      "Epoch 370/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0979 - accuracy: 0.9602 - val_loss: 0.0961 - val_accuracy: 0.9689\n",
      "Epoch 371/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0981 - accuracy: 0.9617 - val_loss: 0.0959 - val_accuracy: 0.9689\n",
      "Epoch 372/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0975 - accuracy: 0.9602 - val_loss: 0.0986 - val_accuracy: 0.9596\n",
      "Epoch 373/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0977 - accuracy: 0.9556 - val_loss: 0.1003 - val_accuracy: 0.9627\n",
      "Epoch 374/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0984 - accuracy: 0.9525 - val_loss: 0.0974 - val_accuracy: 0.9596\n",
      "Epoch 375/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0964 - accuracy: 0.9602 - val_loss: 0.0940 - val_accuracy: 0.9627\n",
      "Epoch 376/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0990 - accuracy: 0.9663 - val_loss: 0.0938 - val_accuracy: 0.9627\n",
      "Epoch 377/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0996 - accuracy: 0.9617 - val_loss: 0.0954 - val_accuracy: 0.9658\n",
      "Epoch 378/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0964 - accuracy: 0.9617 - val_loss: 0.0969 - val_accuracy: 0.9627\n",
      "Epoch 379/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0963 - accuracy: 0.9587 - val_loss: 0.0951 - val_accuracy: 0.9658\n",
      "Epoch 380/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0966 - accuracy: 0.9602 - val_loss: 0.0943 - val_accuracy: 0.9658\n",
      "Epoch 381/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0955 - accuracy: 0.9602 - val_loss: 0.0969 - val_accuracy: 0.9627\n",
      "Epoch 382/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0965 - accuracy: 0.9556 - val_loss: 0.0939 - val_accuracy: 0.9627\n",
      "Epoch 383/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0963 - accuracy: 0.9602 - val_loss: 0.0912 - val_accuracy: 0.9689\n",
      "Epoch 384/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0961 - accuracy: 0.9602 - val_loss: 0.0921 - val_accuracy: 0.9689\n",
      "Epoch 385/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0948 - accuracy: 0.9602 - val_loss: 0.0929 - val_accuracy: 0.9627\n",
      "Epoch 386/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0946 - accuracy: 0.9602 - val_loss: 0.0942 - val_accuracy: 0.9596\n",
      "Epoch 387/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0949 - accuracy: 0.9602 - val_loss: 0.0908 - val_accuracy: 0.9689\n",
      "Epoch 388/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0958 - accuracy: 0.9617 - val_loss: 0.0901 - val_accuracy: 0.9689\n",
      "Epoch 389/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0940 - accuracy: 0.9617 - val_loss: 0.0958 - val_accuracy: 0.9596\n",
      "Epoch 390/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0962 - accuracy: 0.9556 - val_loss: 0.0948 - val_accuracy: 0.9596\n",
      "Epoch 391/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0955 - accuracy: 0.9587 - val_loss: 0.0896 - val_accuracy: 0.9689\n",
      "Epoch 392/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0944 - accuracy: 0.9617 - val_loss: 0.0904 - val_accuracy: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0938 - accuracy: 0.9617 - val_loss: 0.0937 - val_accuracy: 0.9658\n",
      "Epoch 394/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0933 - accuracy: 0.9602 - val_loss: 0.0918 - val_accuracy: 0.9658\n",
      "Epoch 395/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0932 - accuracy: 0.9617 - val_loss: 0.0917 - val_accuracy: 0.9658\n",
      "Epoch 396/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0928 - accuracy: 0.9632 - val_loss: 0.0937 - val_accuracy: 0.9689\n",
      "Epoch 397/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0928 - accuracy: 0.9587 - val_loss: 0.0928 - val_accuracy: 0.9689\n",
      "Epoch 398/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0925 - accuracy: 0.9617 - val_loss: 0.0910 - val_accuracy: 0.9658\n",
      "Epoch 399/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0921 - accuracy: 0.9648 - val_loss: 0.0898 - val_accuracy: 0.9658\n",
      "Epoch 400/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0918 - accuracy: 0.9648 - val_loss: 0.0889 - val_accuracy: 0.9658\n",
      "Epoch 401/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0920 - accuracy: 0.9632 - val_loss: 0.0889 - val_accuracy: 0.9658\n",
      "Epoch 402/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0915 - accuracy: 0.9617 - val_loss: 0.0887 - val_accuracy: 0.9658\n",
      "Epoch 403/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0913 - accuracy: 0.9632 - val_loss: 0.0895 - val_accuracy: 0.9658\n",
      "Epoch 404/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.0894 - val_accuracy: 0.9658\n",
      "Epoch 405/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0909 - accuracy: 0.9632 - val_loss: 0.0881 - val_accuracy: 0.9596\n",
      "Epoch 406/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0917 - accuracy: 0.9678 - val_loss: 0.0896 - val_accuracy: 0.9658\n",
      "Epoch 407/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0907 - accuracy: 0.9648 - val_loss: 0.0914 - val_accuracy: 0.9689\n",
      "Epoch 408/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0901 - accuracy: 0.9648 - val_loss: 0.0904 - val_accuracy: 0.9658\n",
      "Epoch 409/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0901 - accuracy: 0.9663 - val_loss: 0.0920 - val_accuracy: 0.9689\n",
      "Epoch 410/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0900 - accuracy: 0.9617 - val_loss: 0.0936 - val_accuracy: 0.9689\n",
      "Epoch 411/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0896 - accuracy: 0.9602 - val_loss: 0.0889 - val_accuracy: 0.9658\n",
      "Epoch 412/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0891 - accuracy: 0.9648 - val_loss: 0.0875 - val_accuracy: 0.9596\n",
      "Epoch 413/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0920 - accuracy: 0.9632 - val_loss: 0.0889 - val_accuracy: 0.9658\n",
      "Epoch 414/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0876 - accuracy: 0.9632 - val_loss: 0.1002 - val_accuracy: 0.9596\n",
      "Epoch 415/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0939 - accuracy: 0.9556 - val_loss: 0.0942 - val_accuracy: 0.9627\n",
      "Epoch 416/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0890 - accuracy: 0.9632 - val_loss: 0.0863 - val_accuracy: 0.9596\n",
      "Epoch 417/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0917 - accuracy: 0.9617 - val_loss: 0.0865 - val_accuracy: 0.9627\n",
      "Epoch 418/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0902 - accuracy: 0.9602 - val_loss: 0.0920 - val_accuracy: 0.9658\n",
      "Epoch 419/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0867 - accuracy: 0.9617 - val_loss: 0.0891 - val_accuracy: 0.9658\n",
      "Epoch 420/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0877 - accuracy: 0.9678 - val_loss: 0.0894 - val_accuracy: 0.9627\n",
      "Epoch 421/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0878 - accuracy: 0.9678 - val_loss: 0.0937 - val_accuracy: 0.9658\n",
      "Epoch 422/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0862 - accuracy: 0.9678 - val_loss: 0.0926 - val_accuracy: 0.9658\n",
      "Epoch 423/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0858 - accuracy: 0.9709 - val_loss: 0.0922 - val_accuracy: 0.9658\n",
      "Epoch 424/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0857 - accuracy: 0.9694 - val_loss: 0.0906 - val_accuracy: 0.9658\n",
      "Epoch 425/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0855 - accuracy: 0.9724 - val_loss: 0.0893 - val_accuracy: 0.9689\n",
      "Epoch 426/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0843 - accuracy: 0.9709 - val_loss: 0.0931 - val_accuracy: 0.9658\n",
      "Epoch 427/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0852 - accuracy: 0.9648 - val_loss: 0.0957 - val_accuracy: 0.9658\n",
      "Epoch 428/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0869 - accuracy: 0.9602 - val_loss: 0.0885 - val_accuracy: 0.9689\n",
      "Epoch 429/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0827 - accuracy: 0.9694 - val_loss: 0.0874 - val_accuracy: 0.9720\n",
      "Epoch 430/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0905 - accuracy: 0.9663 - val_loss: 0.0870 - val_accuracy: 0.9658\n",
      "Epoch 431/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.1011 - val_accuracy: 0.9596\n",
      "Epoch 432/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0886 - accuracy: 0.9571 - val_loss: 0.0966 - val_accuracy: 0.9596\n",
      "Epoch 433/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0869 - accuracy: 0.9648 - val_loss: 0.0861 - val_accuracy: 0.9658\n",
      "Epoch 434/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0823 - accuracy: 0.9740 - val_loss: 0.0846 - val_accuracy: 0.9658\n",
      "Epoch 435/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0827 - accuracy: 0.9724 - val_loss: 0.0852 - val_accuracy: 0.9658\n",
      "Epoch 436/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0815 - accuracy: 0.9709 - val_loss: 0.0888 - val_accuracy: 0.9658\n",
      "Epoch 437/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0818 - accuracy: 0.9694 - val_loss: 0.0875 - val_accuracy: 0.9658\n",
      "Epoch 438/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0812 - accuracy: 0.9709 - val_loss: 0.0844 - val_accuracy: 0.9658\n",
      "Epoch 439/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0808 - accuracy: 0.9709 - val_loss: 0.0844 - val_accuracy: 0.9658\n",
      "Epoch 440/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0805 - accuracy: 0.9724 - val_loss: 0.0866 - val_accuracy: 0.9658\n",
      "Epoch 441/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0797 - accuracy: 0.9724 - val_loss: 0.0923 - val_accuracy: 0.9658\n",
      "Epoch 442/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0820 - accuracy: 0.9663 - val_loss: 0.0877 - val_accuracy: 0.9658\n",
      "Epoch 443/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0800 - accuracy: 0.9724 - val_loss: 0.0835 - val_accuracy: 0.9720\n",
      "Epoch 444/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0806 - accuracy: 0.9755 - val_loss: 0.0865 - val_accuracy: 0.9658\n",
      "Epoch 445/3500\n",
      "653/653 [==============================] - 0s 64us/step - loss: 0.0794 - accuracy: 0.9755 - val_loss: 0.0909 - val_accuracy: 0.9658\n",
      "Epoch 446/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0797 - accuracy: 0.9709 - val_loss: 0.0846 - val_accuracy: 0.9689\n",
      "Epoch 447/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0796 - accuracy: 0.9709 - val_loss: 0.0834 - val_accuracy: 0.9689\n",
      "Epoch 448/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0813 - accuracy: 0.9678 - val_loss: 0.0867 - val_accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0783 - accuracy: 0.9694 - val_loss: 0.0909 - val_accuracy: 0.9658\n",
      "Epoch 450/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0794 - accuracy: 0.9694 - val_loss: 0.0834 - val_accuracy: 0.9689\n",
      "Epoch 451/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.0806 - val_accuracy: 0.9720\n",
      "Epoch 452/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0783 - accuracy: 0.9724 - val_loss: 0.0850 - val_accuracy: 0.9658\n",
      "Epoch 453/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0794 - accuracy: 0.9678 - val_loss: 0.0868 - val_accuracy: 0.9658\n",
      "Epoch 454/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0794 - accuracy: 0.9724 - val_loss: 0.0810 - val_accuracy: 0.9720\n",
      "Epoch 455/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0770 - accuracy: 0.9755 - val_loss: 0.0825 - val_accuracy: 0.9720\n",
      "Epoch 456/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0758 - accuracy: 0.9770 - val_loss: 0.0857 - val_accuracy: 0.9689\n",
      "Epoch 457/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 0.0834 - val_accuracy: 0.9689\n",
      "Epoch 458/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0765 - accuracy: 0.9724 - val_loss: 0.0816 - val_accuracy: 0.9658\n",
      "Epoch 459/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0766 - accuracy: 0.9724 - val_loss: 0.0842 - val_accuracy: 0.9689\n",
      "Epoch 460/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0759 - accuracy: 0.9724 - val_loss: 0.0843 - val_accuracy: 0.9689\n",
      "Epoch 461/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0753 - accuracy: 0.9740 - val_loss: 0.0814 - val_accuracy: 0.9720\n",
      "Epoch 462/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0745 - accuracy: 0.9755 - val_loss: 0.0836 - val_accuracy: 0.9689\n",
      "Epoch 463/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0753 - accuracy: 0.9724 - val_loss: 0.0838 - val_accuracy: 0.9689\n",
      "Epoch 464/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 0.0794 - val_accuracy: 0.9720\n",
      "Epoch 465/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.0801 - val_accuracy: 0.9720\n",
      "Epoch 466/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0738 - accuracy: 0.9755 - val_loss: 0.0779 - val_accuracy: 0.9720\n",
      "Epoch 467/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.0773 - val_accuracy: 0.9752\n",
      "Epoch 468/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0736 - accuracy: 0.9740 - val_loss: 0.0775 - val_accuracy: 0.9752\n",
      "Epoch 469/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0733 - accuracy: 0.9755 - val_loss: 0.0808 - val_accuracy: 0.9689\n",
      "Epoch 470/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0730 - accuracy: 0.9709 - val_loss: 0.0840 - val_accuracy: 0.9689\n",
      "Epoch 471/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0728 - accuracy: 0.9709 - val_loss: 0.0766 - val_accuracy: 0.9752\n",
      "Epoch 472/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.0755 - val_accuracy: 0.9689\n",
      "Epoch 473/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0707 - accuracy: 0.9740 - val_loss: 0.0799 - val_accuracy: 0.9720\n",
      "Epoch 474/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0709 - accuracy: 0.9755 - val_loss: 0.0765 - val_accuracy: 0.9720\n",
      "Epoch 475/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0702 - accuracy: 0.9740 - val_loss: 0.0729 - val_accuracy: 0.9720\n",
      "Epoch 476/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.0816 - val_accuracy: 0.9720\n",
      "Epoch 477/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0704 - accuracy: 0.9755 - val_loss: 0.0762 - val_accuracy: 0.9689\n",
      "Epoch 478/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0670 - accuracy: 0.9770 - val_loss: 0.0722 - val_accuracy: 0.9689\n",
      "Epoch 479/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0701 - accuracy: 0.9755 - val_loss: 0.0782 - val_accuracy: 0.9720\n",
      "Epoch 480/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0666 - accuracy: 0.9770 - val_loss: 0.0887 - val_accuracy: 0.9689\n",
      "Epoch 481/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 0.0774 - val_accuracy: 0.9752\n",
      "Epoch 482/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0665 - accuracy: 0.9801 - val_loss: 0.0742 - val_accuracy: 0.9752\n",
      "Epoch 483/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0675 - accuracy: 0.9786 - val_loss: 0.0803 - val_accuracy: 0.9720\n",
      "Epoch 484/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0677 - accuracy: 0.9801 - val_loss: 0.0788 - val_accuracy: 0.9752\n",
      "Epoch 485/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0651 - accuracy: 0.9786 - val_loss: 0.0744 - val_accuracy: 0.9689\n",
      "Epoch 486/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0690 - accuracy: 0.9740 - val_loss: 0.0796 - val_accuracy: 0.9720\n",
      "Epoch 487/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0664 - accuracy: 0.9755 - val_loss: 0.0812 - val_accuracy: 0.9720\n",
      "Epoch 488/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0649 - accuracy: 0.9801 - val_loss: 0.0724 - val_accuracy: 0.9752\n",
      "Epoch 489/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0649 - accuracy: 0.9801 - val_loss: 0.0735 - val_accuracy: 0.9720\n",
      "Epoch 490/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0627 - accuracy: 0.9801 - val_loss: 0.0765 - val_accuracy: 0.9720\n",
      "Epoch 491/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0627 - accuracy: 0.9816 - val_loss: 0.0743 - val_accuracy: 0.9752\n",
      "Epoch 492/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0624 - accuracy: 0.9801 - val_loss: 0.0718 - val_accuracy: 0.9720\n",
      "Epoch 493/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.0710 - val_accuracy: 0.9720\n",
      "Epoch 494/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.0727 - val_accuracy: 0.9720\n",
      "Epoch 495/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0616 - accuracy: 0.9816 - val_loss: 0.0749 - val_accuracy: 0.9720\n",
      "Epoch 496/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0626 - accuracy: 0.9832 - val_loss: 0.0731 - val_accuracy: 0.9720\n",
      "Epoch 497/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0618 - accuracy: 0.9816 - val_loss: 0.0708 - val_accuracy: 0.9720\n",
      "Epoch 498/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.0671 - val_accuracy: 0.9752\n",
      "Epoch 499/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0630 - accuracy: 0.9801 - val_loss: 0.0705 - val_accuracy: 0.9720\n",
      "Epoch 500/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0602 - accuracy: 0.9801 - val_loss: 0.0800 - val_accuracy: 0.9720\n",
      "Epoch 501/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0617 - accuracy: 0.9832 - val_loss: 0.0796 - val_accuracy: 0.9720\n",
      "Epoch 502/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0604 - accuracy: 0.9832 - val_loss: 0.0703 - val_accuracy: 0.9752\n",
      "Epoch 503/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0638 - accuracy: 0.9755 - val_loss: 0.0714 - val_accuracy: 0.9752\n",
      "Epoch 504/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0636 - accuracy: 0.9816 - val_loss: 0.0815 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0733 - val_accuracy: 0.9720\n",
      "Epoch 506/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0591 - accuracy: 0.9832 - val_loss: 0.0723 - val_accuracy: 0.9720\n",
      "Epoch 507/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.0738 - val_accuracy: 0.9720\n",
      "Epoch 508/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 0.0772 - val_accuracy: 0.9720\n",
      "Epoch 509/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0611 - accuracy: 0.9801 - val_loss: 0.0724 - val_accuracy: 0.9720\n",
      "Epoch 510/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.0664 - val_accuracy: 0.9752\n",
      "Epoch 511/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0608 - accuracy: 0.9801 - val_loss: 0.0721 - val_accuracy: 0.9720\n",
      "Epoch 512/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.0714 - val_accuracy: 0.9720\n",
      "Epoch 513/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0576 - accuracy: 0.9832 - val_loss: 0.0672 - val_accuracy: 0.9752\n",
      "Epoch 514/3500\n",
      "653/653 [==============================] - 0s 56us/step - loss: 0.0591 - accuracy: 0.9816 - val_loss: 0.0717 - val_accuracy: 0.9720\n",
      "Epoch 515/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0571 - accuracy: 0.9832 - val_loss: 0.0811 - val_accuracy: 0.9720\n",
      "Epoch 516/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 0.0734 - val_accuracy: 0.9720\n",
      "Epoch 517/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0658 - val_accuracy: 0.9752\n",
      "Epoch 518/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0599 - accuracy: 0.9770 - val_loss: 0.0658 - val_accuracy: 0.9783\n",
      "Epoch 519/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.0767 - val_accuracy: 0.9720\n",
      "Epoch 520/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0605 - accuracy: 0.9801 - val_loss: 0.0807 - val_accuracy: 0.9720\n",
      "Epoch 521/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0653 - val_accuracy: 0.9783\n",
      "Epoch 522/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0656 - accuracy: 0.9755 - val_loss: 0.0678 - val_accuracy: 0.9752\n",
      "Epoch 523/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0552 - accuracy: 0.9847 - val_loss: 0.0935 - val_accuracy: 0.9720\n",
      "Epoch 524/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0674 - accuracy: 0.9770 - val_loss: 0.0790 - val_accuracy: 0.9720\n",
      "Epoch 525/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0561 - accuracy: 0.9801 - val_loss: 0.0637 - val_accuracy: 0.9783\n",
      "Epoch 526/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0656 - accuracy: 0.9709 - val_loss: 0.0683 - val_accuracy: 0.9720\n",
      "Epoch 527/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.0952 - val_accuracy: 0.9658\n",
      "Epoch 528/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0689 - accuracy: 0.9740 - val_loss: 0.0682 - val_accuracy: 0.9720\n",
      "Epoch 529/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0558 - accuracy: 0.9801 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 530/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0652 - accuracy: 0.9709 - val_loss: 0.0686 - val_accuracy: 0.9720\n",
      "Epoch 531/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.0846 - val_accuracy: 0.9689\n",
      "Epoch 532/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0629 - accuracy: 0.9786 - val_loss: 0.0676 - val_accuracy: 0.9720\n",
      "Epoch 533/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0604 - val_accuracy: 0.9783\n",
      "Epoch 534/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0592 - accuracy: 0.9786 - val_loss: 0.0671 - val_accuracy: 0.9720\n",
      "Epoch 535/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.0884 - val_accuracy: 0.9689\n",
      "Epoch 536/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0641 - accuracy: 0.9755 - val_loss: 0.0692 - val_accuracy: 0.9720\n",
      "Epoch 537/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0547 - accuracy: 0.9786 - val_loss: 0.0596 - val_accuracy: 0.9783\n",
      "Epoch 538/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0595 - accuracy: 0.9740 - val_loss: 0.0646 - val_accuracy: 0.9752\n",
      "Epoch 539/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0550 - accuracy: 0.9832 - val_loss: 0.0680 - val_accuracy: 0.9720\n",
      "Epoch 540/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0525 - accuracy: 0.9847 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 541/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0587 - accuracy: 0.9801 - val_loss: 0.0701 - val_accuracy: 0.9720\n",
      "Epoch 542/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0554 - accuracy: 0.9847 - val_loss: 0.0965 - val_accuracy: 0.9689\n",
      "Epoch 543/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0678 - accuracy: 0.9740 - val_loss: 0.0660 - val_accuracy: 0.9720\n",
      "Epoch 544/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0508 - accuracy: 0.9862 - val_loss: 0.0637 - val_accuracy: 0.9783\n",
      "Epoch 545/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0732 - accuracy: 0.9694 - val_loss: 0.0653 - val_accuracy: 0.9720\n",
      "Epoch 546/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.0988 - val_accuracy: 0.9689\n",
      "Epoch 547/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0704 - accuracy: 0.9724 - val_loss: 0.0686 - val_accuracy: 0.9720\n",
      "Epoch 548/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0561 - accuracy: 0.9801 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
      "Epoch 549/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0644 - accuracy: 0.9724 - val_loss: 0.0674 - val_accuracy: 0.9720\n",
      "Epoch 550/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.0837 - val_accuracy: 0.9689\n",
      "Epoch 551/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 0.0629 - val_accuracy: 0.9720\n",
      "Epoch 552/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0527 - accuracy: 0.9862 - val_loss: 0.0570 - val_accuracy: 0.9783\n",
      "Epoch 553/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0576 - accuracy: 0.9770 - val_loss: 0.0743 - val_accuracy: 0.9720\n",
      "Epoch 554/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.1063 - val_accuracy: 0.9689\n",
      "Epoch 555/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0765 - accuracy: 0.9648 - val_loss: 0.0697 - val_accuracy: 0.9720\n",
      "Epoch 556/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0594 - val_accuracy: 0.9783\n",
      "Epoch 557/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0688 - accuracy: 0.9678 - val_loss: 0.0658 - val_accuracy: 0.9720\n",
      "Epoch 558/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.0885 - val_accuracy: 0.9720\n",
      "Epoch 559/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0612 - accuracy: 0.9755 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
      "Epoch 560/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0561 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0598 - accuracy: 0.9770 - val_loss: 0.0675 - val_accuracy: 0.9720\n",
      "Epoch 562/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0707 - val_accuracy: 0.9720\n",
      "Epoch 563/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
      "Epoch 564/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
      "Epoch 565/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.0629 - val_accuracy: 0.9720\n",
      "Epoch 566/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0692 - val_accuracy: 0.9720\n",
      "Epoch 567/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0507 - accuracy: 0.9847 - val_loss: 0.0619 - val_accuracy: 0.9752\n",
      "Epoch 568/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 0.0600 - val_accuracy: 0.9752\n",
      "Epoch 569/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.0645 - val_accuracy: 0.9720\n",
      "Epoch 570/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0494 - accuracy: 0.9862 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
      "Epoch 571/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.0644 - val_accuracy: 0.9720\n",
      "Epoch 572/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.0647 - val_accuracy: 0.9720\n",
      "Epoch 573/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 574/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0496 - accuracy: 0.9847 - val_loss: 0.0556 - val_accuracy: 0.9752\n",
      "Epoch 575/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
      "Epoch 576/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.0751 - val_accuracy: 0.9752\n",
      "Epoch 577/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0704 - val_accuracy: 0.9720\n",
      "Epoch 578/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0503 - accuracy: 0.9832 - val_loss: 0.0547 - val_accuracy: 0.9783\n",
      "Epoch 579/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0514 - accuracy: 0.9816 - val_loss: 0.0544 - val_accuracy: 0.9783\n",
      "Epoch 580/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0537 - accuracy: 0.9786 - val_loss: 0.0666 - val_accuracy: 0.9720\n",
      "Epoch 581/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.0807 - val_accuracy: 0.9752\n",
      "Epoch 582/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0588 - val_accuracy: 0.9752\n",
      "Epoch 583/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0497 - accuracy: 0.9832 - val_loss: 0.0558 - val_accuracy: 0.9783\n",
      "Epoch 584/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0658 - val_accuracy: 0.9720\n",
      "Epoch 585/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0490 - accuracy: 0.9832 - val_loss: 0.0779 - val_accuracy: 0.9752\n",
      "Epoch 586/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0546 - accuracy: 0.9816 - val_loss: 0.0625 - val_accuracy: 0.9720\n",
      "Epoch 587/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.0549 - val_accuracy: 0.9783\n",
      "Epoch 588/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0492 - accuracy: 0.9816 - val_loss: 0.0625 - val_accuracy: 0.9720\n",
      "Epoch 589/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0481 - accuracy: 0.9862 - val_loss: 0.0702 - val_accuracy: 0.9720\n",
      "Epoch 590/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 0.0582 - val_accuracy: 0.9720\n",
      "Epoch 591/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0476 - accuracy: 0.9862 - val_loss: 0.0526 - val_accuracy: 0.9783\n",
      "Epoch 592/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.0590 - val_accuracy: 0.9720\n",
      "Epoch 593/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.0598 - val_accuracy: 0.9720\n",
      "Epoch 594/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0477 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9752\n",
      "Epoch 595/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0474 - accuracy: 0.9862 - val_loss: 0.0615 - val_accuracy: 0.9720\n",
      "Epoch 596/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 0.0692 - val_accuracy: 0.9752\n",
      "Epoch 597/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0613 - val_accuracy: 0.9720\n",
      "Epoch 598/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0463 - accuracy: 0.9862 - val_loss: 0.0548 - val_accuracy: 0.9752\n",
      "Epoch 599/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0491 - accuracy: 0.9816 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 600/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.0678 - val_accuracy: 0.9752\n",
      "Epoch 601/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.0619 - val_accuracy: 0.9720\n",
      "Epoch 602/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0471 - accuracy: 0.9847 - val_loss: 0.0594 - val_accuracy: 0.9752\n",
      "Epoch 603/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.0639 - val_accuracy: 0.9720\n",
      "Epoch 604/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0627 - val_accuracy: 0.9720\n",
      "Epoch 605/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0611 - val_accuracy: 0.9720\n",
      "Epoch 606/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0455 - accuracy: 0.9877 - val_loss: 0.0619 - val_accuracy: 0.9720\n",
      "Epoch 607/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0456 - accuracy: 0.9877 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
      "Epoch 608/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0453 - accuracy: 0.9877 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
      "Epoch 609/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0463 - accuracy: 0.9862 - val_loss: 0.0573 - val_accuracy: 0.9752\n",
      "Epoch 610/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.0624 - val_accuracy: 0.9720\n",
      "Epoch 611/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0658 - val_accuracy: 0.9720\n",
      "Epoch 612/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0619 - val_accuracy: 0.9720\n",
      "Epoch 613/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
      "Epoch 614/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0634 - val_accuracy: 0.9783\n",
      "Epoch 615/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0455 - accuracy: 0.9847 - val_loss: 0.0680 - val_accuracy: 0.9752\n",
      "Epoch 616/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.0628 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0543 - val_accuracy: 0.9752\n",
      "Epoch 618/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 0.0559 - val_accuracy: 0.9752\n",
      "Epoch 619/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0456 - accuracy: 0.9862 - val_loss: 0.0639 - val_accuracy: 0.9720\n",
      "Epoch 620/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0461 - accuracy: 0.9877 - val_loss: 0.0637 - val_accuracy: 0.9720\n",
      "Epoch 621/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0625 - val_accuracy: 0.9720\n",
      "Epoch 622/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.0568 - val_accuracy: 0.9752\n",
      "Epoch 623/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0595 - val_accuracy: 0.9720\n",
      "Epoch 624/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 0.0647 - val_accuracy: 0.9720\n",
      "Epoch 625/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
      "Epoch 626/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0535 - val_accuracy: 0.9752\n",
      "Epoch 627/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.0595 - val_accuracy: 0.9752\n",
      "Epoch 628/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
      "Epoch 629/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.0576 - val_accuracy: 0.9752\n",
      "Epoch 630/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.0536 - val_accuracy: 0.9752\n",
      "Epoch 631/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.0650 - val_accuracy: 0.9752\n",
      "Epoch 632/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.0692 - val_accuracy: 0.9752\n",
      "Epoch 633/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.0562 - val_accuracy: 0.9752\n",
      "Epoch 634/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0477 - accuracy: 0.9847 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
      "Epoch 635/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0780 - val_accuracy: 0.9752\n",
      "Epoch 636/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0498 - accuracy: 0.9832 - val_loss: 0.0742 - val_accuracy: 0.9752\n",
      "Epoch 637/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0489 - accuracy: 0.9832 - val_loss: 0.0565 - val_accuracy: 0.9783\n",
      "Epoch 638/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.0560 - val_accuracy: 0.9783\n",
      "Epoch 639/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.0649 - val_accuracy: 0.9720\n",
      "Epoch 640/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.0666 - val_accuracy: 0.9720\n",
      "Epoch 641/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0435 - accuracy: 0.9847 - val_loss: 0.0625 - val_accuracy: 0.9752\n",
      "Epoch 642/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.0631 - val_accuracy: 0.9752\n",
      "Epoch 643/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.0637 - val_accuracy: 0.9752\n",
      "Epoch 644/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 645/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0669 - val_accuracy: 0.9752\n",
      "Epoch 646/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
      "Epoch 647/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0464 - accuracy: 0.9816 - val_loss: 0.0673 - val_accuracy: 0.9752\n",
      "Epoch 648/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.0776 - val_accuracy: 0.9752\n",
      "Epoch 649/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.0637 - val_accuracy: 0.9752\n",
      "Epoch 650/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.0610 - val_accuracy: 0.9752\n",
      "Epoch 651/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0426 - accuracy: 0.9832 - val_loss: 0.0728 - val_accuracy: 0.9720\n",
      "Epoch 652/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0804 - val_accuracy: 0.9752\n",
      "Epoch 653/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 0.0620 - val_accuracy: 0.9752\n",
      "Epoch 654/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 0.0585 - val_accuracy: 0.9752\n",
      "Epoch 655/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.0711 - val_accuracy: 0.9752\n",
      "Epoch 656/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 0.0751 - val_accuracy: 0.9752\n",
      "Epoch 657/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 0.0614 - val_accuracy: 0.9752\n",
      "Epoch 658/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0421 - accuracy: 0.9847 - val_loss: 0.0595 - val_accuracy: 0.9752\n",
      "Epoch 659/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0442 - accuracy: 0.9832 - val_loss: 0.0646 - val_accuracy: 0.9752\n",
      "Epoch 660/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.0641 - val_accuracy: 0.9752\n",
      "Epoch 661/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.0624 - val_accuracy: 0.9752\n",
      "Epoch 662/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.0607 - val_accuracy: 0.9752\n",
      "Epoch 663/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.0646 - val_accuracy: 0.9752\n",
      "Epoch 664/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0687 - val_accuracy: 0.9720\n",
      "Epoch 665/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.0622 - val_accuracy: 0.9752\n",
      "Epoch 666/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0403 - accuracy: 0.9847 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 667/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0417 - accuracy: 0.9832 - val_loss: 0.0596 - val_accuracy: 0.9752\n",
      "Epoch 668/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0404 - accuracy: 0.9832 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
      "Epoch 669/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0407 - accuracy: 0.9832 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 670/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0408 - accuracy: 0.9862 - val_loss: 0.0641 - val_accuracy: 0.9752\n",
      "Epoch 671/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.0673 - val_accuracy: 0.9752\n",
      "Epoch 672/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 0.0566 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.0563 - val_accuracy: 0.9752\n",
      "Epoch 674/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0411 - accuracy: 0.9847 - val_loss: 0.0657 - val_accuracy: 0.9752\n",
      "Epoch 675/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.0703 - val_accuracy: 0.9752\n",
      "Epoch 676/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0399 - accuracy: 0.9862 - val_loss: 0.0599 - val_accuracy: 0.9752\n",
      "Epoch 677/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
      "Epoch 678/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
      "Epoch 679/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 680/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.0567 - val_accuracy: 0.9752\n",
      "Epoch 681/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0403 - accuracy: 0.9862 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 682/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 0.0654 - val_accuracy: 0.9720\n",
      "Epoch 683/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.0627 - val_accuracy: 0.9752\n",
      "Epoch 684/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.0618 - val_accuracy: 0.9752\n",
      "Epoch 685/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
      "Epoch 686/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0604 - val_accuracy: 0.9752\n",
      "Epoch 687/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0627 - val_accuracy: 0.9783\n",
      "Epoch 688/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.0652 - val_accuracy: 0.9783\n",
      "Epoch 689/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.0627 - val_accuracy: 0.9783\n",
      "Epoch 690/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 0.0598 - val_accuracy: 0.9783\n",
      "Epoch 691/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.0572 - val_accuracy: 0.9752\n",
      "Epoch 692/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0587 - val_accuracy: 0.9752\n",
      "Epoch 693/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.0569 - val_accuracy: 0.9752\n",
      "Epoch 694/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9752\n",
      "Epoch 695/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0381 - accuracy: 0.9847 - val_loss: 0.0699 - val_accuracy: 0.9752\n",
      "Epoch 696/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.0768 - val_accuracy: 0.9752\n",
      "Epoch 697/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.0553 - val_accuracy: 0.9752\n",
      "Epoch 698/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0415 - accuracy: 0.9862 - val_loss: 0.0532 - val_accuracy: 0.9752\n",
      "Epoch 699/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 700/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0415 - accuracy: 0.9832 - val_loss: 0.0707 - val_accuracy: 0.9752\n",
      "Epoch 701/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0517 - val_accuracy: 0.9752\n",
      "Epoch 702/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0400 - accuracy: 0.9862 - val_loss: 0.0492 - val_accuracy: 0.9814\n",
      "Epoch 703/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0447 - accuracy: 0.9801 - val_loss: 0.0589 - val_accuracy: 0.9783\n",
      "Epoch 704/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.0659 - val_accuracy: 0.9752\n",
      "Epoch 705/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0387 - accuracy: 0.9862 - val_loss: 0.0538 - val_accuracy: 0.9752\n",
      "Epoch 706/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.0503 - val_accuracy: 0.9752\n",
      "Epoch 707/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 0.0622 - val_accuracy: 0.9752\n",
      "Epoch 708/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0641 - val_accuracy: 0.9752\n",
      "Epoch 709/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0529 - val_accuracy: 0.9752\n",
      "Epoch 710/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0373 - accuracy: 0.9847 - val_loss: 0.0585 - val_accuracy: 0.9752\n",
      "Epoch 711/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0359 - accuracy: 0.9877 - val_loss: 0.0681 - val_accuracy: 0.9752\n",
      "Epoch 712/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0372 - accuracy: 0.9862 - val_loss: 0.0639 - val_accuracy: 0.9783\n",
      "Epoch 713/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0627 - val_accuracy: 0.9783\n",
      "Epoch 714/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0670 - val_accuracy: 0.9783\n",
      "Epoch 715/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0625 - val_accuracy: 0.9783\n",
      "Epoch 716/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0565 - val_accuracy: 0.9752\n",
      "Epoch 717/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0369 - accuracy: 0.9908 - val_loss: 0.0572 - val_accuracy: 0.9752\n",
      "Epoch 718/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0669 - val_accuracy: 0.9752\n",
      "Epoch 719/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 0.0647 - val_accuracy: 0.9752\n",
      "Epoch 720/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0552 - val_accuracy: 0.9752\n",
      "Epoch 721/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0366 - accuracy: 0.9908 - val_loss: 0.0603 - val_accuracy: 0.9783\n",
      "Epoch 722/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0353 - accuracy: 0.9877 - val_loss: 0.0712 - val_accuracy: 0.9752\n",
      "Epoch 723/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.0586 - val_accuracy: 0.9783\n",
      "Epoch 724/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 0.0540 - val_accuracy: 0.9752\n",
      "Epoch 725/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0359 - accuracy: 0.9908 - val_loss: 0.0679 - val_accuracy: 0.9752\n",
      "Epoch 726/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0389 - accuracy: 0.9847 - val_loss: 0.0610 - val_accuracy: 0.9752\n",
      "Epoch 727/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.0497 - val_accuracy: 0.9814\n",
      "Epoch 728/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.0568 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0357 - accuracy: 0.9893 - val_loss: 0.0838 - val_accuracy: 0.9720\n",
      "Epoch 730/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0454 - accuracy: 0.9801 - val_loss: 0.0703 - val_accuracy: 0.9752\n",
      "Epoch 731/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.0549 - val_accuracy: 0.9752\n",
      "Epoch 732/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0375 - accuracy: 0.9908 - val_loss: 0.0596 - val_accuracy: 0.9752\n",
      "Epoch 733/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.0682 - val_accuracy: 0.9752\n",
      "Epoch 734/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0616 - val_accuracy: 0.9783\n",
      "Epoch 735/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 736/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0356 - accuracy: 0.9923 - val_loss: 0.0611 - val_accuracy: 0.9783\n",
      "Epoch 737/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0346 - accuracy: 0.9877 - val_loss: 0.0681 - val_accuracy: 0.9752\n",
      "Epoch 738/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0602 - val_accuracy: 0.9752\n",
      "Epoch 739/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0502 - val_accuracy: 0.9783\n",
      "Epoch 740/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0401 - accuracy: 0.9847 - val_loss: 0.0558 - val_accuracy: 0.9752\n",
      "Epoch 741/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0375 - accuracy: 0.9862 - val_loss: 0.0752 - val_accuracy: 0.9752\n",
      "Epoch 742/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.0555 - val_accuracy: 0.9752\n",
      "Epoch 743/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0336 - accuracy: 0.9908 - val_loss: 0.0490 - val_accuracy: 0.9814\n",
      "Epoch 744/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0446 - accuracy: 0.9832 - val_loss: 0.0587 - val_accuracy: 0.9783\n",
      "Epoch 745/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.0723 - val_accuracy: 0.9752\n",
      "Epoch 746/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
      "Epoch 747/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0353 - accuracy: 0.9923 - val_loss: 0.0567 - val_accuracy: 0.9783\n",
      "Epoch 748/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0343 - accuracy: 0.9877 - val_loss: 0.0673 - val_accuracy: 0.9752\n",
      "Epoch 749/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0356 - accuracy: 0.9862 - val_loss: 0.0611 - val_accuracy: 0.9783\n",
      "Epoch 750/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0342 - accuracy: 0.9862 - val_loss: 0.0534 - val_accuracy: 0.9752\n",
      "Epoch 751/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.0523 - val_accuracy: 0.9752\n",
      "Epoch 752/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0608 - val_accuracy: 0.9752\n",
      "Epoch 753/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0708 - val_accuracy: 0.9752\n",
      "Epoch 754/3500\n",
      "653/653 [==============================] - 0s 48us/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.0513 - val_accuracy: 0.9783\n",
      "Epoch 755/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0377 - accuracy: 0.9893 - val_loss: 0.0500 - val_accuracy: 0.9783\n",
      "Epoch 756/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 0.0740 - val_accuracy: 0.9752\n",
      "Epoch 757/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0403 - accuracy: 0.9816 - val_loss: 0.0708 - val_accuracy: 0.9752\n",
      "Epoch 758/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.0501 - val_accuracy: 0.9814\n",
      "Epoch 759/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 0.0513 - val_accuracy: 0.9783\n",
      "Epoch 760/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0345 - accuracy: 0.9908 - val_loss: 0.0699 - val_accuracy: 0.9752\n",
      "Epoch 761/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0378 - accuracy: 0.9847 - val_loss: 0.0711 - val_accuracy: 0.9752\n",
      "Epoch 762/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 0.0515 - val_accuracy: 0.9783\n",
      "Epoch 763/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0480 - val_accuracy: 0.9783\n",
      "Epoch 764/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0349 - accuracy: 0.9908 - val_loss: 0.0647 - val_accuracy: 0.9752\n",
      "Epoch 765/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0785 - val_accuracy: 0.9752\n",
      "Epoch 766/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0403 - accuracy: 0.9862 - val_loss: 0.0536 - val_accuracy: 0.9752\n",
      "Epoch 767/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0471 - val_accuracy: 0.9814\n",
      "Epoch 768/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0398 - accuracy: 0.9877 - val_loss: 0.0624 - val_accuracy: 0.9752\n",
      "Epoch 769/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0384 - accuracy: 0.9847 - val_loss: 0.0702 - val_accuracy: 0.9752\n",
      "Epoch 770/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0359 - accuracy: 0.9862 - val_loss: 0.0500 - val_accuracy: 0.9783\n",
      "Epoch 771/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0379 - accuracy: 0.9847 - val_loss: 0.0529 - val_accuracy: 0.9783\n",
      "Epoch 772/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.0739 - val_accuracy: 0.9752\n",
      "Epoch 773/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0377 - accuracy: 0.9847 - val_loss: 0.0645 - val_accuracy: 0.9752\n",
      "Epoch 774/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0481 - val_accuracy: 0.9814\n",
      "Epoch 775/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 0.0506 - val_accuracy: 0.9783\n",
      "Epoch 776/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0326 - accuracy: 0.9908 - val_loss: 0.0676 - val_accuracy: 0.9752\n",
      "Epoch 777/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.0642 - val_accuracy: 0.9752\n",
      "Epoch 778/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.0508 - val_accuracy: 0.9783\n",
      "Epoch 779/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0332 - accuracy: 0.9877 - val_loss: 0.0528 - val_accuracy: 0.9783\n",
      "Epoch 780/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.0577 - val_accuracy: 0.9752\n",
      "Epoch 781/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0587 - val_accuracy: 0.9752\n",
      "Epoch 782/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.0573 - val_accuracy: 0.9783\n",
      "Epoch 783/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0511 - val_accuracy: 0.9783\n",
      "Epoch 784/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0326 - accuracy: 0.9923 - val_loss: 0.0546 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 0.0623 - val_accuracy: 0.9783\n",
      "Epoch 786/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
      "Epoch 787/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0574 - val_accuracy: 0.9814\n",
      "Epoch 788/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0518 - val_accuracy: 0.9814\n",
      "Epoch 789/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0561 - val_accuracy: 0.9814\n",
      "Epoch 790/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 0.0639 - val_accuracy: 0.9752\n",
      "Epoch 791/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9814\n",
      "Epoch 792/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.0455 - val_accuracy: 0.9814\n",
      "Epoch 793/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0366 - accuracy: 0.9877 - val_loss: 0.0527 - val_accuracy: 0.9814\n",
      "Epoch 794/3500\n",
      "653/653 [==============================] - 0s 19us/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0753 - val_accuracy: 0.9752\n",
      "Epoch 795/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 0.0573 - val_accuracy: 0.9783\n",
      "Epoch 796/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.0459 - val_accuracy: 0.9814\n",
      "Epoch 797/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0428 - accuracy: 0.9847 - val_loss: 0.0530 - val_accuracy: 0.9814\n",
      "Epoch 798/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0698 - val_accuracy: 0.9752\n",
      "Epoch 799/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 800/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.0501 - val_accuracy: 0.9783\n",
      "Epoch 801/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0326 - accuracy: 0.9939 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
      "Epoch 802/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0325 - accuracy: 0.9877 - val_loss: 0.0614 - val_accuracy: 0.9752\n",
      "Epoch 803/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0318 - accuracy: 0.9877 - val_loss: 0.0537 - val_accuracy: 0.9814\n",
      "Epoch 804/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0306 - accuracy: 0.9923 - val_loss: 0.0516 - val_accuracy: 0.9814\n",
      "Epoch 805/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0315 - accuracy: 0.9939 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
      "Epoch 806/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0605 - val_accuracy: 0.9783\n",
      "Epoch 807/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
      "Epoch 808/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0550 - val_accuracy: 0.9814\n",
      "Epoch 809/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0499 - val_accuracy: 0.9783\n",
      "Epoch 810/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0316 - accuracy: 0.9939 - val_loss: 0.0544 - val_accuracy: 0.9814\n",
      "Epoch 811/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0631 - val_accuracy: 0.9752\n",
      "Epoch 812/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0329 - accuracy: 0.9877 - val_loss: 0.0532 - val_accuracy: 0.9814\n",
      "Epoch 813/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0492 - val_accuracy: 0.9783\n",
      "Epoch 814/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.0563 - val_accuracy: 0.9814\n",
      "Epoch 815/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0305 - accuracy: 0.9893 - val_loss: 0.0612 - val_accuracy: 0.9783\n",
      "Epoch 816/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 817/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.0573 - val_accuracy: 0.9783\n",
      "Epoch 818/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
      "Epoch 819/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0537 - val_accuracy: 0.9814\n",
      "Epoch 820/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0298 - accuracy: 0.9923 - val_loss: 0.0487 - val_accuracy: 0.9783\n",
      "Epoch 821/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0311 - accuracy: 0.9939 - val_loss: 0.0509 - val_accuracy: 0.9814\n",
      "Epoch 822/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0302 - accuracy: 0.9939 - val_loss: 0.0578 - val_accuracy: 0.9783\n",
      "Epoch 823/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
      "Epoch 824/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0509 - val_accuracy: 0.9814\n",
      "Epoch 825/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9814\n",
      "Epoch 826/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0572 - val_accuracy: 0.9814\n",
      "Epoch 827/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0307 - accuracy: 0.9877 - val_loss: 0.0569 - val_accuracy: 0.9814\n",
      "Epoch 828/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0523 - val_accuracy: 0.9814\n",
      "Epoch 829/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0298 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 830/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 0.0555 - val_accuracy: 0.9814\n",
      "Epoch 831/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0570 - val_accuracy: 0.9783\n",
      "Epoch 832/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 0.0572 - val_accuracy: 0.9783\n",
      "Epoch 833/3500\n",
      "653/653 [==============================] - 0s 61us/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
      "Epoch 834/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0301 - accuracy: 0.9877 - val_loss: 0.0517 - val_accuracy: 0.9814\n",
      "Epoch 835/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 0.0461 - val_accuracy: 0.9783\n",
      "Epoch 836/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0305 - accuracy: 0.9893 - val_loss: 0.0505 - val_accuracy: 0.9814\n",
      "Epoch 837/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0577 - val_accuracy: 0.9752\n",
      "Epoch 838/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
      "Epoch 839/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.0498 - val_accuracy: 0.9814\n",
      "Epoch 840/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0294 - accuracy: 0.9923 - val_loss: 0.0535 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
      "Epoch 842/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0299 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 843/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0294 - accuracy: 0.9939 - val_loss: 0.0599 - val_accuracy: 0.9783\n",
      "Epoch 844/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.0596 - val_accuracy: 0.9814\n",
      "Epoch 845/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0498 - val_accuracy: 0.9814\n",
      "Epoch 846/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0293 - accuracy: 0.9939 - val_loss: 0.0478 - val_accuracy: 0.9783\n",
      "Epoch 847/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0298 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9814\n",
      "Epoch 848/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0294 - accuracy: 0.9893 - val_loss: 0.0491 - val_accuracy: 0.9814\n",
      "Epoch 849/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0293 - accuracy: 0.9939 - val_loss: 0.0474 - val_accuracy: 0.9783\n",
      "Epoch 850/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
      "Epoch 851/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
      "Epoch 852/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 853/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0479 - val_accuracy: 0.9845\n",
      "Epoch 854/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0305 - accuracy: 0.9969 - val_loss: 0.0528 - val_accuracy: 0.9814\n",
      "Epoch 855/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0668 - val_accuracy: 0.9752\n",
      "Epoch 856/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.0603 - val_accuracy: 0.9783\n",
      "Epoch 857/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0301 - accuracy: 0.9877 - val_loss: 0.0482 - val_accuracy: 0.9814\n",
      "Epoch 858/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
      "Epoch 859/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0659 - val_accuracy: 0.9783\n",
      "Epoch 860/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0327 - accuracy: 0.9877 - val_loss: 0.0521 - val_accuracy: 0.9814\n",
      "Epoch 861/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0474 - val_accuracy: 0.9845\n",
      "Epoch 862/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0295 - accuracy: 0.9954 - val_loss: 0.0577 - val_accuracy: 0.9814\n",
      "Epoch 863/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0628 - val_accuracy: 0.9783\n",
      "Epoch 864/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 0.0508 - val_accuracy: 0.9814\n",
      "Epoch 865/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0290 - accuracy: 0.9954 - val_loss: 0.0479 - val_accuracy: 0.9783\n",
      "Epoch 866/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0296 - accuracy: 0.9939 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 867/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0617 - val_accuracy: 0.9752\n",
      "Epoch 868/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0297 - accuracy: 0.9877 - val_loss: 0.0553 - val_accuracy: 0.9814\n",
      "Epoch 869/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0470 - val_accuracy: 0.9814\n",
      "Epoch 870/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0300 - accuracy: 0.9954 - val_loss: 0.0479 - val_accuracy: 0.9814\n",
      "Epoch 871/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0296 - accuracy: 0.9954 - val_loss: 0.0586 - val_accuracy: 0.9814\n",
      "Epoch 872/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0295 - accuracy: 0.9877 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
      "Epoch 873/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.0483 - val_accuracy: 0.9845\n",
      "Epoch 874/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0310 - accuracy: 0.9954 - val_loss: 0.0523 - val_accuracy: 0.9814\n",
      "Epoch 875/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0287 - accuracy: 0.9954 - val_loss: 0.0594 - val_accuracy: 0.9814\n",
      "Epoch 876/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0286 - accuracy: 0.9893 - val_loss: 0.0590 - val_accuracy: 0.9814\n",
      "Epoch 877/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0285 - accuracy: 0.9893 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
      "Epoch 878/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0295 - accuracy: 0.9969 - val_loss: 0.0489 - val_accuracy: 0.9814\n",
      "Epoch 879/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0584 - val_accuracy: 0.9783\n",
      "Epoch 880/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.0522 - val_accuracy: 0.9814\n",
      "Epoch 881/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0503 - val_accuracy: 0.9814\n",
      "Epoch 882/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
      "Epoch 883/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9814\n",
      "Epoch 884/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0507 - val_accuracy: 0.9814\n",
      "Epoch 885/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.0514 - val_accuracy: 0.9814\n",
      "Epoch 886/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
      "Epoch 887/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
      "Epoch 888/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0491 - val_accuracy: 0.9814\n",
      "Epoch 889/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0282 - accuracy: 0.9969 - val_loss: 0.0527 - val_accuracy: 0.9814\n",
      "Epoch 890/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 0.0623 - val_accuracy: 0.9783\n",
      "Epoch 891/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0300 - accuracy: 0.9877 - val_loss: 0.0497 - val_accuracy: 0.9814\n",
      "Epoch 892/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0278 - accuracy: 0.9969 - val_loss: 0.0429 - val_accuracy: 0.9814\n",
      "Epoch 893/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0353 - accuracy: 0.9862 - val_loss: 0.0594 - val_accuracy: 0.9783\n",
      "Epoch 894/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.0835 - val_accuracy: 0.9720\n",
      "Epoch 895/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0405 - accuracy: 0.9832 - val_loss: 0.0497 - val_accuracy: 0.9814\n",
      "Epoch 896/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0414 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0369 - accuracy: 0.9862 - val_loss: 0.0578 - val_accuracy: 0.9783\n",
      "Epoch 898/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0327 - accuracy: 0.9862 - val_loss: 0.0901 - val_accuracy: 0.9720\n",
      "Epoch 899/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0470 - accuracy: 0.9816 - val_loss: 0.0492 - val_accuracy: 0.9814\n",
      "Epoch 900/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0268 - accuracy: 0.9939 - val_loss: 0.0423 - val_accuracy: 0.9814\n",
      "Epoch 901/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
      "Epoch 902/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0732 - val_accuracy: 0.9752\n",
      "Epoch 903/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0337 - accuracy: 0.9877 - val_loss: 0.0446 - val_accuracy: 0.9814\n",
      "Epoch 904/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0280 - accuracy: 0.9969 - val_loss: 0.0394 - val_accuracy: 0.9845\n",
      "Epoch 905/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0377 - accuracy: 0.9862 - val_loss: 0.0513 - val_accuracy: 0.9814\n",
      "Epoch 906/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.0757 - val_accuracy: 0.9752\n",
      "Epoch 907/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0378 - accuracy: 0.9862 - val_loss: 0.0508 - val_accuracy: 0.9814\n",
      "Epoch 908/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0400 - val_accuracy: 0.9814\n",
      "Epoch 909/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.0474 - val_accuracy: 0.9814\n",
      "Epoch 910/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0277 - accuracy: 0.9954 - val_loss: 0.0712 - val_accuracy: 0.9752\n",
      "Epoch 911/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0336 - accuracy: 0.9862 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 912/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0280 - accuracy: 0.9893 - val_loss: 0.0447 - val_accuracy: 0.9845\n",
      "Epoch 913/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0282 - accuracy: 0.9939 - val_loss: 0.0488 - val_accuracy: 0.9814\n",
      "Epoch 914/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0260 - accuracy: 0.9969 - val_loss: 0.0617 - val_accuracy: 0.9783\n",
      "Epoch 915/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0290 - accuracy: 0.9893 - val_loss: 0.0636 - val_accuracy: 0.9783\n",
      "Epoch 916/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.0510 - val_accuracy: 0.9814\n",
      "Epoch 917/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0264 - accuracy: 0.9893 - val_loss: 0.0444 - val_accuracy: 0.9845\n",
      "Epoch 918/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0280 - accuracy: 0.9954 - val_loss: 0.0463 - val_accuracy: 0.9814\n",
      "Epoch 919/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0273 - accuracy: 0.9954 - val_loss: 0.0577 - val_accuracy: 0.9783\n",
      "Epoch 920/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.0517 - val_accuracy: 0.9814\n",
      "Epoch 921/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0266 - accuracy: 0.9969 - val_loss: 0.0443 - val_accuracy: 0.9845\n",
      "Epoch 922/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.0507 - val_accuracy: 0.9814\n",
      "Epoch 923/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9783\n",
      "Epoch 924/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
      "Epoch 925/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.0403 - val_accuracy: 0.9814\n",
      "Epoch 926/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0463 - val_accuracy: 0.9814\n",
      "Epoch 927/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0668 - val_accuracy: 0.9783\n",
      "Epoch 928/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 929/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0415 - val_accuracy: 0.9845\n",
      "Epoch 930/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0294 - accuracy: 0.9923 - val_loss: 0.0465 - val_accuracy: 0.9814\n",
      "Epoch 931/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0267 - accuracy: 0.9954 - val_loss: 0.0581 - val_accuracy: 0.9783\n",
      "Epoch 932/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0281 - accuracy: 0.9893 - val_loss: 0.0525 - val_accuracy: 0.9814\n",
      "Epoch 933/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0430 - val_accuracy: 0.9845\n",
      "Epoch 934/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0282 - accuracy: 0.9954 - val_loss: 0.0493 - val_accuracy: 0.9814\n",
      "Epoch 935/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0642 - val_accuracy: 0.9783\n",
      "Epoch 936/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.0552 - val_accuracy: 0.9814\n",
      "Epoch 937/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.0480 - val_accuracy: 0.9845\n",
      "Epoch 938/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0276 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 939/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 940/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0557 - val_accuracy: 0.9814\n",
      "Epoch 941/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.0534 - val_accuracy: 0.9814\n",
      "Epoch 942/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0267 - accuracy: 0.9954 - val_loss: 0.0571 - val_accuracy: 0.9814\n",
      "Epoch 943/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0517 - val_accuracy: 0.9814\n",
      "Epoch 944/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
      "Epoch 945/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.0546 - val_accuracy: 0.9814\n",
      "Epoch 946/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0505 - val_accuracy: 0.9814\n",
      "Epoch 947/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0254 - accuracy: 0.9954 - val_loss: 0.0445 - val_accuracy: 0.9845\n",
      "Epoch 948/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0276 - accuracy: 0.9954 - val_loss: 0.0495 - val_accuracy: 0.9814\n",
      "Epoch 949/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0248 - accuracy: 0.9954 - val_loss: 0.0614 - val_accuracy: 0.9783\n",
      "Epoch 950/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0275 - accuracy: 0.9893 - val_loss: 0.0562 - val_accuracy: 0.9814\n",
      "Epoch 951/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0447 - val_accuracy: 0.9845\n",
      "Epoch 952/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0263 - accuracy: 0.9969 - val_loss: 0.0470 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0251 - accuracy: 0.9954 - val_loss: 0.0576 - val_accuracy: 0.9814\n",
      "Epoch 954/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0261 - accuracy: 0.9893 - val_loss: 0.0601 - val_accuracy: 0.9814\n",
      "Epoch 955/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 956/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0451 - val_accuracy: 0.9845\n",
      "Epoch 957/3500\n",
      "653/653 [==============================] - 0s 22us/step - loss: 0.0275 - accuracy: 0.9954 - val_loss: 0.0489 - val_accuracy: 0.9814\n",
      "Epoch 958/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0252 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9783\n",
      "Epoch 959/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0575 - val_accuracy: 0.9814\n",
      "Epoch 960/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
      "Epoch 961/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0249 - accuracy: 0.9969 - val_loss: 0.0539 - val_accuracy: 0.9814\n",
      "Epoch 962/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0593 - val_accuracy: 0.9814\n",
      "Epoch 963/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0587 - val_accuracy: 0.9814\n",
      "Epoch 964/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0530 - val_accuracy: 0.9814\n",
      "Epoch 965/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0498 - val_accuracy: 0.9814\n",
      "Epoch 966/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.0549 - val_accuracy: 0.9814\n",
      "Epoch 967/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
      "Epoch 968/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0471 - val_accuracy: 0.9814\n",
      "Epoch 969/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0258 - accuracy: 0.9969 - val_loss: 0.0448 - val_accuracy: 0.9845\n",
      "Epoch 970/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0264 - accuracy: 0.9969 - val_loss: 0.0534 - val_accuracy: 0.9814\n",
      "Epoch 971/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
      "Epoch 972/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0555 - val_accuracy: 0.9814\n",
      "Epoch 973/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0243 - accuracy: 0.9969 - val_loss: 0.0491 - val_accuracy: 0.9845\n",
      "Epoch 974/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.0518 - val_accuracy: 0.9814\n",
      "Epoch 975/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0260 - accuracy: 0.9939 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
      "Epoch 976/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.0491 - val_accuracy: 0.9814\n",
      "Epoch 977/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.0446 - val_accuracy: 0.9814\n",
      "Epoch 978/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.0495 - val_accuracy: 0.9814\n",
      "Epoch 979/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0584 - val_accuracy: 0.9814\n",
      "Epoch 980/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
      "Epoch 981/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0250 - accuracy: 0.9969 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
      "Epoch 982/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 0.0552 - val_accuracy: 0.9814\n",
      "Epoch 983/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9814\n",
      "Epoch 984/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
      "Epoch 985/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0250 - accuracy: 0.9969 - val_loss: 0.0527 - val_accuracy: 0.9814\n",
      "Epoch 986/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9814\n",
      "Epoch 987/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0606 - val_accuracy: 0.9814\n",
      "Epoch 988/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.0250 - accuracy: 0.9969 - val_loss: 0.0533 - val_accuracy: 0.9814\n",
      "Epoch 989/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9814\n",
      "Epoch 990/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0242 - accuracy: 0.9954 - val_loss: 0.0593 - val_accuracy: 0.9814\n",
      "Epoch 991/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 992/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0549 - val_accuracy: 0.9814\n",
      "Epoch 993/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.0546 - val_accuracy: 0.9814\n",
      "Epoch 994/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0240 - accuracy: 0.9969 - val_loss: 0.0579 - val_accuracy: 0.9814\n",
      "Epoch 995/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0242 - accuracy: 0.9954 - val_loss: 0.0599 - val_accuracy: 0.9814\n",
      "Epoch 996/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0240 - accuracy: 0.9969 - val_loss: 0.0523 - val_accuracy: 0.9814\n",
      "Epoch 997/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.0539 - val_accuracy: 0.9814\n",
      "Epoch 998/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0629 - val_accuracy: 0.9783\n",
      "Epoch 999/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0253 - accuracy: 0.9893 - val_loss: 0.0558 - val_accuracy: 0.9814\n",
      "Epoch 1000/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 1001/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.0609 - val_accuracy: 0.9783\n",
      "Epoch 1002/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0248 - accuracy: 0.9893 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 1003/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.0546 - val_accuracy: 0.9814\n",
      "Epoch 1004/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 1005/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0255 - accuracy: 0.9954 - val_loss: 0.0578 - val_accuracy: 0.9814\n",
      "Epoch 1006/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.0484 - val_accuracy: 0.9845\n",
      "Epoch 1007/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0531 - val_accuracy: 0.9814\n",
      "Epoch 1008/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0554 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1009/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.0509 - val_accuracy: 0.9814\n",
      "Epoch 1010/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0240 - accuracy: 0.9969 - val_loss: 0.0517 - val_accuracy: 0.9814\n",
      "Epoch 1011/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.0575 - val_accuracy: 0.9814\n",
      "Epoch 1012/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9954 - val_loss: 0.0588 - val_accuracy: 0.9814\n",
      "Epoch 1013/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0247 - accuracy: 0.9954 - val_loss: 0.0572 - val_accuracy: 0.9814\n",
      "Epoch 1014/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.0616 - val_accuracy: 0.9814\n",
      "Epoch 1015/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0250 - accuracy: 0.9908 - val_loss: 0.0554 - val_accuracy: 0.9814\n",
      "Epoch 1016/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0452 - val_accuracy: 0.9845\n",
      "Epoch 1017/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.0510 - val_accuracy: 0.9814\n",
      "Epoch 1018/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.0642 - val_accuracy: 0.9783\n",
      "Epoch 1019/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0263 - accuracy: 0.9877 - val_loss: 0.0528 - val_accuracy: 0.9814\n",
      "Epoch 1020/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0235 - accuracy: 0.9969 - val_loss: 0.0431 - val_accuracy: 0.9814\n",
      "Epoch 1021/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0510 - val_accuracy: 0.9814\n",
      "Epoch 1022/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
      "Epoch 1023/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 1024/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.0421 - val_accuracy: 0.9814\n",
      "Epoch 1025/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0305 - accuracy: 0.9923 - val_loss: 0.0462 - val_accuracy: 0.9845\n",
      "Epoch 1026/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9969 - val_loss: 0.0636 - val_accuracy: 0.9814\n",
      "Epoch 1027/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0260 - accuracy: 0.9893 - val_loss: 0.0644 - val_accuracy: 0.9814\n",
      "Epoch 1028/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0241 - accuracy: 0.9908 - val_loss: 0.0449 - val_accuracy: 0.9845\n",
      "Epoch 1029/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0264 - accuracy: 0.9954 - val_loss: 0.0436 - val_accuracy: 0.9845\n",
      "Epoch 1030/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.0652 - val_accuracy: 0.9783\n",
      "Epoch 1031/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0296 - accuracy: 0.9862 - val_loss: 0.0696 - val_accuracy: 0.9783\n",
      "Epoch 1032/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.0431 - val_accuracy: 0.9814\n",
      "Epoch 1033/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.0530 - val_accuracy: 0.9814\n",
      "Epoch 1034/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 0.1055 - val_accuracy: 0.9720\n",
      "Epoch 1035/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0520 - accuracy: 0.9755 - val_loss: 0.0682 - val_accuracy: 0.9783\n",
      "Epoch 1036/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0435 - val_accuracy: 0.9783\n",
      "Epoch 1037/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0402 - accuracy: 0.9847 - val_loss: 0.0479 - val_accuracy: 0.9845\n",
      "Epoch 1038/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0282 - accuracy: 0.9939 - val_loss: 0.0816 - val_accuracy: 0.9752\n",
      "Epoch 1039/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0335 - accuracy: 0.9862 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
      "Epoch 1040/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0250 - accuracy: 0.9969 - val_loss: 0.0450 - val_accuracy: 0.9783\n",
      "Epoch 1041/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0575 - val_accuracy: 0.9814\n",
      "Epoch 1042/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9783\n",
      "Epoch 1043/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0272 - accuracy: 0.9893 - val_loss: 0.0594 - val_accuracy: 0.9814\n",
      "Epoch 1044/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.0524 - val_accuracy: 0.9845\n",
      "Epoch 1045/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0232 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 1046/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0655 - val_accuracy: 0.9783\n",
      "Epoch 1047/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0647 - val_accuracy: 0.9814\n",
      "Epoch 1048/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 1049/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0540 - val_accuracy: 0.9814\n",
      "Epoch 1050/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0226 - accuracy: 0.9969 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
      "Epoch 1051/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0236 - accuracy: 0.9969 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
      "Epoch 1052/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 0.0562 - val_accuracy: 0.9814\n",
      "Epoch 1053/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
      "Epoch 1054/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9814\n",
      "Epoch 1055/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
      "Epoch 1056/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.0639 - val_accuracy: 0.9783\n",
      "Epoch 1057/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0574 - val_accuracy: 0.9814\n",
      "Epoch 1058/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 0.0496 - val_accuracy: 0.9845\n",
      "Epoch 1059/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0248 - accuracy: 0.9954 - val_loss: 0.0521 - val_accuracy: 0.9814\n",
      "Epoch 1060/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.0575 - val_accuracy: 0.9814\n",
      "Epoch 1061/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
      "Epoch 1062/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 0.0553 - val_accuracy: 0.9814\n",
      "Epoch 1063/3500\n",
      "653/653 [==============================] - 0s 69us/step - loss: 0.0229 - accuracy: 0.9969 - val_loss: 0.0608 - val_accuracy: 0.9814\n",
      "Epoch 1064/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 0.0617 - val_accuracy: 0.9814\n",
      "Epoch 1065/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0235 - accuracy: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9814\n",
      "Epoch 1066/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 1067/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0231 - accuracy: 0.9908 - val_loss: 0.0588 - val_accuracy: 0.9814\n",
      "Epoch 1068/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0226 - accuracy: 0.9969 - val_loss: 0.0517 - val_accuracy: 0.9814\n",
      "Epoch 1069/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
      "Epoch 1070/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0228 - accuracy: 0.9954 - val_loss: 0.0676 - val_accuracy: 0.9783\n",
      "Epoch 1071/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0252 - accuracy: 0.9893 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 1072/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 0.0550 - val_accuracy: 0.9814\n",
      "Epoch 1073/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9814\n",
      "Epoch 1074/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
      "Epoch 1075/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 0.0580 - val_accuracy: 0.9845\n",
      "Epoch 1076/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 0.0518 - val_accuracy: 0.9845\n",
      "Epoch 1077/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0241 - accuracy: 0.9954 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
      "Epoch 1078/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.0730 - val_accuracy: 0.9752\n",
      "Epoch 1079/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0264 - accuracy: 0.9877 - val_loss: 0.0618 - val_accuracy: 0.9814\n",
      "Epoch 1080/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0235 - accuracy: 0.9908 - val_loss: 0.0478 - val_accuracy: 0.9845\n",
      "Epoch 1081/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0236 - accuracy: 0.9969 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 1082/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0230 - accuracy: 0.9954 - val_loss: 0.0569 - val_accuracy: 0.9814\n",
      "Epoch 1083/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0538 - val_accuracy: 0.9814\n",
      "Epoch 1084/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
      "Epoch 1085/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0557 - val_accuracy: 0.9814\n",
      "Epoch 1086/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0557 - val_accuracy: 0.9814\n",
      "Epoch 1087/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0539 - val_accuracy: 0.9814\n",
      "Epoch 1088/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.0533 - val_accuracy: 0.9814\n",
      "Epoch 1089/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0541 - val_accuracy: 0.9814\n",
      "Epoch 1090/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.0577 - val_accuracy: 0.9814\n",
      "Epoch 1091/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0223 - accuracy: 0.9969 - val_loss: 0.0615 - val_accuracy: 0.9814\n",
      "Epoch 1092/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.0514 - val_accuracy: 0.9845\n",
      "Epoch 1093/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0235 - accuracy: 0.9969 - val_loss: 0.0524 - val_accuracy: 0.9845\n",
      "Epoch 1094/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.0627 - val_accuracy: 0.9814\n",
      "Epoch 1095/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 0.0578 - val_accuracy: 0.9814\n",
      "Epoch 1096/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.0527 - val_accuracy: 0.9845\n",
      "Epoch 1097/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 0.0560 - val_accuracy: 0.9845\n",
      "Epoch 1098/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 1099/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0221 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9814\n",
      "Epoch 1100/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
      "Epoch 1101/3500\n",
      "653/653 [==============================] - 0s 56us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9814\n",
      "Epoch 1102/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0214 - accuracy: 0.9969 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 1103/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0221 - accuracy: 0.9969 - val_loss: 0.0513 - val_accuracy: 0.9814\n",
      "Epoch 1104/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0489 - val_accuracy: 0.9845\n",
      "Epoch 1105/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 0.0585 - val_accuracy: 0.9814\n",
      "Epoch 1106/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9783\n",
      "Epoch 1107/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
      "Epoch 1108/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0223 - accuracy: 0.9969 - val_loss: 0.0531 - val_accuracy: 0.9845\n",
      "Epoch 1109/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9814\n",
      "Epoch 1110/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9783\n",
      "Epoch 1111/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0235 - accuracy: 0.9893 - val_loss: 0.0571 - val_accuracy: 0.9814\n",
      "Epoch 1112/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0215 - accuracy: 0.9969 - val_loss: 0.0537 - val_accuracy: 0.9845\n",
      "Epoch 1113/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0219 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9814\n",
      "Epoch 1114/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0214 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9814\n",
      "Epoch 1115/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0582 - val_accuracy: 0.9814\n",
      "Epoch 1116/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0545 - val_accuracy: 0.9845\n",
      "Epoch 1117/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9783\n",
      "Epoch 1118/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0755 - val_accuracy: 0.9783\n",
      "Epoch 1119/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 12us/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0583 - val_accuracy: 0.9814\n",
      "Epoch 1120/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.0468 - val_accuracy: 0.9814\n",
      "Epoch 1121/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0259 - accuracy: 0.9954 - val_loss: 0.0496 - val_accuracy: 0.9845\n",
      "Epoch 1122/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0225 - accuracy: 0.9954 - val_loss: 0.0659 - val_accuracy: 0.9783\n",
      "Epoch 1123/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0245 - accuracy: 0.9893 - val_loss: 0.0624 - val_accuracy: 0.9814\n",
      "Epoch 1124/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0223 - accuracy: 0.9908 - val_loss: 0.0485 - val_accuracy: 0.9845\n",
      "Epoch 1125/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0243 - accuracy: 0.9954 - val_loss: 0.0514 - val_accuracy: 0.9845\n",
      "Epoch 1126/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0652 - val_accuracy: 0.9814\n",
      "Epoch 1127/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 1128/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0525 - val_accuracy: 0.9845\n",
      "Epoch 1129/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.0528 - val_accuracy: 0.9845\n",
      "Epoch 1130/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0214 - accuracy: 0.9969 - val_loss: 0.0602 - val_accuracy: 0.9814\n",
      "Epoch 1131/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0211 - accuracy: 0.9954 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 1132/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.0638 - val_accuracy: 0.9814\n",
      "Epoch 1133/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0213 - accuracy: 0.9954 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
      "Epoch 1134/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 1135/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 1136/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0624 - val_accuracy: 0.9814\n",
      "Epoch 1137/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0602 - val_accuracy: 0.9814\n",
      "Epoch 1138/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0624 - val_accuracy: 0.9814\n",
      "Epoch 1139/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9814\n",
      "Epoch 1140/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9814\n",
      "Epoch 1141/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 1142/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9814\n",
      "Epoch 1143/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0572 - val_accuracy: 0.9814\n",
      "Epoch 1144/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0597 - val_accuracy: 0.9814\n",
      "Epoch 1145/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0607 - val_accuracy: 0.9814\n",
      "Epoch 1146/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0577 - val_accuracy: 0.9814\n",
      "Epoch 1147/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.0551 - val_accuracy: 0.9845\n",
      "Epoch 1148/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.0574 - val_accuracy: 0.9814\n",
      "Epoch 1149/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9814\n",
      "Epoch 1150/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0625 - val_accuracy: 0.9814\n",
      "Epoch 1151/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0522 - val_accuracy: 0.9845\n",
      "Epoch 1152/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.0495 - val_accuracy: 0.9845\n",
      "Epoch 1153/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0258 - accuracy: 0.9939 - val_loss: 0.0606 - val_accuracy: 0.9814\n",
      "Epoch 1154/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
      "Epoch 1155/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 0.0614 - val_accuracy: 0.9814\n",
      "Epoch 1156/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0211 - accuracy: 0.9969 - val_loss: 0.0513 - val_accuracy: 0.9845\n",
      "Epoch 1157/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0214 - accuracy: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9814\n",
      "Epoch 1158/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0660 - val_accuracy: 0.9783\n",
      "Epoch 1159/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.0527 - val_accuracy: 0.9845\n",
      "Epoch 1160/3500\n",
      "653/653 [==============================] - 0s 61us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0494 - val_accuracy: 0.9845\n",
      "Epoch 1161/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9814\n",
      "Epoch 1162/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0717 - val_accuracy: 0.9783\n",
      "Epoch 1163/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0619 - val_accuracy: 0.9814\n",
      "Epoch 1164/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.0526 - val_accuracy: 0.9845\n",
      "Epoch 1165/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0223 - accuracy: 0.9969 - val_loss: 0.0578 - val_accuracy: 0.9814\n",
      "Epoch 1166/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
      "Epoch 1167/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0244 - accuracy: 0.9908 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 1168/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.0456 - val_accuracy: 0.9814\n",
      "Epoch 1169/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0518 - val_accuracy: 0.9845\n",
      "Epoch 1170/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9814\n",
      "Epoch 1171/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9845\n",
      "Epoch 1172/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0202 - accuracy: 0.9969 - val_loss: 0.0527 - val_accuracy: 0.9845\n",
      "Epoch 1173/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9814\n",
      "Epoch 1174/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0679 - val_accuracy: 0.9783\n",
      "Epoch 1175/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 1176/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.0501 - val_accuracy: 0.9845\n",
      "Epoch 1177/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0636 - val_accuracy: 0.9783\n",
      "Epoch 1178/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0599 - val_accuracy: 0.9814\n",
      "Epoch 1179/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0202 - accuracy: 0.9969 - val_loss: 0.0469 - val_accuracy: 0.9814\n",
      "Epoch 1180/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
      "Epoch 1181/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0229 - accuracy: 0.9954 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
      "Epoch 1182/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.0592 - val_accuracy: 0.9845\n",
      "Epoch 1183/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0202 - accuracy: 0.9969 - val_loss: 0.0508 - val_accuracy: 0.9845\n",
      "Epoch 1184/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.0592 - val_accuracy: 0.9814\n",
      "Epoch 1185/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0750 - val_accuracy: 0.9752\n",
      "Epoch 1186/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0243 - accuracy: 0.9893 - val_loss: 0.0623 - val_accuracy: 0.9814\n",
      "Epoch 1187/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0210 - accuracy: 0.9954 - val_loss: 0.0513 - val_accuracy: 0.9845\n",
      "Epoch 1188/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0563 - val_accuracy: 0.9814\n",
      "Epoch 1189/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0692 - val_accuracy: 0.9783\n",
      "Epoch 1190/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0605 - val_accuracy: 0.9814\n",
      "Epoch 1191/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0496 - val_accuracy: 0.9845\n",
      "Epoch 1192/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 0.0616 - val_accuracy: 0.9845\n",
      "Epoch 1193/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0235 - accuracy: 0.9954 - val_loss: 0.0875 - val_accuracy: 0.9752\n",
      "Epoch 1194/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.0621 - val_accuracy: 0.9814\n",
      "Epoch 1195/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
      "Epoch 1196/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0527 - val_accuracy: 0.9845\n",
      "Epoch 1197/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0223 - accuracy: 0.9969 - val_loss: 0.0618 - val_accuracy: 0.9814\n",
      "Epoch 1198/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9783\n",
      "Epoch 1199/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 0.0678 - val_accuracy: 0.9814\n",
      "Epoch 1200/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.0558 - val_accuracy: 0.9845\n",
      "Epoch 1201/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0230 - accuracy: 0.9969 - val_loss: 0.0609 - val_accuracy: 0.9814\n",
      "Epoch 1202/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 1203/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.0747 - val_accuracy: 0.9783\n",
      "Epoch 1204/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 0.0523 - val_accuracy: 0.9845\n",
      "Epoch 1205/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
      "Epoch 1206/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0820 - val_accuracy: 0.9752\n",
      "Epoch 1207/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0275 - accuracy: 0.9893 - val_loss: 0.0565 - val_accuracy: 0.9814\n",
      "Epoch 1208/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0234 - accuracy: 0.9969 - val_loss: 0.0446 - val_accuracy: 0.9814\n",
      "Epoch 1209/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.0598 - val_accuracy: 0.9814\n",
      "Epoch 1210/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0936 - val_accuracy: 0.9752\n",
      "Epoch 1211/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0336 - accuracy: 0.9877 - val_loss: 0.0679 - val_accuracy: 0.9783\n",
      "Epoch 1212/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0472 - val_accuracy: 0.9845\n",
      "Epoch 1213/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 1214/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 1215/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 0.0704 - val_accuracy: 0.9814\n",
      "Epoch 1216/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0625 - val_accuracy: 0.9814\n",
      "Epoch 1217/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9814\n",
      "Epoch 1218/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9814\n",
      "Epoch 1219/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0662 - val_accuracy: 0.9814\n",
      "Epoch 1220/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0596 - val_accuracy: 0.9814\n",
      "Epoch 1221/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0584 - val_accuracy: 0.9845\n",
      "Epoch 1222/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0614 - val_accuracy: 0.9814\n",
      "Epoch 1223/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0621 - val_accuracy: 0.9814\n",
      "Epoch 1224/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9814\n",
      "Epoch 1225/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 1226/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9814\n",
      "Epoch 1227/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0610 - val_accuracy: 0.9814\n",
      "Epoch 1228/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0547 - val_accuracy: 0.9845\n",
      "Epoch 1229/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 14us/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.0544 - val_accuracy: 0.9845\n",
      "Epoch 1230/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 1231/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 1232/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 1233/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0463 - val_accuracy: 0.9814\n",
      "Epoch 1234/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0246 - accuracy: 0.9954 - val_loss: 0.0517 - val_accuracy: 0.9845\n",
      "Epoch 1235/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
      "Epoch 1236/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9814\n",
      "Epoch 1237/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9814\n",
      "Epoch 1238/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0614 - val_accuracy: 0.9814\n",
      "Epoch 1239/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0587 - val_accuracy: 0.9814\n",
      "Epoch 1240/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0523 - val_accuracy: 0.9845\n",
      "Epoch 1241/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9814\n",
      "Epoch 1242/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0765 - val_accuracy: 0.9783\n",
      "Epoch 1243/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 1244/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0535 - val_accuracy: 0.9845\n",
      "Epoch 1245/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9814\n",
      "Epoch 1246/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 1247/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0590 - val_accuracy: 0.9814\n",
      "Epoch 1248/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0515 - val_accuracy: 0.9845\n",
      "Epoch 1249/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
      "Epoch 1250/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0214 - accuracy: 0.9954 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
      "Epoch 1251/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 1252/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0491 - val_accuracy: 0.9845\n",
      "Epoch 1253/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0671 - val_accuracy: 0.9814\n",
      "Epoch 1254/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0216 - accuracy: 0.9908 - val_loss: 0.0780 - val_accuracy: 0.9752\n",
      "Epoch 1255/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0567 - val_accuracy: 0.9845\n",
      "Epoch 1256/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0522 - val_accuracy: 0.9845\n",
      "Epoch 1257/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0213 - accuracy: 0.9954 - val_loss: 0.0615 - val_accuracy: 0.9845\n",
      "Epoch 1258/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0778 - val_accuracy: 0.9752\n",
      "Epoch 1259/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.0613 - val_accuracy: 0.9814\n",
      "Epoch 1260/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
      "Epoch 1261/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0617 - val_accuracy: 0.9814\n",
      "Epoch 1262/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 0.0798 - val_accuracy: 0.9752\n",
      "Epoch 1263/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0235 - accuracy: 0.9893 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 1264/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0526 - val_accuracy: 0.9845\n",
      "Epoch 1265/3500\n",
      "653/653 [==============================] - 0s 56us/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0601 - val_accuracy: 0.9814\n",
      "Epoch 1266/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9814\n",
      "Epoch 1267/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 1268/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.0562 - val_accuracy: 0.9845\n",
      "Epoch 1269/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9814\n",
      "Epoch 1270/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
      "Epoch 1271/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0483 - val_accuracy: 0.9845\n",
      "Epoch 1272/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.0511 - val_accuracy: 0.9845\n",
      "Epoch 1273/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0638 - val_accuracy: 0.9814\n",
      "Epoch 1274/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9783\n",
      "Epoch 1275/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0560 - val_accuracy: 0.9845\n",
      "Epoch 1276/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0492 - val_accuracy: 0.9845\n",
      "Epoch 1277/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 0.0573 - val_accuracy: 0.9845\n",
      "Epoch 1278/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 1279/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0655 - val_accuracy: 0.9814\n",
      "Epoch 1280/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.0559 - val_accuracy: 0.9845\n",
      "Epoch 1281/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0532 - val_accuracy: 0.9845\n",
      "Epoch 1282/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0583 - val_accuracy: 0.9814\n",
      "Epoch 1283/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 1284/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0661 - val_accuracy: 0.9814\n",
      "Epoch 1285/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0569 - val_accuracy: 0.9814\n",
      "Epoch 1286/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 1287/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0601 - val_accuracy: 0.9814\n",
      "Epoch 1288/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9814\n",
      "Epoch 1289/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9814\n",
      "Epoch 1290/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9814\n",
      "Epoch 1291/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9845\n",
      "Epoch 1292/3500\n",
      "653/653 [==============================] - 0s 33us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0597 - val_accuracy: 0.9845\n",
      "Epoch 1293/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9783\n",
      "Epoch 1294/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9814\n",
      "Epoch 1295/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0189 - accuracy: 0.9985 - val_loss: 0.0556 - val_accuracy: 0.9845\n",
      "Epoch 1296/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0544 - val_accuracy: 0.9845\n",
      "Epoch 1297/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9814\n",
      "Epoch 1298/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9814\n",
      "Epoch 1299/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0607 - val_accuracy: 0.9814\n",
      "Epoch 1300/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9845\n",
      "Epoch 1301/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0617 - val_accuracy: 0.9814\n",
      "Epoch 1302/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9783\n",
      "Epoch 1303/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0608 - val_accuracy: 0.9814\n",
      "Epoch 1304/3500\n",
      "653/653 [==============================] - 0s 95us/step - loss: 0.0184 - accuracy: 0.9969 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 1305/3500\n",
      "653/653 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.99 - 0s 17us/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0612 - val_accuracy: 0.9845\n",
      "Epoch 1306/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 0.0684 - val_accuracy: 0.9814\n",
      "Epoch 1307/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0564 - val_accuracy: 0.9845\n",
      "Epoch 1308/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0577 - val_accuracy: 0.9845\n",
      "Epoch 1309/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9783\n",
      "Epoch 1310/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.0590 - val_accuracy: 0.9845\n",
      "Epoch 1311/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.0488 - val_accuracy: 0.9876\n",
      "Epoch 1312/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0583 - val_accuracy: 0.9845\n",
      "Epoch 1313/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.0847 - val_accuracy: 0.9752\n",
      "Epoch 1314/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0262 - accuracy: 0.9893 - val_loss: 0.0602 - val_accuracy: 0.9814\n",
      "Epoch 1315/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0443 - val_accuracy: 0.9814\n",
      "Epoch 1316/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0546 - val_accuracy: 0.9845\n",
      "Epoch 1317/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0724 - val_accuracy: 0.9752\n",
      "Epoch 1318/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0225 - accuracy: 0.9908 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
      "Epoch 1319/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0494 - val_accuracy: 0.9845\n",
      "Epoch 1320/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.0514 - val_accuracy: 0.9845\n",
      "Epoch 1321/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0676 - val_accuracy: 0.9783\n",
      "Epoch 1322/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0672 - val_accuracy: 0.9783\n",
      "Epoch 1323/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0509 - val_accuracy: 0.9845\n",
      "Epoch 1324/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.0507 - val_accuracy: 0.9845\n",
      "Epoch 1325/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
      "Epoch 1326/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0694 - val_accuracy: 0.9783\n",
      "Epoch 1327/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.0580 - val_accuracy: 0.9845\n",
      "Epoch 1328/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0182 - accuracy: 0.9969 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 1329/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9845\n",
      "Epoch 1330/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0675 - val_accuracy: 0.9814\n",
      "Epoch 1331/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9845\n",
      "Epoch 1332/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9845\n",
      "Epoch 1333/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9845\n",
      "Epoch 1334/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9845\n",
      "Epoch 1335/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0579 - val_accuracy: 0.9845\n",
      "Epoch 1336/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0182 - accuracy: 0.9969 - val_loss: 0.0555 - val_accuracy: 0.9845\n",
      "Epoch 1337/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9845\n",
      "Epoch 1338/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9814\n",
      "Epoch 1339/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 26us/step - loss: 0.0182 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9845\n",
      "Epoch 1340/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0558 - val_accuracy: 0.9845\n",
      "Epoch 1341/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0517 - val_accuracy: 0.9845\n",
      "Epoch 1342/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.0564 - val_accuracy: 0.9845\n",
      "Epoch 1343/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0642 - val_accuracy: 0.9814\n",
      "Epoch 1344/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 1345/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9814\n",
      "Epoch 1346/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0584 - val_accuracy: 0.9845\n",
      "Epoch 1347/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 1348/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0673 - val_accuracy: 0.9814\n",
      "Epoch 1349/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.0636 - val_accuracy: 0.9814\n",
      "Epoch 1350/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0530 - val_accuracy: 0.9845\n",
      "Epoch 1351/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
      "Epoch 1352/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0693 - val_accuracy: 0.9783\n",
      "Epoch 1353/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 1354/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0522 - val_accuracy: 0.9845\n",
      "Epoch 1355/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.0518 - val_accuracy: 0.9845\n",
      "Epoch 1356/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9814\n",
      "Epoch 1357/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0668 - val_accuracy: 0.9814\n",
      "Epoch 1358/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9845\n",
      "Epoch 1359/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9845\n",
      "Epoch 1360/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9845\n",
      "Epoch 1361/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9752\n",
      "Epoch 1362/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0653 - val_accuracy: 0.9814\n",
      "Epoch 1363/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
      "Epoch 1364/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0220 - accuracy: 0.9954 - val_loss: 0.0577 - val_accuracy: 0.9845\n",
      "Epoch 1365/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0792 - val_accuracy: 0.9752\n",
      "Epoch 1366/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.0740 - val_accuracy: 0.9752\n",
      "Epoch 1367/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.0575 - val_accuracy: 0.9845\n",
      "Epoch 1368/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0517 - val_accuracy: 0.9845\n",
      "Epoch 1369/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0585 - val_accuracy: 0.9814\n",
      "Epoch 1370/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9814\n",
      "Epoch 1371/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.0615 - val_accuracy: 0.9814\n",
      "Epoch 1372/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0545 - val_accuracy: 0.9845\n",
      "Epoch 1373/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.0550 - val_accuracy: 0.9845\n",
      "Epoch 1374/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 1375/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9783\n",
      "Epoch 1376/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0569 - val_accuracy: 0.9845\n",
      "Epoch 1377/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0584 - val_accuracy: 0.9845\n",
      "Epoch 1378/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9783\n",
      "Epoch 1379/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.0656 - val_accuracy: 0.9814\n",
      "Epoch 1380/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0498 - val_accuracy: 0.9845\n",
      "Epoch 1381/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0537 - val_accuracy: 0.9845\n",
      "Epoch 1382/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9752\n",
      "Epoch 1383/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 0.0696 - val_accuracy: 0.9783\n",
      "Epoch 1384/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0560 - val_accuracy: 0.9845\n",
      "Epoch 1385/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.0593 - val_accuracy: 0.9845\n",
      "Epoch 1386/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9845\n",
      "Epoch 1387/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0606 - val_accuracy: 0.9845\n",
      "Epoch 1388/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9814\n",
      "Epoch 1389/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9814\n",
      "Epoch 1390/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0615 - val_accuracy: 0.9814\n",
      "Epoch 1391/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9814\n",
      "Epoch 1392/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9783\n",
      "Epoch 1393/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0621 - val_accuracy: 0.9814\n",
      "Epoch 1394/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0540 - val_accuracy: 0.9845\n",
      "Epoch 1395/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 1396/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9783\n",
      "Epoch 1397/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0199 - accuracy: 0.9908 - val_loss: 0.0599 - val_accuracy: 0.9845\n",
      "Epoch 1398/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0487 - val_accuracy: 0.9876\n",
      "Epoch 1399/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.0555 - val_accuracy: 0.9845\n",
      "Epoch 1400/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9814\n",
      "Epoch 1401/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0592 - val_accuracy: 0.9845\n",
      "Epoch 1402/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0533 - val_accuracy: 0.9845\n",
      "Epoch 1403/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0674 - val_accuracy: 0.9814\n",
      "Epoch 1404/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0816 - val_accuracy: 0.9752\n",
      "Epoch 1405/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.0562 - val_accuracy: 0.9845\n",
      "Epoch 1406/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0502 - val_accuracy: 0.9845\n",
      "Epoch 1407/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 0.0595 - val_accuracy: 0.9845\n",
      "Epoch 1408/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9814\n",
      "Epoch 1409/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0665 - val_accuracy: 0.9814\n",
      "Epoch 1410/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9845\n",
      "Epoch 1411/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9845\n",
      "Epoch 1412/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9783\n",
      "Epoch 1413/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.0808 - val_accuracy: 0.9752\n",
      "Epoch 1414/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9845\n",
      "Epoch 1415/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0530 - val_accuracy: 0.9845\n",
      "Epoch 1416/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9845\n",
      "Epoch 1417/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0638 - val_accuracy: 0.9845\n",
      "Epoch 1418/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0573 - val_accuracy: 0.9845\n",
      "Epoch 1419/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.0701 - val_accuracy: 0.9814\n",
      "Epoch 1420/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0821 - val_accuracy: 0.9752\n",
      "Epoch 1421/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 0.0601 - val_accuracy: 0.9845\n",
      "Epoch 1422/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0549 - val_accuracy: 0.9845\n",
      "Epoch 1423/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 1424/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0658 - val_accuracy: 0.9814\n",
      "Epoch 1425/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0614 - val_accuracy: 0.9845\n",
      "Epoch 1426/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9814\n",
      "Epoch 1427/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0824 - val_accuracy: 0.9752\n",
      "Epoch 1428/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0733 - val_accuracy: 0.9814\n",
      "Epoch 1429/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 1430/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9845\n",
      "Epoch 1431/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0793 - val_accuracy: 0.9752\n",
      "Epoch 1432/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0711 - val_accuracy: 0.9814\n",
      "Epoch 1433/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0542 - val_accuracy: 0.9845\n",
      "Epoch 1434/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0190 - accuracy: 0.9969 - val_loss: 0.0559 - val_accuracy: 0.9845\n",
      "Epoch 1435/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9814\n",
      "Epoch 1436/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9783\n",
      "Epoch 1437/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.0632 - val_accuracy: 0.9845\n",
      "Epoch 1438/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0572 - val_accuracy: 0.9845\n",
      "Epoch 1439/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0578 - val_accuracy: 0.9845\n",
      "Epoch 1440/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9783\n",
      "Epoch 1441/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9783\n",
      "Epoch 1442/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0604 - val_accuracy: 0.9845\n",
      "Epoch 1443/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9845\n",
      "Epoch 1444/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9783\n",
      "Epoch 1445/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9783\n",
      "Epoch 1446/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9845\n",
      "Epoch 1447/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.0615 - val_accuracy: 0.9845\n",
      "Epoch 1448/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0665 - val_accuracy: 0.9814\n",
      "Epoch 1449/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 52us/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.0594 - val_accuracy: 0.9845\n",
      "Epoch 1450/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 1451/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0747 - val_accuracy: 0.9783\n",
      "Epoch 1452/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
      "Epoch 1453/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0546 - val_accuracy: 0.9845\n",
      "Epoch 1454/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0565 - val_accuracy: 0.9845\n",
      "Epoch 1455/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.0606 - val_accuracy: 0.9845\n",
      "Epoch 1456/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9845\n",
      "Epoch 1457/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9845\n",
      "Epoch 1458/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 1459/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9845\n",
      "Epoch 1460/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0716 - val_accuracy: 0.9814\n",
      "Epoch 1461/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9845\n",
      "Epoch 1462/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0619 - val_accuracy: 0.9845\n",
      "Epoch 1463/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9845\n",
      "Epoch 1464/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0628 - val_accuracy: 0.9845\n",
      "Epoch 1465/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9845\n",
      "Epoch 1466/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9814\n",
      "Epoch 1467/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9814\n",
      "Epoch 1468/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0599 - val_accuracy: 0.9845\n",
      "Epoch 1469/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9845\n",
      "Epoch 1470/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9814\n",
      "Epoch 1471/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0674 - val_accuracy: 0.9814\n",
      "Epoch 1472/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0619 - val_accuracy: 0.9845\n",
      "Epoch 1473/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0613 - val_accuracy: 0.9845\n",
      "Epoch 1474/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9845\n",
      "Epoch 1475/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9845\n",
      "Epoch 1476/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.0551 - val_accuracy: 0.9845\n",
      "Epoch 1477/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9814\n",
      "Epoch 1478/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9752\n",
      "Epoch 1479/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0698 - val_accuracy: 0.9814\n",
      "Epoch 1480/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9845\n",
      "Epoch 1481/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.0557 - val_accuracy: 0.9876\n",
      "Epoch 1482/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0636 - val_accuracy: 0.9845\n",
      "Epoch 1483/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9814\n",
      "Epoch 1484/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9814\n",
      "Epoch 1485/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0613 - val_accuracy: 0.9845\n",
      "Epoch 1486/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0570 - val_accuracy: 0.9845\n",
      "Epoch 1487/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0182 - accuracy: 0.9969 - val_loss: 0.0647 - val_accuracy: 0.9845\n",
      "Epoch 1488/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9814\n",
      "Epoch 1489/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0711 - val_accuracy: 0.9814\n",
      "Epoch 1490/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0607 - val_accuracy: 0.9845\n",
      "Epoch 1491/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.0614 - val_accuracy: 0.9845\n",
      "Epoch 1492/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0767 - val_accuracy: 0.9752\n",
      "Epoch 1493/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0640 - val_accuracy: 0.9845\n",
      "Epoch 1494/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0548 - val_accuracy: 0.9845\n",
      "Epoch 1495/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9814\n",
      "Epoch 1496/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0800 - val_accuracy: 0.9752\n",
      "Epoch 1497/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0192 - accuracy: 0.9954 - val_loss: 0.0607 - val_accuracy: 0.9845\n",
      "Epoch 1498/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0554 - val_accuracy: 0.9845\n",
      "Epoch 1499/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9845\n",
      "Epoch 1500/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
      "Epoch 1501/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0664 - val_accuracy: 0.9845\n",
      "Epoch 1502/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0556 - val_accuracy: 0.9845\n",
      "Epoch 1503/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.0571 - val_accuracy: 0.9845\n",
      "Epoch 1504/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9783\n",
      "Epoch 1505/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.0774 - val_accuracy: 0.9752\n",
      "Epoch 1506/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
      "Epoch 1507/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0281 - accuracy: 0.9893 - val_loss: 0.0560 - val_accuracy: 0.9845\n",
      "Epoch 1508/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0906 - val_accuracy: 0.9752\n",
      "Epoch 1509/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0250 - accuracy: 0.9862 - val_loss: 0.0650 - val_accuracy: 0.9845\n",
      "Epoch 1510/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0541 - val_accuracy: 0.9876\n",
      "Epoch 1511/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0639 - val_accuracy: 0.9845\n",
      "Epoch 1512/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9783\n",
      "Epoch 1513/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0629 - val_accuracy: 0.9845\n",
      "Epoch 1514/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0600 - val_accuracy: 0.9845\n",
      "Epoch 1515/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0664 - val_accuracy: 0.9845\n",
      "Epoch 1516/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
      "Epoch 1517/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9814\n",
      "Epoch 1518/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9814\n",
      "Epoch 1519/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0644 - val_accuracy: 0.9845\n",
      "Epoch 1520/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
      "Epoch 1521/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.0702 - val_accuracy: 0.9845\n",
      "Epoch 1522/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0804 - val_accuracy: 0.9783\n",
      "Epoch 1523/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 1524/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.0559 - val_accuracy: 0.9845\n",
      "Epoch 1525/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0676 - val_accuracy: 0.9845\n",
      "Epoch 1526/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9783\n",
      "Epoch 1527/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0819 - val_accuracy: 0.9752\n",
      "Epoch 1528/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0663 - val_accuracy: 0.9845\n",
      "Epoch 1529/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0563 - val_accuracy: 0.9876\n",
      "Epoch 1530/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0599 - val_accuracy: 0.9845\n",
      "Epoch 1531/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9814\n",
      "Epoch 1532/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0681 - val_accuracy: 0.9814\n",
      "Epoch 1533/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0603 - val_accuracy: 0.9845\n",
      "Epoch 1534/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0577 - val_accuracy: 0.9845\n",
      "Epoch 1535/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0665 - val_accuracy: 0.9845\n",
      "Epoch 1536/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9783\n",
      "Epoch 1537/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 1538/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0601 - val_accuracy: 0.9845\n",
      "Epoch 1539/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9783\n",
      "Epoch 1540/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0765 - val_accuracy: 0.9752\n",
      "Epoch 1541/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0581 - val_accuracy: 0.9876\n",
      "Epoch 1542/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0529 - val_accuracy: 0.9876\n",
      "Epoch 1543/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0610 - val_accuracy: 0.9845\n",
      "Epoch 1544/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0751 - val_accuracy: 0.9814\n",
      "Epoch 1545/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0675 - val_accuracy: 0.9845\n",
      "Epoch 1546/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9876\n",
      "Epoch 1547/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0664 - val_accuracy: 0.9845\n",
      "Epoch 1548/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9783\n",
      "Epoch 1549/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9845\n",
      "Epoch 1550/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9845\n",
      "Epoch 1551/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9845\n",
      "Epoch 1552/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
      "Epoch 1553/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
      "Epoch 1554/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9845\n",
      "Epoch 1555/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0653 - val_accuracy: 0.9845\n",
      "Epoch 1556/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9752\n",
      "Epoch 1557/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9814\n",
      "Epoch 1558/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0658 - val_accuracy: 0.9876\n",
      "Epoch 1559/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 12us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0702 - val_accuracy: 0.9814\n",
      "Epoch 1560/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9783\n",
      "Epoch 1561/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9814\n",
      "Epoch 1562/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0613 - val_accuracy: 0.9845\n",
      "Epoch 1563/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9845\n",
      "Epoch 1564/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0659 - val_accuracy: 0.9845\n",
      "Epoch 1565/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9814\n",
      "Epoch 1566/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 1567/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0642 - val_accuracy: 0.9845\n",
      "Epoch 1568/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9845\n",
      "Epoch 1569/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9845\n",
      "Epoch 1570/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9814\n",
      "Epoch 1571/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9814\n",
      "Epoch 1572/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0628 - val_accuracy: 0.9845\n",
      "Epoch 1573/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0587 - val_accuracy: 0.9845\n",
      "Epoch 1574/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9845\n",
      "Epoch 1575/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9814\n",
      "Epoch 1576/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9845\n",
      "Epoch 1577/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0638 - val_accuracy: 0.9845\n",
      "Epoch 1578/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0621 - val_accuracy: 0.9845\n",
      "Epoch 1579/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0670 - val_accuracy: 0.9845\n",
      "Epoch 1580/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
      "Epoch 1581/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0612 - val_accuracy: 0.9845\n",
      "Epoch 1582/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0544 - val_accuracy: 0.9876\n",
      "Epoch 1583/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0611 - val_accuracy: 0.9845\n",
      "Epoch 1584/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9845\n",
      "Epoch 1585/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9783\n",
      "Epoch 1586/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0625 - val_accuracy: 0.9845\n",
      "Epoch 1587/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0577 - val_accuracy: 0.9845\n",
      "Epoch 1588/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9845\n",
      "Epoch 1589/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9814\n",
      "Epoch 1590/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
      "Epoch 1591/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9845\n",
      "Epoch 1592/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0618 - val_accuracy: 0.9845\n",
      "Epoch 1593/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9845\n",
      "Epoch 1594/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0663 - val_accuracy: 0.9845\n",
      "Epoch 1595/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9845\n",
      "Epoch 1596/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9845\n",
      "Epoch 1597/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0653 - val_accuracy: 0.9845\n",
      "Epoch 1598/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9814\n",
      "Epoch 1599/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0718 - val_accuracy: 0.9845\n",
      "Epoch 1600/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 1601/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0609 - val_accuracy: 0.9845\n",
      "Epoch 1602/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0629 - val_accuracy: 0.9845\n",
      "Epoch 1603/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9845\n",
      "Epoch 1604/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9845\n",
      "Epoch 1605/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0624 - val_accuracy: 0.9845\n",
      "Epoch 1606/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9845\n",
      "Epoch 1607/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9845\n",
      "Epoch 1608/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0662 - val_accuracy: 0.9845\n",
      "Epoch 1609/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9845\n",
      "Epoch 1610/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9845\n",
      "Epoch 1611/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9814\n",
      "Epoch 1612/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9845\n",
      "Epoch 1613/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0610 - val_accuracy: 0.9845\n",
      "Epoch 1614/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0613 - val_accuracy: 0.9845\n",
      "Epoch 1615/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
      "Epoch 1616/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9845\n",
      "Epoch 1617/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9876\n",
      "Epoch 1618/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9845\n",
      "Epoch 1619/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
      "Epoch 1620/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9814\n",
      "Epoch 1621/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9845\n",
      "Epoch 1622/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0594 - val_accuracy: 0.9876\n",
      "Epoch 1623/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0575 - val_accuracy: 0.9876\n",
      "Epoch 1624/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0632 - val_accuracy: 0.9845\n",
      "Epoch 1625/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0664 - val_accuracy: 0.9845\n",
      "Epoch 1626/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0700 - val_accuracy: 0.9814\n",
      "Epoch 1627/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
      "Epoch 1628/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0608 - val_accuracy: 0.9845\n",
      "Epoch 1629/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 1630/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0751 - val_accuracy: 0.9783\n",
      "Epoch 1631/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9876\n",
      "Epoch 1632/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0594 - val_accuracy: 0.9876\n",
      "Epoch 1633/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0691 - val_accuracy: 0.9845\n",
      "Epoch 1634/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9783\n",
      "Epoch 1635/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0720 - val_accuracy: 0.9845\n",
      "Epoch 1636/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9845\n",
      "Epoch 1637/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9845\n",
      "Epoch 1638/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0692 - val_accuracy: 0.9814\n",
      "Epoch 1639/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9845\n",
      "Epoch 1640/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0662 - val_accuracy: 0.9845\n",
      "Epoch 1641/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
      "Epoch 1642/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0679 - val_accuracy: 0.9845\n",
      "Epoch 1643/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0615 - val_accuracy: 0.9845\n",
      "Epoch 1644/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9783\n",
      "Epoch 1645/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0709 - val_accuracy: 0.9845\n",
      "Epoch 1646/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9845\n",
      "Epoch 1647/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0675 - val_accuracy: 0.9845\n",
      "Epoch 1648/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9845\n",
      "Epoch 1649/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9845\n",
      "Epoch 1650/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9845\n",
      "Epoch 1651/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9845\n",
      "Epoch 1652/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0658 - val_accuracy: 0.9845\n",
      "Epoch 1653/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0642 - val_accuracy: 0.9845\n",
      "Epoch 1654/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
      "Epoch 1655/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0671 - val_accuracy: 0.9845\n",
      "Epoch 1656/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0657 - val_accuracy: 0.9845\n",
      "Epoch 1657/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
      "Epoch 1658/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 1659/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0637 - val_accuracy: 0.9845\n",
      "Epoch 1660/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0652 - val_accuracy: 0.9845\n",
      "Epoch 1661/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0728 - val_accuracy: 0.9814\n",
      "Epoch 1662/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0659 - val_accuracy: 0.9845\n",
      "Epoch 1663/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0647 - val_accuracy: 0.9845\n",
      "Epoch 1664/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0687 - val_accuracy: 0.9845\n",
      "Epoch 1665/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9845\n",
      "Epoch 1666/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0641 - val_accuracy: 0.9845\n",
      "Epoch 1667/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9876\n",
      "Epoch 1668/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
      "Epoch 1669/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0819 - val_accuracy: 0.9752\n",
      "Epoch 1670/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0628 - val_accuracy: 0.9845\n",
      "Epoch 1671/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0617 - val_accuracy: 0.9845\n",
      "Epoch 1672/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9814\n",
      "Epoch 1673/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9814\n",
      "Epoch 1674/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9845\n",
      "Epoch 1675/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0652 - val_accuracy: 0.9845\n",
      "Epoch 1676/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9845\n",
      "Epoch 1677/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9814\n",
      "Epoch 1678/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9845\n",
      "Epoch 1679/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9845\n",
      "Epoch 1680/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9752\n",
      "Epoch 1681/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0700 - val_accuracy: 0.9814\n",
      "Epoch 1682/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0609 - val_accuracy: 0.9876\n",
      "Epoch 1683/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0638 - val_accuracy: 0.9845\n",
      "Epoch 1684/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0727 - val_accuracy: 0.9814\n",
      "Epoch 1685/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9845\n",
      "Epoch 1686/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0596 - val_accuracy: 0.9876\n",
      "Epoch 1687/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0718 - val_accuracy: 0.9814\n",
      "Epoch 1688/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0857 - val_accuracy: 0.9752\n",
      "Epoch 1689/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0691 - val_accuracy: 0.9845\n",
      "Epoch 1690/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9876\n",
      "Epoch 1691/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0618 - val_accuracy: 0.9845\n",
      "Epoch 1692/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9845\n",
      "Epoch 1693/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9845\n",
      "Epoch 1694/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0650 - val_accuracy: 0.9845\n",
      "Epoch 1695/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0652 - val_accuracy: 0.9845\n",
      "Epoch 1696/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9845\n",
      "Epoch 1697/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0666 - val_accuracy: 0.9845\n",
      "Epoch 1698/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0745 - val_accuracy: 0.9814\n",
      "Epoch 1699/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 0.0795 - val_accuracy: 0.9752\n",
      "Epoch 1700/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9845\n",
      "Epoch 1701/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0600 - val_accuracy: 0.9876\n",
      "Epoch 1702/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0641 - val_accuracy: 0.9845\n",
      "Epoch 1703/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9845\n",
      "Epoch 1704/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0688 - val_accuracy: 0.9845\n",
      "Epoch 1705/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0723 - val_accuracy: 0.9814\n",
      "Epoch 1706/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0663 - val_accuracy: 0.9845\n",
      "Epoch 1707/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0684 - val_accuracy: 0.9845\n",
      "Epoch 1708/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0793 - val_accuracy: 0.9752\n",
      "Epoch 1709/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 1710/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0546 - val_accuracy: 0.9876\n",
      "Epoch 1711/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0657 - val_accuracy: 0.9845\n",
      "Epoch 1712/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0941 - val_accuracy: 0.9752\n",
      "Epoch 1713/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 1714/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0544 - val_accuracy: 0.9876\n",
      "Epoch 1715/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0726 - val_accuracy: 0.9814\n",
      "Epoch 1716/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.1070 - val_accuracy: 0.9720\n",
      "Epoch 1717/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0309 - accuracy: 0.9847 - val_loss: 0.0601 - val_accuracy: 0.9876\n",
      "Epoch 1718/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0577 - val_accuracy: 0.9814\n",
      "Epoch 1719/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0257 - accuracy: 0.9893 - val_loss: 0.0795 - val_accuracy: 0.9783\n",
      "Epoch 1720/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0206 - accuracy: 0.9893 - val_loss: 0.0939 - val_accuracy: 0.9752\n",
      "Epoch 1721/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.0518 - val_accuracy: 0.9876\n",
      "Epoch 1722/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0498 - val_accuracy: 0.9783\n",
      "Epoch 1723/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0232 - accuracy: 0.9908 - val_loss: 0.0763 - val_accuracy: 0.9783\n",
      "Epoch 1724/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.1119 - val_accuracy: 0.9720\n",
      "Epoch 1725/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0335 - accuracy: 0.9862 - val_loss: 0.0594 - val_accuracy: 0.9876\n",
      "Epoch 1726/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0552 - val_accuracy: 0.9814\n",
      "Epoch 1727/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 0.0823 - val_accuracy: 0.9783\n",
      "Epoch 1728/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.1066 - val_accuracy: 0.9752\n",
      "Epoch 1729/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0291 - accuracy: 0.9832 - val_loss: 0.0600 - val_accuracy: 0.9845\n",
      "Epoch 1730/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0550 - val_accuracy: 0.9783\n",
      "Epoch 1731/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0312 - accuracy: 0.9893 - val_loss: 0.0689 - val_accuracy: 0.9814\n",
      "Epoch 1732/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.1016 - val_accuracy: 0.9720\n",
      "Epoch 1733/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0290 - accuracy: 0.9877 - val_loss: 0.0649 - val_accuracy: 0.9845\n",
      "Epoch 1734/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0507 - val_accuracy: 0.9876\n",
      "Epoch 1735/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0214 - accuracy: 0.9954 - val_loss: 0.0590 - val_accuracy: 0.9876\n",
      "Epoch 1736/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 1737/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0713 - val_accuracy: 0.9814\n",
      "Epoch 1738/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0619 - val_accuracy: 0.9845\n",
      "Epoch 1739/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0669 - val_accuracy: 0.9845\n",
      "Epoch 1740/3500\n",
      "653/653 [==============================] - 0s 87us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0841 - val_accuracy: 0.9783\n",
      "Epoch 1741/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0831 - val_accuracy: 0.9783\n",
      "Epoch 1742/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0614 - val_accuracy: 0.9845\n",
      "Epoch 1743/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0609 - val_accuracy: 0.9876\n",
      "Epoch 1744/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0819 - val_accuracy: 0.9752\n",
      "Epoch 1745/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0839 - val_accuracy: 0.9752\n",
      "Epoch 1746/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9876\n",
      "Epoch 1747/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9876\n",
      "Epoch 1748/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 1749/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9845\n",
      "Epoch 1750/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0633 - val_accuracy: 0.9845\n",
      "Epoch 1751/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9845\n",
      "Epoch 1752/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9814\n",
      "Epoch 1753/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0683 - val_accuracy: 0.9845\n",
      "Epoch 1754/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9876\n",
      "Epoch 1755/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.0620 - val_accuracy: 0.9876\n",
      "Epoch 1756/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
      "Epoch 1757/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0744 - val_accuracy: 0.9783\n",
      "Epoch 1758/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0591 - val_accuracy: 0.9876\n",
      "Epoch 1759/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0577 - val_accuracy: 0.9876\n",
      "Epoch 1760/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0740 - val_accuracy: 0.9814\n",
      "Epoch 1761/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0817 - val_accuracy: 0.9752\n",
      "Epoch 1762/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0690 - val_accuracy: 0.9845\n",
      "Epoch 1763/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0606 - val_accuracy: 0.9876\n",
      "Epoch 1764/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0675 - val_accuracy: 0.9845\n",
      "Epoch 1765/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0797 - val_accuracy: 0.9783\n",
      "Epoch 1766/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
      "Epoch 1767/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9876\n",
      "Epoch 1768/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9845\n",
      "Epoch 1769/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9783\n",
      "Epoch 1770/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 1771/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0596 - val_accuracy: 0.9876\n",
      "Epoch 1772/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
      "Epoch 1773/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0869 - val_accuracy: 0.9752\n",
      "Epoch 1774/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0684 - val_accuracy: 0.9845\n",
      "Epoch 1775/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9876\n",
      "Epoch 1776/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0700 - val_accuracy: 0.9845\n",
      "Epoch 1777/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.1027 - val_accuracy: 0.9720\n",
      "Epoch 1778/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.0646 - val_accuracy: 0.9876\n",
      "Epoch 1779/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 51us/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.0537 - val_accuracy: 0.9876\n",
      "Epoch 1780/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.0704 - val_accuracy: 0.9845\n",
      "Epoch 1781/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0887 - val_accuracy: 0.9752\n",
      "Epoch 1782/3500\n",
      "653/653 [==============================] - 0s 22us/step - loss: 0.0203 - accuracy: 0.9954 - val_loss: 0.0673 - val_accuracy: 0.9876\n",
      "Epoch 1783/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
      "Epoch 1784/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9845\n",
      "Epoch 1785/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0138 - accuracy: 0.9985 - val_loss: 0.0808 - val_accuracy: 0.9752\n",
      "Epoch 1786/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 0.0717 - val_accuracy: 0.9814\n",
      "Epoch 1787/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0553 - val_accuracy: 0.9876\n",
      "Epoch 1788/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9876\n",
      "Epoch 1789/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0821 - val_accuracy: 0.9752\n",
      "Epoch 1790/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0822 - val_accuracy: 0.9783\n",
      "Epoch 1791/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0629 - val_accuracy: 0.9876\n",
      "Epoch 1792/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0622 - val_accuracy: 0.9876\n",
      "Epoch 1793/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
      "Epoch 1794/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0719 - val_accuracy: 0.9845\n",
      "Epoch 1795/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0594 - val_accuracy: 0.9876\n",
      "Epoch 1796/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9876\n",
      "Epoch 1797/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0752 - val_accuracy: 0.9845\n",
      "Epoch 1798/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0836 - val_accuracy: 0.9752\n",
      "Epoch 1799/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9845\n",
      "Epoch 1800/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 1801/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9845\n",
      "Epoch 1802/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0731 - val_accuracy: 0.9814\n",
      "Epoch 1803/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0660 - val_accuracy: 0.9845\n",
      "Epoch 1804/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0600 - val_accuracy: 0.9876\n",
      "Epoch 1805/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0607 - val_accuracy: 0.9876\n",
      "Epoch 1806/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9876\n",
      "Epoch 1807/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 1808/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0738 - val_accuracy: 0.9814\n",
      "Epoch 1809/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9845\n",
      "Epoch 1810/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0648 - val_accuracy: 0.9845\n",
      "Epoch 1811/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0745 - val_accuracy: 0.9814\n",
      "Epoch 1812/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9845\n",
      "Epoch 1813/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9876\n",
      "Epoch 1814/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0636 - val_accuracy: 0.9876\n",
      "Epoch 1815/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0641 - val_accuracy: 0.9876\n",
      "Epoch 1816/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9845\n",
      "Epoch 1817/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9783\n",
      "Epoch 1818/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
      "Epoch 1819/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0655 - val_accuracy: 0.9876\n",
      "Epoch 1820/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9876\n",
      "Epoch 1821/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0666 - val_accuracy: 0.9876\n",
      "Epoch 1822/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9783\n",
      "Epoch 1823/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0673 - val_accuracy: 0.9845\n",
      "Epoch 1824/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9876\n",
      "Epoch 1825/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 1826/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9845\n",
      "Epoch 1827/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0621 - val_accuracy: 0.9876\n",
      "Epoch 1828/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9876\n",
      "Epoch 1829/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 1830/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 1831/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0668 - val_accuracy: 0.9876\n",
      "Epoch 1832/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0650 - val_accuracy: 0.9876\n",
      "Epoch 1833/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 1834/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9783\n",
      "Epoch 1835/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0808 - val_accuracy: 0.9752\n",
      "Epoch 1836/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 1837/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0590 - val_accuracy: 0.9876\n",
      "Epoch 1838/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0705 - val_accuracy: 0.9845\n",
      "Epoch 1839/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9814\n",
      "Epoch 1840/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9814\n",
      "Epoch 1841/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 1842/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0813 - val_accuracy: 0.9783\n",
      "Epoch 1843/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0730 - val_accuracy: 0.9814\n",
      "Epoch 1844/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0629 - val_accuracy: 0.9876\n",
      "Epoch 1845/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0645 - val_accuracy: 0.9876\n",
      "Epoch 1846/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9845\n",
      "Epoch 1847/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0834 - val_accuracy: 0.9752\n",
      "Epoch 1848/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0703 - val_accuracy: 0.9814\n",
      "Epoch 1849/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9876\n",
      "Epoch 1850/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9876\n",
      "Epoch 1851/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9783\n",
      "Epoch 1852/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9876\n",
      "Epoch 1853/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9876\n",
      "Epoch 1854/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0628 - val_accuracy: 0.9876\n",
      "Epoch 1855/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9783\n",
      "Epoch 1856/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0801 - val_accuracy: 0.9783\n",
      "Epoch 1857/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "Epoch 1858/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9876\n",
      "Epoch 1859/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9814\n",
      "Epoch 1860/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0897 - val_accuracy: 0.9752\n",
      "Epoch 1861/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0795 - val_accuracy: 0.9783\n",
      "Epoch 1862/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0624 - val_accuracy: 0.9876\n",
      "Epoch 1863/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0584 - val_accuracy: 0.9876\n",
      "Epoch 1864/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0704 - val_accuracy: 0.9845\n",
      "Epoch 1865/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9752\n",
      "Epoch 1866/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0670 - val_accuracy: 0.9876\n",
      "Epoch 1867/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0624 - val_accuracy: 0.9876\n",
      "Epoch 1868/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9845\n",
      "Epoch 1869/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9814\n",
      "Epoch 1870/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0675 - val_accuracy: 0.9876\n",
      "Epoch 1871/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0618 - val_accuracy: 0.9876\n",
      "Epoch 1872/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9876\n",
      "Epoch 1873/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9814\n",
      "Epoch 1874/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0888 - val_accuracy: 0.9752\n",
      "Epoch 1875/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 0.0735 - val_accuracy: 0.9814\n",
      "Epoch 1876/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0637 - val_accuracy: 0.9876\n",
      "Epoch 1877/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0723 - val_accuracy: 0.9845\n",
      "Epoch 1878/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9783\n",
      "Epoch 1879/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9876\n",
      "Epoch 1880/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0637 - val_accuracy: 0.9876\n",
      "Epoch 1881/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0637 - val_accuracy: 0.9876\n",
      "Epoch 1882/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 1883/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0742 - val_accuracy: 0.9845\n",
      "Epoch 1884/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9845\n",
      "Epoch 1885/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0665 - val_accuracy: 0.9876\n",
      "Epoch 1886/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.0702 - val_accuracy: 0.9845\n",
      "Epoch 1887/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9814\n",
      "Epoch 1888/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9814\n",
      "Epoch 1889/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 14us/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0645 - val_accuracy: 0.9876\n",
      "Epoch 1890/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9876\n",
      "Epoch 1891/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9752\n",
      "Epoch 1892/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0727 - val_accuracy: 0.9814\n",
      "Epoch 1893/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0569 - val_accuracy: 0.9876\n",
      "Epoch 1894/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0613 - val_accuracy: 0.9876\n",
      "Epoch 1895/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9814\n",
      "Epoch 1896/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0747 - val_accuracy: 0.9814\n",
      "Epoch 1897/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0657 - val_accuracy: 0.9876\n",
      "Epoch 1898/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0636 - val_accuracy: 0.9876\n",
      "Epoch 1899/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 1900/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0896 - val_accuracy: 0.9752\n",
      "Epoch 1901/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0690 - val_accuracy: 0.9845\n",
      "Epoch 1902/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0601 - val_accuracy: 0.9876\n",
      "Epoch 1903/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0638 - val_accuracy: 0.9876\n",
      "Epoch 1904/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0792 - val_accuracy: 0.9814\n",
      "Epoch 1905/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9783\n",
      "Epoch 1906/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9876\n",
      "Epoch 1907/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0642 - val_accuracy: 0.9876\n",
      "Epoch 1908/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9814\n",
      "Epoch 1909/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0731 - val_accuracy: 0.9845\n",
      "Epoch 1910/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0633 - val_accuracy: 0.9876\n",
      "Epoch 1911/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0603 - val_accuracy: 0.9876\n",
      "Epoch 1912/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9845\n",
      "Epoch 1913/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0832 - val_accuracy: 0.9783\n",
      "Epoch 1914/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.0718 - val_accuracy: 0.9814\n",
      "Epoch 1915/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0638 - val_accuracy: 0.9876\n",
      "Epoch 1916/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9876\n",
      "Epoch 1917/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0725 - val_accuracy: 0.9845\n",
      "Epoch 1918/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0808 - val_accuracy: 0.9783\n",
      "Epoch 1919/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9814\n",
      "Epoch 1920/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 1921/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0602 - val_accuracy: 0.9876\n",
      "Epoch 1922/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9876\n",
      "Epoch 1923/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0745 - val_accuracy: 0.9814\n",
      "Epoch 1924/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9876\n",
      "Epoch 1925/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "Epoch 1926/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 1927/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0837 - val_accuracy: 0.9752\n",
      "Epoch 1928/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9845\n",
      "Epoch 1929/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0658 - val_accuracy: 0.9876\n",
      "Epoch 1930/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0680 - val_accuracy: 0.9876\n",
      "Epoch 1931/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9814\n",
      "Epoch 1932/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 1933/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0670 - val_accuracy: 0.9876\n",
      "Epoch 1934/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9876\n",
      "Epoch 1935/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0704 - val_accuracy: 0.9845\n",
      "Epoch 1936/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9845\n",
      "Epoch 1937/3500\n",
      "653/653 [==============================] - 0s 22us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9845\n",
      "Epoch 1938/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 1939/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9845\n",
      "Epoch 1940/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9845\n",
      "Epoch 1941/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9814\n",
      "Epoch 1942/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9814\n",
      "Epoch 1943/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 1944/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0633 - val_accuracy: 0.9876\n",
      "Epoch 1945/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9876\n",
      "Epoch 1946/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9845\n",
      "Epoch 1947/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0668 - val_accuracy: 0.9876\n",
      "Epoch 1948/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9876\n",
      "Epoch 1949/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0750 - val_accuracy: 0.9814\n",
      "Epoch 1950/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0824 - val_accuracy: 0.9783\n",
      "Epoch 1951/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 1952/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 1953/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9752\n",
      "Epoch 1954/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0687 - val_accuracy: 0.9876\n",
      "Epoch 1955/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0587 - val_accuracy: 0.9845\n",
      "Epoch 1956/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0669 - val_accuracy: 0.9876\n",
      "Epoch 1957/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9783\n",
      "Epoch 1958/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9814\n",
      "Epoch 1959/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9876\n",
      "Epoch 1960/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0693 - val_accuracy: 0.9814\n",
      "Epoch 1961/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9814\n",
      "Epoch 1962/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9814\n",
      "Epoch 1963/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0631 - val_accuracy: 0.9876\n",
      "Epoch 1964/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9845\n",
      "Epoch 1965/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0671 - val_accuracy: 0.9876\n",
      "Epoch 1966/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
      "Epoch 1967/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9783\n",
      "Epoch 1968/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0828 - val_accuracy: 0.9752\n",
      "Epoch 1969/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9876\n",
      "Epoch 1970/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0615 - val_accuracy: 0.9876\n",
      "Epoch 1971/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0166 - accuracy: 0.9923 - val_loss: 0.0735 - val_accuracy: 0.9845\n",
      "Epoch 1972/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0848 - val_accuracy: 0.9752\n",
      "Epoch 1973/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9876\n",
      "Epoch 1974/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9876\n",
      "Epoch 1975/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0640 - val_accuracy: 0.9876\n",
      "Epoch 1976/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0808 - val_accuracy: 0.9783\n",
      "Epoch 1977/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0792 - val_accuracy: 0.9783\n",
      "Epoch 1978/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9876\n",
      "Epoch 1979/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0581 - val_accuracy: 0.9876\n",
      "Epoch 1980/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0674 - val_accuracy: 0.9845\n",
      "Epoch 1981/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.0836 - val_accuracy: 0.9752\n",
      "Epoch 1982/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0762 - val_accuracy: 0.9814\n",
      "Epoch 1983/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0609 - val_accuracy: 0.9876\n",
      "Epoch 1984/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0603 - val_accuracy: 0.9876\n",
      "Epoch 1985/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.0717 - val_accuracy: 0.9876\n",
      "Epoch 1986/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
      "Epoch 1987/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9876\n",
      "Epoch 1988/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0657 - val_accuracy: 0.9876\n",
      "Epoch 1989/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0792 - val_accuracy: 0.9783\n",
      "Epoch 1990/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0694 - val_accuracy: 0.9876\n",
      "Epoch 1991/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0606 - val_accuracy: 0.9814\n",
      "Epoch 1992/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0242 - accuracy: 0.9908 - val_loss: 0.0695 - val_accuracy: 0.9814\n",
      "Epoch 1993/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
      "Epoch 1994/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0652 - val_accuracy: 0.9876\n",
      "Epoch 1995/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9876\n",
      "Epoch 1996/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0747 - val_accuracy: 0.9845\n",
      "Epoch 1997/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0923 - val_accuracy: 0.9752\n",
      "Epoch 1998/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0692 - val_accuracy: 0.9845\n",
      "Epoch 1999/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9939 - val_loss: 0.0579 - val_accuracy: 0.9845\n",
      "Epoch 2000/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.0693 - val_accuracy: 0.9814\n",
      "Epoch 2001/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9814\n",
      "Epoch 2002/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0647 - val_accuracy: 0.9814\n",
      "Epoch 2003/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9814\n",
      "Epoch 2004/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9814\n",
      "Epoch 2005/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9814\n",
      "Epoch 2006/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0691 - val_accuracy: 0.9845\n",
      "Epoch 2007/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9814\n",
      "Epoch 2008/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0792 - val_accuracy: 0.9814\n",
      "Epoch 2009/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9845\n",
      "Epoch 2010/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9876\n",
      "Epoch 2011/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0629 - val_accuracy: 0.9876\n",
      "Epoch 2012/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 2013/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9939 - val_loss: 0.0805 - val_accuracy: 0.9814\n",
      "Epoch 2014/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.0763 - val_accuracy: 0.9814\n",
      "Epoch 2015/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9845\n",
      "Epoch 2016/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 2017/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9814\n",
      "Epoch 2018/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0642 - val_accuracy: 0.9876\n",
      "Epoch 2019/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0602 - val_accuracy: 0.9783\n",
      "Epoch 2020/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 2021/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0856 - val_accuracy: 0.9814\n",
      "Epoch 2022/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0169 - accuracy: 0.9923 - val_loss: 0.0765 - val_accuracy: 0.9814\n",
      "Epoch 2023/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9845\n",
      "Epoch 2024/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9876\n",
      "Epoch 2025/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 2026/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9876\n",
      "Epoch 2027/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9876\n",
      "Epoch 2028/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9876\n",
      "Epoch 2029/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9876\n",
      "Epoch 2030/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
      "Epoch 2031/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0126 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9845\n",
      "Epoch 2032/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9845\n",
      "Epoch 2033/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0753 - val_accuracy: 0.9814\n",
      "Epoch 2034/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0745 - val_accuracy: 0.9814\n",
      "Epoch 2035/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0736 - val_accuracy: 0.9845\n",
      "Epoch 2036/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0680 - val_accuracy: 0.9876\n",
      "Epoch 2037/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9845\n",
      "Epoch 2038/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9845\n",
      "Epoch 2039/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.0804 - val_accuracy: 0.9752\n",
      "Epoch 2040/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 2041/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0656 - val_accuracy: 0.9876\n",
      "Epoch 2042/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9845\n",
      "Epoch 2043/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0664 - val_accuracy: 0.9876\n",
      "Epoch 2044/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9876\n",
      "Epoch 2045/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9814\n",
      "Epoch 2046/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9814\n",
      "Epoch 2047/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9814\n",
      "Epoch 2048/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9876\n",
      "Epoch 2049/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0704 - val_accuracy: 0.9876\n",
      "Epoch 2050/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0680 - val_accuracy: 0.9876\n",
      "Epoch 2051/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9876\n",
      "Epoch 2052/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
      "Epoch 2053/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0778 - val_accuracy: 0.9814\n",
      "Epoch 2054/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0602 - val_accuracy: 0.9876\n",
      "Epoch 2055/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0175 - accuracy: 0.9923 - val_loss: 0.0642 - val_accuracy: 0.9876\n",
      "Epoch 2056/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0897 - val_accuracy: 0.9752\n",
      "Epoch 2057/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 2058/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 2059/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0722 - val_accuracy: 0.9814\n",
      "Epoch 2060/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.1091 - val_accuracy: 0.9752\n",
      "Epoch 2061/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0291 - accuracy: 0.9862 - val_loss: 0.0645 - val_accuracy: 0.9845\n",
      "Epoch 2062/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0517 - val_accuracy: 0.9783\n",
      "Epoch 2063/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0233 - accuracy: 0.9893 - val_loss: 0.0622 - val_accuracy: 0.9845\n",
      "Epoch 2064/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0898 - val_accuracy: 0.9752\n",
      "Epoch 2065/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0780 - val_accuracy: 0.9814\n",
      "Epoch 2066/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.0650 - val_accuracy: 0.9845\n",
      "Epoch 2067/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0667 - val_accuracy: 0.9845\n",
      "Epoch 2068/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0711 - val_accuracy: 0.9814\n",
      "Epoch 2069/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9814\n",
      "Epoch 2070/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9814\n",
      "Epoch 2071/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0666 - val_accuracy: 0.9876\n",
      "Epoch 2072/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9876\n",
      "Epoch 2073/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
      "Epoch 2074/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0814 - val_accuracy: 0.9783\n",
      "Epoch 2075/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9876\n",
      "Epoch 2076/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 2077/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9845\n",
      "Epoch 2078/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 2079/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9876\n",
      "Epoch 2080/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0719 - val_accuracy: 0.9876\n",
      "Epoch 2081/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9876\n",
      "Epoch 2082/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 2083/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0696 - val_accuracy: 0.9876\n",
      "Epoch 2084/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9783\n",
      "Epoch 2085/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9876\n",
      "Epoch 2086/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0614 - val_accuracy: 0.9876\n",
      "Epoch 2087/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.0722 - val_accuracy: 0.9845\n",
      "Epoch 2088/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9814\n",
      "Epoch 2089/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0127 - accuracy: 0.9985 - val_loss: 0.0797 - val_accuracy: 0.9814\n",
      "Epoch 2090/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9814\n",
      "Epoch 2091/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9876\n",
      "Epoch 2092/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0664 - val_accuracy: 0.9876\n",
      "Epoch 2093/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0671 - val_accuracy: 0.9876\n",
      "Epoch 2094/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9845\n",
      "Epoch 2095/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 2096/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0665 - val_accuracy: 0.9876\n",
      "Epoch 2097/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0618 - val_accuracy: 0.9876\n",
      "Epoch 2098/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0674 - val_accuracy: 0.9876\n",
      "Epoch 2099/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 2100/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0837 - val_accuracy: 0.9814\n",
      "Epoch 2101/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2102/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0674 - val_accuracy: 0.9876\n",
      "Epoch 2103/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9876\n",
      "Epoch 2104/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2105/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9876\n",
      "Epoch 2106/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0647 - val_accuracy: 0.9876\n",
      "Epoch 2107/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0705 - val_accuracy: 0.9876\n",
      "Epoch 2108/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9814\n",
      "Epoch 2109/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9814\n",
      "Epoch 2110/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
      "Epoch 2111/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9876\n",
      "Epoch 2112/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0716 - val_accuracy: 0.9876\n",
      "Epoch 2113/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9814\n",
      "Epoch 2114/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9814\n",
      "Epoch 2115/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9876\n",
      "Epoch 2116/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0652 - val_accuracy: 0.9876\n",
      "Epoch 2117/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2118/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9845\n",
      "Epoch 2119/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9876\n",
      "Epoch 2120/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9845\n",
      "Epoch 2121/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 2122/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.0794 - val_accuracy: 0.9845\n",
      "Epoch 2123/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0719 - val_accuracy: 0.9876\n",
      "Epoch 2124/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9876\n",
      "Epoch 2125/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0731 - val_accuracy: 0.9876\n",
      "Epoch 2126/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.0843 - val_accuracy: 0.9752\n",
      "Epoch 2127/3500\n",
      "653/653 [==============================] - 0s 61us/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0677 - val_accuracy: 0.9876\n",
      "Epoch 2128/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0647 - val_accuracy: 0.9814\n",
      "Epoch 2129/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0739 - val_accuracy: 0.9845\n",
      "Epoch 2130/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0869 - val_accuracy: 0.9814\n",
      "Epoch 2131/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9814\n",
      "Epoch 2132/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 2133/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.0714 - val_accuracy: 0.9814\n",
      "Epoch 2134/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0965 - val_accuracy: 0.9752\n",
      "Epoch 2135/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0830 - val_accuracy: 0.9752\n",
      "Epoch 2136/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0597 - val_accuracy: 0.9876\n",
      "Epoch 2137/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.0610 - val_accuracy: 0.9876\n",
      "Epoch 2138/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0828 - val_accuracy: 0.9752\n",
      "Epoch 2139/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0806 - val_accuracy: 0.9783\n",
      "Epoch 2140/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0671 - val_accuracy: 0.9876\n",
      "Epoch 2141/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0669 - val_accuracy: 0.9876\n",
      "Epoch 2142/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0752 - val_accuracy: 0.9814\n",
      "Epoch 2143/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9814\n",
      "Epoch 2144/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9814\n",
      "Epoch 2145/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2146/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0724 - val_accuracy: 0.9845\n",
      "Epoch 2147/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9876\n",
      "Epoch 2148/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9876\n",
      "Epoch 2149/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0639 - val_accuracy: 0.9876\n",
      "Epoch 2150/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9876\n",
      "Epoch 2151/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 2152/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9783\n",
      "Epoch 2153/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9876\n",
      "Epoch 2154/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2155/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2156/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0778 - val_accuracy: 0.9845\n",
      "Epoch 2157/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9814\n",
      "Epoch 2158/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.0680 - val_accuracy: 0.9876\n",
      "Epoch 2159/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0639 - val_accuracy: 0.9876\n",
      "Epoch 2160/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9814\n",
      "Epoch 2161/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0739 - val_accuracy: 0.9814\n",
      "Epoch 2162/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0124 - accuracy: 0.9985 - val_loss: 0.0644 - val_accuracy: 0.9876\n",
      "Epoch 2163/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9876\n",
      "Epoch 2164/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
      "Epoch 2165/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0806 - val_accuracy: 0.9845\n",
      "Epoch 2166/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9845\n",
      "Epoch 2167/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0633 - val_accuracy: 0.9845\n",
      "Epoch 2168/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0682 - val_accuracy: 0.9876\n",
      "Epoch 2169/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0827 - val_accuracy: 0.9814\n",
      "Epoch 2170/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9814\n",
      "Epoch 2171/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.0629 - val_accuracy: 0.9876\n",
      "Epoch 2172/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.0650 - val_accuracy: 0.9876\n",
      "Epoch 2173/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 2174/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0848 - val_accuracy: 0.9752\n",
      "Epoch 2175/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0658 - val_accuracy: 0.9876\n",
      "Epoch 2176/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0641 - val_accuracy: 0.9876\n",
      "Epoch 2177/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0815 - val_accuracy: 0.9814\n",
      "Epoch 2178/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0854 - val_accuracy: 0.9752\n",
      "Epoch 2179/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0657 - val_accuracy: 0.9876\n",
      "Epoch 2180/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0606 - val_accuracy: 0.9876\n",
      "Epoch 2181/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0692 - val_accuracy: 0.9876\n",
      "Epoch 2182/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0840 - val_accuracy: 0.9752\n",
      "Epoch 2183/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0740 - val_accuracy: 0.9845\n",
      "Epoch 2184/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "Epoch 2185/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0631 - val_accuracy: 0.9876\n",
      "Epoch 2186/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9876\n",
      "Epoch 2187/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0776 - val_accuracy: 0.9845\n",
      "Epoch 2188/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9876\n",
      "Epoch 2189/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0693 - val_accuracy: 0.9876\n",
      "Epoch 2190/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0674 - val_accuracy: 0.9876\n",
      "Epoch 2191/3500\n",
      "653/653 [==============================] - 0s 89us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9876\n",
      "Epoch 2192/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 2193/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9876\n",
      "Epoch 2194/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2195/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0658 - val_accuracy: 0.9876\n",
      "Epoch 2196/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 2197/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9876\n",
      "Epoch 2198/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0777 - val_accuracy: 0.9845\n",
      "Epoch 2199/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 2200/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9876\n",
      "Epoch 2201/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9876\n",
      "Epoch 2202/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0797 - val_accuracy: 0.9814\n",
      "Epoch 2203/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0723 - val_accuracy: 0.9876\n",
      "Epoch 2204/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0635 - val_accuracy: 0.9876\n",
      "Epoch 2205/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0653 - val_accuracy: 0.9876\n",
      "Epoch 2206/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
      "Epoch 2207/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 0.0810 - val_accuracy: 0.9814\n",
      "Epoch 2208/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0745 - val_accuracy: 0.9845\n",
      "Epoch 2209/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2210/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9876\n",
      "Epoch 2211/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0798 - val_accuracy: 0.9814\n",
      "Epoch 2212/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0670 - val_accuracy: 0.9876\n",
      "Epoch 2213/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0628 - val_accuracy: 0.9814\n",
      "Epoch 2214/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0193 - accuracy: 0.9923 - val_loss: 0.0738 - val_accuracy: 0.9876\n",
      "Epoch 2215/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.1025 - val_accuracy: 0.9720\n",
      "Epoch 2216/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.0758 - val_accuracy: 0.9876\n",
      "Epoch 2217/3500\n",
      "653/653 [==============================] - 0s 19us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9876\n",
      "Epoch 2218/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 2219/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9876\n",
      "Epoch 2220/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 2221/3500\n",
      "653/653 [==============================] - 0s 70us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0691 - val_accuracy: 0.9876\n",
      "Epoch 2222/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9876\n",
      "Epoch 2223/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0678 - val_accuracy: 0.9876\n",
      "Epoch 2224/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0777 - val_accuracy: 0.9814\n",
      "Epoch 2225/3500\n",
      "653/653 [==============================] - 0s 56us/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.0743 - val_accuracy: 0.9814\n",
      "Epoch 2226/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0678 - val_accuracy: 0.9845\n",
      "Epoch 2227/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.0728 - val_accuracy: 0.9845\n",
      "Epoch 2228/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0793 - val_accuracy: 0.9845\n",
      "Epoch 2229/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9845\n",
      "Epoch 2230/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9876\n",
      "Epoch 2231/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9876\n",
      "Epoch 2232/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0832 - val_accuracy: 0.9752\n",
      "Epoch 2233/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0706 - val_accuracy: 0.9845\n",
      "Epoch 2234/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0597 - val_accuracy: 0.9876\n",
      "Epoch 2235/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9876\n",
      "Epoch 2236/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9876\n",
      "Epoch 2237/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9814\n",
      "Epoch 2238/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9814\n",
      "Epoch 2239/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9845\n",
      "Epoch 2240/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9876\n",
      "Epoch 2241/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9876\n",
      "Epoch 2242/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0673 - val_accuracy: 0.9876\n",
      "Epoch 2243/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2244/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0742 - val_accuracy: 0.9876\n",
      "Epoch 2245/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9876\n",
      "Epoch 2246/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9814\n",
      "Epoch 2247/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9814\n",
      "Epoch 2248/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2249/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9876\n",
      "Epoch 2250/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "Epoch 2251/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0798 - val_accuracy: 0.9814\n",
      "Epoch 2252/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 2253/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0628 - val_accuracy: 0.9845\n",
      "Epoch 2254/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.0662 - val_accuracy: 0.9876\n",
      "Epoch 2255/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0838 - val_accuracy: 0.9783\n",
      "Epoch 2256/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0815 - val_accuracy: 0.9814\n",
      "Epoch 2257/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0666 - val_accuracy: 0.9876\n",
      "Epoch 2258/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9876\n",
      "Epoch 2259/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 2260/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0684 - val_accuracy: 0.9876\n",
      "Epoch 2261/3500\n",
      "653/653 [==============================] - 0s 64us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0581 - val_accuracy: 0.9876\n",
      "Epoch 2262/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "Epoch 2263/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0838 - val_accuracy: 0.9814\n",
      "Epoch 2264/3500\n",
      "653/653 [==============================] - 0s 67us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "Epoch 2265/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0682 - val_accuracy: 0.9876\n",
      "Epoch 2266/3500\n",
      "653/653 [==============================] - 0s 96us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9845\n",
      "Epoch 2267/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0743 - val_accuracy: 0.9845\n",
      "Epoch 2268/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 2269/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9876\n",
      "Epoch 2270/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9845\n",
      "Epoch 2271/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.0810 - val_accuracy: 0.9814\n",
      "Epoch 2272/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0790 - val_accuracy: 0.9845\n",
      "Epoch 2273/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0724 - val_accuracy: 0.9876\n",
      "Epoch 2274/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0728 - val_accuracy: 0.9876\n",
      "Epoch 2275/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0738 - val_accuracy: 0.9876\n",
      "Epoch 2276/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2277/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2278/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2279/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0730 - val_accuracy: 0.9845\n",
      "Epoch 2280/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
      "Epoch 2281/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9845\n",
      "Epoch 2282/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
      "Epoch 2283/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0721 - val_accuracy: 0.9845\n",
      "Epoch 2284/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0682 - val_accuracy: 0.9876\n",
      "Epoch 2285/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9845\n",
      "Epoch 2286/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0861 - val_accuracy: 0.9752\n",
      "Epoch 2287/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0717 - val_accuracy: 0.9876\n",
      "Epoch 2288/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0604 - val_accuracy: 0.9876\n",
      "Epoch 2289/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0647 - val_accuracy: 0.9876\n",
      "Epoch 2290/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9814\n",
      "Epoch 2291/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9814\n",
      "Epoch 2292/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.0708 - val_accuracy: 0.9845\n",
      "Epoch 2293/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9845\n",
      "Epoch 2294/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9845\n",
      "Epoch 2295/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0710 - val_accuracy: 0.9845\n",
      "Epoch 2296/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 2297/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9845\n",
      "Epoch 2298/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0710 - val_accuracy: 0.9845\n",
      "Epoch 2299/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0724 - val_accuracy: 0.9845\n",
      "Epoch 2300/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9845\n",
      "Epoch 2301/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0723 - val_accuracy: 0.9876\n",
      "Epoch 2302/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0639 - val_accuracy: 0.9876\n",
      "Epoch 2303/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0666 - val_accuracy: 0.9876\n",
      "Epoch 2304/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 2305/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.0756 - val_accuracy: 0.9845\n",
      "Epoch 2306/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9876\n",
      "Epoch 2307/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9876\n",
      "Epoch 2308/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9845\n",
      "Epoch 2309/3500\n",
      "653/653 [==============================] - 0s 69us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9876\n",
      "Epoch 2310/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9876\n",
      "Epoch 2311/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0719 - val_accuracy: 0.9845\n",
      "Epoch 2312/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0912 - val_accuracy: 0.9752\n",
      "Epoch 2313/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 2314/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9876\n",
      "Epoch 2315/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9876\n",
      "Epoch 2316/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9814\n",
      "Epoch 2317/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9845\n",
      "Epoch 2318/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9876\n",
      "Epoch 2319/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0670 - val_accuracy: 0.9876\n",
      "Epoch 2320/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0834 - val_accuracy: 0.9814\n",
      "Epoch 2321/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9845\n",
      "Epoch 2322/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.0675 - val_accuracy: 0.9876\n",
      "Epoch 2323/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0728 - val_accuracy: 0.9845\n",
      "Epoch 2324/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0903 - val_accuracy: 0.9752\n",
      "Epoch 2325/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0686 - val_accuracy: 0.9876\n",
      "Epoch 2326/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0592 - val_accuracy: 0.9876\n",
      "Epoch 2327/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0673 - val_accuracy: 0.9876\n",
      "Epoch 2328/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.0818 - val_accuracy: 0.9783\n",
      "Epoch 2329/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 26us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9845\n",
      "Epoch 2330/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0707 - val_accuracy: 0.9876\n",
      "Epoch 2331/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 2332/3500\n",
      "653/653 [==============================] - 0s 22us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0808 - val_accuracy: 0.9845\n",
      "Epoch 2333/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0753 - val_accuracy: 0.9845\n",
      "Epoch 2334/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
      "Epoch 2335/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9845\n",
      "Epoch 2336/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9845\n",
      "Epoch 2337/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2338/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0683 - val_accuracy: 0.9876\n",
      "Epoch 2339/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9876\n",
      "Epoch 2340/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9876\n",
      "Epoch 2341/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0639 - val_accuracy: 0.9876\n",
      "Epoch 2342/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9876\n",
      "Epoch 2343/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0857 - val_accuracy: 0.9783\n",
      "Epoch 2344/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0737 - val_accuracy: 0.9876\n",
      "Epoch 2345/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0635 - val_accuracy: 0.9876\n",
      "Epoch 2346/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9876\n",
      "Epoch 2347/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9814\n",
      "Epoch 2348/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9814\n",
      "Epoch 2349/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.0702 - val_accuracy: 0.9876\n",
      "Epoch 2350/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9876\n",
      "Epoch 2351/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 2352/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9876\n",
      "Epoch 2353/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0692 - val_accuracy: 0.9876\n",
      "Epoch 2354/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9876\n",
      "Epoch 2355/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9876\n",
      "Epoch 2356/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0684 - val_accuracy: 0.9876\n",
      "Epoch 2357/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9876\n",
      "Epoch 2358/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0727 - val_accuracy: 0.9876\n",
      "Epoch 2359/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
      "Epoch 2360/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0780 - val_accuracy: 0.9845\n",
      "Epoch 2361/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9845\n",
      "Epoch 2362/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0776 - val_accuracy: 0.9845\n",
      "Epoch 2363/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9876\n",
      "Epoch 2364/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2365/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 2366/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9876\n",
      "Epoch 2367/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 0.0738 - val_accuracy: 0.9876\n",
      "Epoch 2368/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2369/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0656 - val_accuracy: 0.9876\n",
      "Epoch 2370/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0689 - val_accuracy: 0.9876\n",
      "Epoch 2371/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0870 - val_accuracy: 0.9752\n",
      "Epoch 2372/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0845 - val_accuracy: 0.9783\n",
      "Epoch 2373/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2374/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0672 - val_accuracy: 0.9876\n",
      "Epoch 2375/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0745 - val_accuracy: 0.9845\n",
      "Epoch 2376/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.0845 - val_accuracy: 0.9752\n",
      "Epoch 2377/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9876\n",
      "Epoch 2378/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0659 - val_accuracy: 0.9814\n",
      "Epoch 2379/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0185 - accuracy: 0.9923 - val_loss: 0.0732 - val_accuracy: 0.9845\n",
      "Epoch 2380/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0850 - val_accuracy: 0.9814\n",
      "Epoch 2381/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9845\n",
      "Epoch 2382/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 0.0668 - val_accuracy: 0.9876\n",
      "Epoch 2383/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9876\n",
      "Epoch 2384/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9876\n",
      "Epoch 2385/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0781 - val_accuracy: 0.9845\n",
      "Epoch 2386/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0788 - val_accuracy: 0.9845\n",
      "Epoch 2387/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9845\n",
      "Epoch 2388/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0744 - val_accuracy: 0.9845\n",
      "Epoch 2389/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9876\n",
      "Epoch 2390/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0745 - val_accuracy: 0.9845\n",
      "Epoch 2391/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0850 - val_accuracy: 0.9814\n",
      "Epoch 2392/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9845\n",
      "Epoch 2393/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0677 - val_accuracy: 0.9845\n",
      "Epoch 2394/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0157 - accuracy: 0.9923 - val_loss: 0.0702 - val_accuracy: 0.9876\n",
      "Epoch 2395/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0840 - val_accuracy: 0.9814\n",
      "Epoch 2396/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
      "Epoch 2397/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0691 - val_accuracy: 0.9876\n",
      "Epoch 2398/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0657 - val_accuracy: 0.9814\n",
      "Epoch 2399/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0194 - accuracy: 0.9923 - val_loss: 0.0714 - val_accuracy: 0.9876\n",
      "Epoch 2400/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0846 - val_accuracy: 0.9814\n",
      "Epoch 2401/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9845\n",
      "Epoch 2402/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0663 - val_accuracy: 0.9876\n",
      "Epoch 2403/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
      "Epoch 2404/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9876\n",
      "Epoch 2405/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
      "Epoch 2406/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0663 - val_accuracy: 0.9876\n",
      "Epoch 2407/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9876\n",
      "Epoch 2408/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
      "Epoch 2409/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9814\n",
      "Epoch 2410/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.0702 - val_accuracy: 0.9876\n",
      "Epoch 2411/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9814\n",
      "Epoch 2412/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0693 - val_accuracy: 0.9845\n",
      "Epoch 2413/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0862 - val_accuracy: 0.9814\n",
      "Epoch 2414/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0130 - accuracy: 0.9985 - val_loss: 0.0852 - val_accuracy: 0.9814\n",
      "Epoch 2415/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0725 - val_accuracy: 0.9876\n",
      "Epoch 2416/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9876\n",
      "Epoch 2417/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9876\n",
      "Epoch 2418/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0825 - val_accuracy: 0.9783\n",
      "Epoch 2419/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9876\n",
      "Epoch 2420/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9876\n",
      "Epoch 2421/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9876\n",
      "Epoch 2422/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9814\n",
      "Epoch 2423/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9845\n",
      "Epoch 2424/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
      "Epoch 2425/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9845\n",
      "Epoch 2426/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0793 - val_accuracy: 0.9845\n",
      "Epoch 2427/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9845\n",
      "Epoch 2428/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9876\n",
      "Epoch 2429/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0710 - val_accuracy: 0.9876\n",
      "Epoch 2430/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0834 - val_accuracy: 0.9783\n",
      "Epoch 2431/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9876\n",
      "Epoch 2432/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0657 - val_accuracy: 0.9845\n",
      "Epoch 2433/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0156 - accuracy: 0.9923 - val_loss: 0.0680 - val_accuracy: 0.9876\n",
      "Epoch 2434/3500\n",
      "653/653 [==============================] - 0s 56us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0793 - val_accuracy: 0.9814\n",
      "Epoch 2435/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0835 - val_accuracy: 0.9814\n",
      "Epoch 2436/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9814\n",
      "Epoch 2437/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 0.0749 - val_accuracy: 0.9845\n",
      "Epoch 2438/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9876\n",
      "Epoch 2439/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 15us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9845\n",
      "Epoch 2440/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9845\n",
      "Epoch 2441/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0717 - val_accuracy: 0.9876\n",
      "Epoch 2442/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0683 - val_accuracy: 0.9876\n",
      "Epoch 2443/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 2444/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9814\n",
      "Epoch 2445/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9845\n",
      "Epoch 2446/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9845\n",
      "Epoch 2447/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0832 - val_accuracy: 0.9814\n",
      "Epoch 2448/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 2449/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9876\n",
      "Epoch 2450/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0655 - val_accuracy: 0.9876\n",
      "Epoch 2451/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9845\n",
      "Epoch 2452/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9876\n",
      "Epoch 2453/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9876\n",
      "Epoch 2454/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 2455/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9845\n",
      "Epoch 2456/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0842 - val_accuracy: 0.9783\n",
      "Epoch 2457/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9876\n",
      "Epoch 2458/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9845\n",
      "Epoch 2459/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0146 - accuracy: 0.9923 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 2460/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0859 - val_accuracy: 0.9783\n",
      "Epoch 2461/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9985 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2462/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0141 - accuracy: 0.9939 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2463/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0860 - val_accuracy: 0.9783\n",
      "Epoch 2464/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9876\n",
      "Epoch 2465/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0666 - val_accuracy: 0.9876\n",
      "Epoch 2466/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9876\n",
      "Epoch 2467/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 2468/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0824 - val_accuracy: 0.9845\n",
      "Epoch 2469/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0777 - val_accuracy: 0.9845\n",
      "Epoch 2470/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9845\n",
      "Epoch 2471/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2472/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9845\n",
      "Epoch 2473/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9876\n",
      "Epoch 2474/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9876\n",
      "Epoch 2475/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9845\n",
      "Epoch 2476/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 0.0788 - val_accuracy: 0.9845\n",
      "Epoch 2477/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0737 - val_accuracy: 0.9876\n",
      "Epoch 2478/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9845\n",
      "Epoch 2479/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0846 - val_accuracy: 0.9814\n",
      "Epoch 2480/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9845\n",
      "Epoch 2481/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0657 - val_accuracy: 0.9845\n",
      "Epoch 2482/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0663 - val_accuracy: 0.9845\n",
      "Epoch 2483/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9845\n",
      "Epoch 2484/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0879 - val_accuracy: 0.9814\n",
      "Epoch 2485/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 2486/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9845\n",
      "Epoch 2487/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 2488/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 2489/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0824 - val_accuracy: 0.9845\n",
      "Epoch 2490/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9845\n",
      "Epoch 2491/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 2492/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0141 - accuracy: 0.9939 - val_loss: 0.0820 - val_accuracy: 0.9845\n",
      "Epoch 2493/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0943 - val_accuracy: 0.9752\n",
      "Epoch 2494/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 2495/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9814\n",
      "Epoch 2496/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0153 - accuracy: 0.9923 - val_loss: 0.0683 - val_accuracy: 0.9845\n",
      "Epoch 2497/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0781 - val_accuracy: 0.9845\n",
      "Epoch 2498/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.0805 - val_accuracy: 0.9845\n",
      "Epoch 2499/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2500/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9876\n",
      "Epoch 2501/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0739 - val_accuracy: 0.9876\n",
      "Epoch 2502/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9845\n",
      "Epoch 2503/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "Epoch 2504/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9845\n",
      "Epoch 2505/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9845\n",
      "Epoch 2506/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 2507/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2508/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0742 - val_accuracy: 0.9876\n",
      "Epoch 2509/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9876\n",
      "Epoch 2510/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9876\n",
      "Epoch 2511/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9876\n",
      "Epoch 2512/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2513/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9876\n",
      "Epoch 2514/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
      "Epoch 2515/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0727 - val_accuracy: 0.9876\n",
      "Epoch 2516/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 2517/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9876\n",
      "Epoch 2518/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0767 - val_accuracy: 0.9845\n",
      "Epoch 2519/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0749 - val_accuracy: 0.9845\n",
      "Epoch 2520/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.0688 - val_accuracy: 0.9876\n",
      "Epoch 2521/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9876\n",
      "Epoch 2522/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 2523/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9876\n",
      "Epoch 2524/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 2525/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9845\n",
      "Epoch 2526/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9876\n",
      "Epoch 2527/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "Epoch 2528/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0732 - val_accuracy: 0.9876\n",
      "Epoch 2529/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0702 - val_accuracy: 0.9876\n",
      "Epoch 2530/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9845\n",
      "Epoch 2531/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0835 - val_accuracy: 0.9814\n",
      "Epoch 2532/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9845\n",
      "Epoch 2533/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 2534/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9845\n",
      "Epoch 2535/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9845\n",
      "Epoch 2536/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9845\n",
      "Epoch 2537/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9876\n",
      "Epoch 2538/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9876\n",
      "Epoch 2539/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0838 - val_accuracy: 0.9814\n",
      "Epoch 2540/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9845\n",
      "Epoch 2541/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0710 - val_accuracy: 0.9876\n",
      "Epoch 2542/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9876\n",
      "Epoch 2543/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9876\n",
      "Epoch 2544/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9845\n",
      "Epoch 2545/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9845\n",
      "Epoch 2546/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9876\n",
      "Epoch 2547/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9845\n",
      "Epoch 2548/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9845\n",
      "Epoch 2549/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 41us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0869 - val_accuracy: 0.9783\n",
      "Epoch 2550/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 2551/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 2552/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0728 - val_accuracy: 0.9876\n",
      "Epoch 2553/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0779 - val_accuracy: 0.9845\n",
      "Epoch 2554/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9876\n",
      "Epoch 2555/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0727 - val_accuracy: 0.9876\n",
      "Epoch 2556/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9845\n",
      "Epoch 2557/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0859 - val_accuracy: 0.9814\n",
      "Epoch 2558/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0781 - val_accuracy: 0.9845\n",
      "Epoch 2559/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0730 - val_accuracy: 0.9876\n",
      "Epoch 2560/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9876\n",
      "Epoch 2561/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9845\n",
      "Epoch 2562/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9876\n",
      "Epoch 2563/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2564/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0727 - val_accuracy: 0.9876\n",
      "Epoch 2565/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9876\n",
      "Epoch 2566/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9954 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 2567/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0778 - val_accuracy: 0.9845\n",
      "Epoch 2568/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9845\n",
      "Epoch 2569/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 2570/3500\n",
      "653/653 [==============================] - 0s 22us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0727 - val_accuracy: 0.9876\n",
      "Epoch 2571/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2572/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "Epoch 2573/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 2574/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2575/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0742 - val_accuracy: 0.9876\n",
      "Epoch 2576/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.0908 - val_accuracy: 0.9783\n",
      "Epoch 2577/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0784 - val_accuracy: 0.9845\n",
      "Epoch 2578/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0686 - val_accuracy: 0.9845\n",
      "Epoch 2579/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0692 - val_accuracy: 0.9876\n",
      "Epoch 2580/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "Epoch 2581/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
      "Epoch 2582/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0832 - val_accuracy: 0.9845\n",
      "Epoch 2583/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2584/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9814\n",
      "Epoch 2585/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0170 - accuracy: 0.9923 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 2586/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1012 - val_accuracy: 0.9752\n",
      "Epoch 2587/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0192 - accuracy: 0.9954 - val_loss: 0.0749 - val_accuracy: 0.9845\n",
      "Epoch 2588/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0664 - val_accuracy: 0.9845\n",
      "Epoch 2589/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0696 - val_accuracy: 0.9876\n",
      "Epoch 2590/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9814\n",
      "Epoch 2591/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2592/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0677 - val_accuracy: 0.9814\n",
      "Epoch 2593/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0164 - accuracy: 0.9923 - val_loss: 0.0771 - val_accuracy: 0.9845\n",
      "Epoch 2594/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.1192 - val_accuracy: 0.9720\n",
      "Epoch 2595/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0320 - accuracy: 0.9832 - val_loss: 0.0644 - val_accuracy: 0.9876\n",
      "Epoch 2596/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.1092 - val_accuracy: 0.9658\n",
      "Epoch 2597/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0771 - accuracy: 0.9724 - val_loss: 0.1104 - val_accuracy: 0.9752\n",
      "Epoch 2598/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0453 - accuracy: 0.9832 - val_loss: 0.0892 - val_accuracy: 0.9752\n",
      "Epoch 2599/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
      "Epoch 2600/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0594 - val_accuracy: 0.9814\n",
      "Epoch 2601/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.0866 - val_accuracy: 0.9814\n",
      "Epoch 2602/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0136 - accuracy: 0.9939 - val_loss: 0.0915 - val_accuracy: 0.9814\n",
      "Epoch 2603/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
      "Epoch 2604/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0850 - val_accuracy: 0.9783\n",
      "Epoch 2605/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0862 - val_accuracy: 0.9814\n",
      "Epoch 2606/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0800 - val_accuracy: 0.9845\n",
      "Epoch 2607/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9876\n",
      "Epoch 2608/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2609/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9876\n",
      "Epoch 2610/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0624 - val_accuracy: 0.9845\n",
      "Epoch 2611/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2612/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0887 - val_accuracy: 0.9752\n",
      "Epoch 2613/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
      "Epoch 2614/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9814\n",
      "Epoch 2615/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.0715 - val_accuracy: 0.9845\n",
      "Epoch 2616/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0823 - val_accuracy: 0.9814\n",
      "Epoch 2617/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
      "Epoch 2618/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0702 - val_accuracy: 0.9876\n",
      "Epoch 2619/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9845\n",
      "Epoch 2620/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9876\n",
      "Epoch 2621/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0854 - val_accuracy: 0.9752\n",
      "Epoch 2622/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0831 - val_accuracy: 0.9814\n",
      "Epoch 2623/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9876\n",
      "Epoch 2624/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.0677 - val_accuracy: 0.9814\n",
      "Epoch 2625/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.0777 - val_accuracy: 0.9845\n",
      "Epoch 2626/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0959 - val_accuracy: 0.9752\n",
      "Epoch 2627/3500\n",
      "653/653 [==============================] - 0s 33us/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2628/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9814\n",
      "Epoch 2629/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.0686 - val_accuracy: 0.9845\n",
      "Epoch 2630/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0844 - val_accuracy: 0.9814\n",
      "Epoch 2631/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0822 - val_accuracy: 0.9814\n",
      "Epoch 2632/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 2633/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0652 - val_accuracy: 0.9845\n",
      "Epoch 2634/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0741 - val_accuracy: 0.9876\n",
      "Epoch 2635/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0824 - val_accuracy: 0.9845\n",
      "Epoch 2636/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0705 - val_accuracy: 0.9876\n",
      "Epoch 2637/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 2638/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.0700 - val_accuracy: 0.9845\n",
      "Epoch 2639/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0783 - val_accuracy: 0.9845\n",
      "Epoch 2640/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0135 - accuracy: 0.9939 - val_loss: 0.0831 - val_accuracy: 0.9814\n",
      "Epoch 2641/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9845\n",
      "Epoch 2642/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0778 - val_accuracy: 0.9845\n",
      "Epoch 2643/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0806 - val_accuracy: 0.9845\n",
      "Epoch 2644/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 2645/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0762 - val_accuracy: 0.9876\n",
      "Epoch 2646/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2647/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9876\n",
      "Epoch 2648/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9876\n",
      "Epoch 2649/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9876\n",
      "Epoch 2650/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9876\n",
      "Epoch 2651/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9876\n",
      "Epoch 2652/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9876\n",
      "Epoch 2653/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9876\n",
      "Epoch 2654/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 2655/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9845\n",
      "Epoch 2656/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0799 - val_accuracy: 0.9845\n",
      "Epoch 2657/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0775 - val_accuracy: 0.9845\n",
      "Epoch 2658/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9876\n",
      "Epoch 2659/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0719 - val_accuracy: 0.9876\n",
      "Epoch 2660/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9876\n",
      "Epoch 2661/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0827 - val_accuracy: 0.9814\n",
      "Epoch 2662/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0829 - val_accuracy: 0.9814\n",
      "Epoch 2663/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9876\n",
      "Epoch 2664/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 2665/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9845\n",
      "Epoch 2666/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0817 - val_accuracy: 0.9845\n",
      "Epoch 2667/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 2668/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0658 - val_accuracy: 0.9814\n",
      "Epoch 2669/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0738 - val_accuracy: 0.9876\n",
      "Epoch 2670/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0846 - val_accuracy: 0.9814\n",
      "Epoch 2671/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0673 - val_accuracy: 0.9876\n",
      "Epoch 2672/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0674 - val_accuracy: 0.9876\n",
      "Epoch 2673/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0796 - val_accuracy: 0.9876\n",
      "Epoch 2674/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0725 - val_accuracy: 0.9876\n",
      "Epoch 2675/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0655 - val_accuracy: 0.9876\n",
      "Epoch 2676/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 2677/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0788 - val_accuracy: 0.9876\n",
      "Epoch 2678/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 2679/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0723 - val_accuracy: 0.9876\n",
      "Epoch 2680/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2681/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9876\n",
      "Epoch 2682/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "Epoch 2683/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
      "Epoch 2684/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 2685/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9876\n",
      "Epoch 2686/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2687/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0753 - val_accuracy: 0.9876\n",
      "Epoch 2688/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9876\n",
      "Epoch 2689/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0692 - val_accuracy: 0.9876\n",
      "Epoch 2690/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2691/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2692/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9876\n",
      "Epoch 2693/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0795 - val_accuracy: 0.9845\n",
      "Epoch 2694/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2695/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9845\n",
      "Epoch 2696/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2697/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0768 - val_accuracy: 0.9876\n",
      "Epoch 2698/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0702 - val_accuracy: 0.9814\n",
      "Epoch 2699/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0166 - accuracy: 0.9923 - val_loss: 0.0719 - val_accuracy: 0.9845\n",
      "Epoch 2700/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0892 - val_accuracy: 0.9814\n",
      "Epoch 2701/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0825 - val_accuracy: 0.9814\n",
      "Epoch 2702/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
      "Epoch 2703/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0699 - val_accuracy: 0.9876\n",
      "Epoch 2704/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0815 - val_accuracy: 0.9845\n",
      "Epoch 2705/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9876\n",
      "Epoch 2706/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0659 - val_accuracy: 0.9845\n",
      "Epoch 2707/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9876\n",
      "Epoch 2708/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9876\n",
      "Epoch 2709/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 2710/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9876\n",
      "Epoch 2711/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9876\n",
      "Epoch 2712/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 2713/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9876\n",
      "Epoch 2714/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0686 - val_accuracy: 0.9876\n",
      "Epoch 2715/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9876\n",
      "Epoch 2716/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9876\n",
      "Epoch 2717/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9876\n",
      "Epoch 2718/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9876\n",
      "Epoch 2719/3500\n",
      "653/653 [==============================] - 0s 105us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0684 - val_accuracy: 0.9845\n",
      "Epoch 2720/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9876\n",
      "Epoch 2721/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0800 - val_accuracy: 0.9845\n",
      "Epoch 2722/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 2723/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0746 - val_accuracy: 0.9876\n",
      "Epoch 2724/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 2725/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0809 - val_accuracy: 0.9845\n",
      "Epoch 2726/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0723 - val_accuracy: 0.9876\n",
      "Epoch 2727/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 2728/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9876\n",
      "Epoch 2729/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0821 - val_accuracy: 0.9845\n",
      "Epoch 2730/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2731/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0705 - val_accuracy: 0.9845\n",
      "Epoch 2732/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0723 - val_accuracy: 0.9845\n",
      "Epoch 2733/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
      "Epoch 2734/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0849 - val_accuracy: 0.9814\n",
      "Epoch 2735/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 2736/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9876\n",
      "Epoch 2737/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9876\n",
      "Epoch 2738/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0784 - val_accuracy: 0.9876\n",
      "Epoch 2739/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2740/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0707 - val_accuracy: 0.9876\n",
      "Epoch 2741/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0686 - val_accuracy: 0.9876\n",
      "Epoch 2742/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9876\n",
      "Epoch 2743/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 2744/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0716 - val_accuracy: 0.9876\n",
      "Epoch 2745/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0705 - val_accuracy: 0.9876\n",
      "Epoch 2746/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0834 - val_accuracy: 0.9814\n",
      "Epoch 2747/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9845\n",
      "Epoch 2748/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9814\n",
      "Epoch 2749/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0138 - accuracy: 0.9923 - val_loss: 0.0734 - val_accuracy: 0.9845\n",
      "Epoch 2750/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9814\n",
      "Epoch 2751/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0810 - val_accuracy: 0.9845\n",
      "Epoch 2752/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9876\n",
      "Epoch 2753/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9814\n",
      "Epoch 2754/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0153 - accuracy: 0.9923 - val_loss: 0.0685 - val_accuracy: 0.9876\n",
      "Epoch 2755/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0962 - val_accuracy: 0.9752\n",
      "Epoch 2756/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 2757/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0755 - val_accuracy: 0.9814\n",
      "Epoch 2758/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0200 - accuracy: 0.9923 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 2759/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0143 - accuracy: 0.9923 - val_loss: 0.0853 - val_accuracy: 0.9814\n",
      "Epoch 2760/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0937 - val_accuracy: 0.9783\n",
      "Epoch 2761/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
      "Epoch 2762/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9845\n",
      "Epoch 2763/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0747 - val_accuracy: 0.9876\n",
      "Epoch 2764/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 2765/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0768 - val_accuracy: 0.9876\n",
      "Epoch 2766/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0746 - val_accuracy: 0.9876\n",
      "Epoch 2767/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9876\n",
      "Epoch 2768/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2769/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 26us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9876\n",
      "Epoch 2770/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0745 - val_accuracy: 0.9876\n",
      "Epoch 2771/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9876\n",
      "Epoch 2772/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0782 - val_accuracy: 0.9876\n",
      "Epoch 2773/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9876\n",
      "Epoch 2774/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9876\n",
      "Epoch 2775/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 2776/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
      "Epoch 2777/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0710 - val_accuracy: 0.9814\n",
      "Epoch 2778/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0145 - accuracy: 0.9923 - val_loss: 0.0745 - val_accuracy: 0.9876\n",
      "Epoch 2779/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0917 - val_accuracy: 0.9752\n",
      "Epoch 2780/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0799 - val_accuracy: 0.9845\n",
      "Epoch 2781/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0683 - val_accuracy: 0.9845\n",
      "Epoch 2782/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0669 - val_accuracy: 0.9845\n",
      "Epoch 2783/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0702 - val_accuracy: 0.9876\n",
      "Epoch 2784/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0710 - val_accuracy: 0.9876\n",
      "Epoch 2785/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2786/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9876\n",
      "Epoch 2787/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9876\n",
      "Epoch 2788/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 2789/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9876\n",
      "Epoch 2790/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
      "Epoch 2791/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0765 - val_accuracy: 0.9876\n",
      "Epoch 2792/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9876\n",
      "Epoch 2793/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0740 - val_accuracy: 0.9876\n",
      "Epoch 2794/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0728 - val_accuracy: 0.9876\n",
      "Epoch 2795/3500\n",
      "653/653 [==============================] - 0s 63us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9876\n",
      "Epoch 2796/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "Epoch 2797/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9876\n",
      "Epoch 2798/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9876\n",
      "Epoch 2799/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0825 - val_accuracy: 0.9845\n",
      "Epoch 2800/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2801/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0714 - val_accuracy: 0.9845\n",
      "Epoch 2802/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2803/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
      "Epoch 2804/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0731 - val_accuracy: 0.9876\n",
      "Epoch 2805/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9845\n",
      "Epoch 2806/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0128 - accuracy: 0.9923 - val_loss: 0.0675 - val_accuracy: 0.9845\n",
      "Epoch 2807/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0751 - val_accuracy: 0.9876\n",
      "Epoch 2808/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9876\n",
      "Epoch 2809/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0687 - val_accuracy: 0.9845\n",
      "Epoch 2810/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9845\n",
      "Epoch 2811/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
      "Epoch 2812/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0813 - val_accuracy: 0.9814\n",
      "Epoch 2813/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9876\n",
      "Epoch 2814/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0700 - val_accuracy: 0.9876\n",
      "Epoch 2815/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9845\n",
      "Epoch 2816/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9845\n",
      "Epoch 2817/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0691 - val_accuracy: 0.9876\n",
      "Epoch 2818/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9845\n",
      "Epoch 2819/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9845\n",
      "Epoch 2820/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9876\n",
      "Epoch 2821/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0790 - val_accuracy: 0.9845\n",
      "Epoch 2822/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9876\n",
      "Epoch 2823/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0695 - val_accuracy: 0.9876\n",
      "Epoch 2824/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0688 - val_accuracy: 0.9876\n",
      "Epoch 2825/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2826/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0796 - val_accuracy: 0.9876\n",
      "Epoch 2827/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9876\n",
      "Epoch 2828/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0674 - val_accuracy: 0.9845\n",
      "Epoch 2829/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9876\n",
      "Epoch 2830/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0836 - val_accuracy: 0.9814\n",
      "Epoch 2831/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0757 - val_accuracy: 0.9876\n",
      "Epoch 2832/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0730 - val_accuracy: 0.9814\n",
      "Epoch 2833/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0181 - accuracy: 0.9923 - val_loss: 0.0778 - val_accuracy: 0.9845\n",
      "Epoch 2834/3500\n",
      "653/653 [==============================] - 0s 33us/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.1061 - val_accuracy: 0.9752\n",
      "Epoch 2835/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0222 - accuracy: 0.9908 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 2836/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0654 - val_accuracy: 0.9814\n",
      "Epoch 2837/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0202 - accuracy: 0.9923 - val_loss: 0.0633 - val_accuracy: 0.9814\n",
      "Epoch 2838/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0854 - val_accuracy: 0.9814\n",
      "Epoch 2839/3500\n",
      "653/653 [==============================] - 0s 53us/step - loss: 0.0138 - accuracy: 0.9939 - val_loss: 0.0899 - val_accuracy: 0.9814\n",
      "Epoch 2840/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9845\n",
      "Epoch 2841/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9845\n",
      "Epoch 2842/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0857 - val_accuracy: 0.9845\n",
      "Epoch 2843/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.0898 - val_accuracy: 0.9783\n",
      "Epoch 2844/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0683 - val_accuracy: 0.9845\n",
      "Epoch 2845/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9814\n",
      "Epoch 2846/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0168 - accuracy: 0.9923 - val_loss: 0.0722 - val_accuracy: 0.9876\n",
      "Epoch 2847/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0909 - val_accuracy: 0.9814\n",
      "Epoch 2848/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0813 - val_accuracy: 0.9845\n",
      "Epoch 2849/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9814\n",
      "Epoch 2850/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0754 - val_accuracy: 0.9876\n",
      "Epoch 2851/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0883 - val_accuracy: 0.9814\n",
      "Epoch 2852/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0731 - val_accuracy: 0.9876\n",
      "Epoch 2853/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 2854/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
      "Epoch 2855/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0849 - val_accuracy: 0.9814\n",
      "Epoch 2856/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9845\n",
      "Epoch 2857/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0729 - val_accuracy: 0.9814\n",
      "Epoch 2858/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0134 - accuracy: 0.9939 - val_loss: 0.0727 - val_accuracy: 0.9814\n",
      "Epoch 2859/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 2860/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0834 - val_accuracy: 0.9814\n",
      "Epoch 2861/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.0769 - val_accuracy: 0.9876\n",
      "Epoch 2862/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9876\n",
      "Epoch 2863/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0790 - val_accuracy: 0.9876\n",
      "Epoch 2864/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0839 - val_accuracy: 0.9845\n",
      "Epoch 2865/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9876\n",
      "Epoch 2866/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2867/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9876\n",
      "Epoch 2868/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9876\n",
      "Epoch 2869/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9845\n",
      "Epoch 2870/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2871/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9845\n",
      "Epoch 2872/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9876\n",
      "Epoch 2873/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0781 - val_accuracy: 0.9876\n",
      "Epoch 2874/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9876\n",
      "Epoch 2875/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9814\n",
      "Epoch 2876/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0144 - accuracy: 0.9939 - val_loss: 0.0730 - val_accuracy: 0.9814\n",
      "Epoch 2877/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0870 - val_accuracy: 0.9814\n",
      "Epoch 2878/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0841 - val_accuracy: 0.9814\n",
      "Epoch 2879/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 59us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0634 - val_accuracy: 0.9845\n",
      "Epoch 2880/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9845\n",
      "Epoch 2881/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9876\n",
      "Epoch 2882/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0873 - val_accuracy: 0.9783\n",
      "Epoch 2883/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9876\n",
      "Epoch 2884/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9814\n",
      "Epoch 2885/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0154 - accuracy: 0.9923 - val_loss: 0.0849 - val_accuracy: 0.9845\n",
      "Epoch 2886/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.1030 - val_accuracy: 0.9752\n",
      "Epoch 2887/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0780 - val_accuracy: 0.9876\n",
      "Epoch 2888/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0723 - val_accuracy: 0.9845\n",
      "Epoch 2889/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9876\n",
      "Epoch 2890/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0894 - val_accuracy: 0.9783\n",
      "Epoch 2891/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9876\n",
      "Epoch 2892/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0722 - val_accuracy: 0.9845\n",
      "Epoch 2893/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9876\n",
      "Epoch 2894/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0866 - val_accuracy: 0.9814\n",
      "Epoch 2895/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0870 - val_accuracy: 0.9814\n",
      "Epoch 2896/3500\n",
      "653/653 [==============================] - 0s 31us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0834 - val_accuracy: 0.9845\n",
      "Epoch 2897/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0829 - val_accuracy: 0.9814\n",
      "Epoch 2898/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0857 - val_accuracy: 0.9814\n",
      "Epoch 2899/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0826 - val_accuracy: 0.9814\n",
      "Epoch 2900/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
      "Epoch 2901/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9845\n",
      "Epoch 2902/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0777 - val_accuracy: 0.9876\n",
      "Epoch 2903/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0813 - val_accuracy: 0.9876\n",
      "Epoch 2904/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0742 - val_accuracy: 0.9876\n",
      "Epoch 2905/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0730 - val_accuracy: 0.9876\n",
      "Epoch 2906/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2907/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0775 - val_accuracy: 0.9876\n",
      "Epoch 2908/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9876\n",
      "Epoch 2909/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9876\n",
      "Epoch 2910/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 2911/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9876\n",
      "Epoch 2912/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9876\n",
      "Epoch 2913/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9876\n",
      "Epoch 2914/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9876\n",
      "Epoch 2915/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9876\n",
      "Epoch 2916/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0780 - val_accuracy: 0.9876\n",
      "Epoch 2917/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 2918/3500\n",
      "653/653 [==============================] - 0s 48us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9876\n",
      "Epoch 2919/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0792 - val_accuracy: 0.9876\n",
      "Epoch 2920/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0811 - val_accuracy: 0.9876\n",
      "Epoch 2921/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
      "Epoch 2922/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9876\n",
      "Epoch 2923/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0858 - val_accuracy: 0.9814\n",
      "Epoch 2924/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9876\n",
      "Epoch 2925/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 2926/3500\n",
      "653/653 [==============================] - 0s 63us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0680 - val_accuracy: 0.9845\n",
      "Epoch 2927/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0693 - val_accuracy: 0.9876\n",
      "Epoch 2928/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9876\n",
      "Epoch 2929/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2930/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9876\n",
      "Epoch 2931/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9876\n",
      "Epoch 2932/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0778 - val_accuracy: 0.9876\n",
      "Epoch 2933/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0733 - val_accuracy: 0.9845\n",
      "Epoch 2934/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9845\n",
      "Epoch 2935/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9876\n",
      "Epoch 2936/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0836 - val_accuracy: 0.9814\n",
      "Epoch 2937/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 2938/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
      "Epoch 2939/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9876\n",
      "Epoch 2940/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0851 - val_accuracy: 0.9845\n",
      "Epoch 2941/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
      "Epoch 2942/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 2943/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9845\n",
      "Epoch 2944/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0126 - accuracy: 0.9939 - val_loss: 0.0744 - val_accuracy: 0.9876\n",
      "Epoch 2945/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 2946/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0737 - val_accuracy: 0.9876\n",
      "Epoch 2947/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9845\n",
      "Epoch 2948/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9876\n",
      "Epoch 2949/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9954 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 2950/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9876\n",
      "Epoch 2951/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9876\n",
      "Epoch 2952/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0731 - val_accuracy: 0.9876\n",
      "Epoch 2953/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0730 - val_accuracy: 0.9876\n",
      "Epoch 2954/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 2955/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9845\n",
      "Epoch 2956/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9876\n",
      "Epoch 2957/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9876\n",
      "Epoch 2958/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9876\n",
      "Epoch 2959/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9876\n",
      "Epoch 2960/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0740 - val_accuracy: 0.9876\n",
      "Epoch 2961/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9845\n",
      "Epoch 2962/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9876\n",
      "Epoch 2963/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0717 - val_accuracy: 0.9845\n",
      "Epoch 2964/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0136 - accuracy: 0.9923 - val_loss: 0.0729 - val_accuracy: 0.9876\n",
      "Epoch 2965/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0834 - val_accuracy: 0.9845\n",
      "Epoch 2966/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0817 - val_accuracy: 0.9845\n",
      "Epoch 2967/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9845\n",
      "Epoch 2968/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0722 - val_accuracy: 0.9845\n",
      "Epoch 2969/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0818 - val_accuracy: 0.9814\n",
      "Epoch 2970/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0861 - val_accuracy: 0.9814\n",
      "Epoch 2971/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0767 - val_accuracy: 0.9876\n",
      "Epoch 2972/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9876\n",
      "Epoch 2973/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0747 - val_accuracy: 0.9876\n",
      "Epoch 2974/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0724 - val_accuracy: 0.9876\n",
      "Epoch 2975/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9876\n",
      "Epoch 2976/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9876\n",
      "Epoch 2977/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0774 - val_accuracy: 0.9876\n",
      "Epoch 2978/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0725 - val_accuracy: 0.9845\n",
      "Epoch 2979/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9845\n",
      "Epoch 2980/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "Epoch 2981/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0856 - val_accuracy: 0.9814\n",
      "Epoch 2982/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9876\n",
      "Epoch 2983/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0706 - val_accuracy: 0.9876\n",
      "Epoch 2984/3500\n",
      "653/653 [==============================] - 0s 72us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9876\n",
      "Epoch 2985/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0710 - val_accuracy: 0.9876\n",
      "Epoch 2986/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9876\n",
      "Epoch 2987/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0772 - val_accuracy: 0.9845\n",
      "Epoch 2988/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "Epoch 2989/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0692 - val_accuracy: 0.9845\n",
      "Epoch 2990/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9876\n",
      "Epoch 2991/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9845\n",
      "Epoch 2992/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9876\n",
      "Epoch 2993/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9814\n",
      "Epoch 2994/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9923 - val_loss: 0.0812 - val_accuracy: 0.9814\n",
      "Epoch 2995/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.1077 - val_accuracy: 0.9752\n",
      "Epoch 2996/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0207 - accuracy: 0.9954 - val_loss: 0.0698 - val_accuracy: 0.9876\n",
      "Epoch 2997/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9814\n",
      "Epoch 2998/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0695 - val_accuracy: 0.9876\n",
      "Epoch 2999/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9845\n",
      "Epoch 3000/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9845\n",
      "Epoch 3001/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9814\n",
      "Epoch 3002/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0814 - val_accuracy: 0.9845\n",
      "Epoch 3003/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9845\n",
      "Epoch 3004/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9876\n",
      "Epoch 3005/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0819 - val_accuracy: 0.9814\n",
      "Epoch 3006/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0854 - val_accuracy: 0.9814\n",
      "Epoch 3007/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0747 - val_accuracy: 0.9876\n",
      "Epoch 3008/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0106 - accuracy: 0.9939 - val_loss: 0.0722 - val_accuracy: 0.9845\n",
      "Epoch 3009/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0810 - val_accuracy: 0.9876\n",
      "Epoch 3010/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0811 - val_accuracy: 0.9845\n",
      "Epoch 3011/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9876\n",
      "Epoch 3012/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 3013/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0724 - val_accuracy: 0.9876\n",
      "Epoch 3014/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9876\n",
      "Epoch 3015/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0830 - val_accuracy: 0.9814\n",
      "Epoch 3016/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0807 - val_accuracy: 0.9845\n",
      "Epoch 3017/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
      "Epoch 3018/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 3019/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0890 - val_accuracy: 0.9814\n",
      "Epoch 3020/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0994 - val_accuracy: 0.9752\n",
      "Epoch 3021/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0713 - val_accuracy: 0.9876\n",
      "Epoch 3022/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0673 - val_accuracy: 0.9814\n",
      "Epoch 3023/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0709 - val_accuracy: 0.9876\n",
      "Epoch 3024/3500\n",
      "653/653 [==============================] - 0s 69us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0839 - val_accuracy: 0.9845\n",
      "Epoch 3025/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9876\n",
      "Epoch 3026/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0751 - val_accuracy: 0.9845\n",
      "Epoch 3027/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0771 - val_accuracy: 0.9845\n",
      "Epoch 3028/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0887 - val_accuracy: 0.9814\n",
      "Epoch 3029/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0934 - val_accuracy: 0.9814\n",
      "Epoch 3030/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 3031/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9876\n",
      "Epoch 3032/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0821 - val_accuracy: 0.9845\n",
      "Epoch 3033/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9876\n",
      "Epoch 3034/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9876\n",
      "Epoch 3035/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9845\n",
      "Epoch 3036/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0738 - val_accuracy: 0.9845\n",
      "Epoch 3037/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0851 - val_accuracy: 0.9814\n",
      "Epoch 3038/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0898 - val_accuracy: 0.9814\n",
      "Epoch 3039/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9876\n",
      "Epoch 3040/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9814\n",
      "Epoch 3041/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0164 - accuracy: 0.9923 - val_loss: 0.0754 - val_accuracy: 0.9814\n",
      "Epoch 3042/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0893 - val_accuracy: 0.9814\n",
      "Epoch 3043/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0877 - val_accuracy: 0.9814\n",
      "Epoch 3044/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9845\n",
      "Epoch 3045/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9954 - val_loss: 0.0672 - val_accuracy: 0.9845\n",
      "Epoch 3046/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9876\n",
      "Epoch 3047/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0837 - val_accuracy: 0.9814\n",
      "Epoch 3048/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0833 - val_accuracy: 0.9814\n",
      "Epoch 3049/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0804 - val_accuracy: 0.9845\n",
      "Epoch 3050/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9814\n",
      "Epoch 3051/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0843 - val_accuracy: 0.9814\n",
      "Epoch 3052/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0906 - val_accuracy: 0.9814\n",
      "Epoch 3053/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0799 - val_accuracy: 0.9845\n",
      "Epoch 3054/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9814\n",
      "Epoch 3055/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0139 - accuracy: 0.9923 - val_loss: 0.0781 - val_accuracy: 0.9845\n",
      "Epoch 3056/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0871 - val_accuracy: 0.9814\n",
      "Epoch 3057/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0876 - val_accuracy: 0.9814\n",
      "Epoch 3058/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0811 - val_accuracy: 0.9845\n",
      "Epoch 3059/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 3060/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0881 - val_accuracy: 0.9845\n",
      "Epoch 3061/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0767 - val_accuracy: 0.9876\n",
      "Epoch 3062/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 3063/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0181 - accuracy: 0.9923 - val_loss: 0.0805 - val_accuracy: 0.9814\n",
      "Epoch 3064/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1192 - val_accuracy: 0.9720\n",
      "Epoch 3065/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0307 - accuracy: 0.9877 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 3066/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0634 - val_accuracy: 0.9876\n",
      "Epoch 3067/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9876\n",
      "Epoch 3068/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 3069/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9845\n",
      "Epoch 3070/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0821 - val_accuracy: 0.9845\n",
      "Epoch 3071/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.0957 - val_accuracy: 0.9814\n",
      "Epoch 3072/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0835 - val_accuracy: 0.9814\n",
      "Epoch 3073/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0894 - val_accuracy: 0.9783\n",
      "Epoch 3074/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0181 - accuracy: 0.9923 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 3075/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.1028 - val_accuracy: 0.9814\n",
      "Epoch 3076/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0836 - val_accuracy: 0.9845\n",
      "Epoch 3077/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0772 - val_accuracy: 0.9814\n",
      "Epoch 3078/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.0720 - val_accuracy: 0.9845\n",
      "Epoch 3079/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0767 - val_accuracy: 0.9876\n",
      "Epoch 3080/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0733 - val_accuracy: 0.9876\n",
      "Epoch 3081/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0725 - val_accuracy: 0.9845\n",
      "Epoch 3082/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9876\n",
      "Epoch 3083/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0826 - val_accuracy: 0.9876\n",
      "Epoch 3084/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0823 - val_accuracy: 0.9876\n",
      "Epoch 3085/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9876\n",
      "Epoch 3086/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0781 - val_accuracy: 0.9876\n",
      "Epoch 3087/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9845\n",
      "Epoch 3088/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
      "Epoch 3089/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9876\n",
      "Epoch 3090/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0841 - val_accuracy: 0.9845\n",
      "Epoch 3091/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9876\n",
      "Epoch 3092/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 3093/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 3094/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0792 - val_accuracy: 0.9876\n",
      "Epoch 3095/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
      "Epoch 3096/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0755 - val_accuracy: 0.9845\n",
      "Epoch 3097/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9845\n",
      "Epoch 3098/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9845\n",
      "Epoch 3099/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9876\n",
      "Epoch 3100/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0846 - val_accuracy: 0.9814\n",
      "Epoch 3101/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9876\n",
      "Epoch 3102/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9845\n",
      "Epoch 3103/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9814\n",
      "Epoch 3104/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0130 - accuracy: 0.9923 - val_loss: 0.0792 - val_accuracy: 0.9845\n",
      "Epoch 3105/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0924 - val_accuracy: 0.9814\n",
      "Epoch 3106/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0806 - val_accuracy: 0.9876\n",
      "Epoch 3107/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0781 - val_accuracy: 0.9814\n",
      "Epoch 3108/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0170 - accuracy: 0.9923 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 3109/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0113 - accuracy: 0.9939 - val_loss: 0.0867 - val_accuracy: 0.9814\n",
      "Epoch 3110/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.1097 - val_accuracy: 0.9720\n",
      "Epoch 3111/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.0760 - val_accuracy: 0.9876\n",
      "Epoch 3112/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0722 - val_accuracy: 0.9814\n",
      "Epoch 3113/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0181 - accuracy: 0.9923 - val_loss: 0.0743 - val_accuracy: 0.9845\n",
      "Epoch 3114/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.1144 - val_accuracy: 0.9752\n",
      "Epoch 3115/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0240 - accuracy: 0.9908 - val_loss: 0.0938 - val_accuracy: 0.9814\n",
      "Epoch 3116/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9814\n",
      "Epoch 3117/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0785 - val_accuracy: 0.9783\n",
      "Epoch 3118/3500\n",
      "653/653 [==============================] - 0s 27us/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0768 - val_accuracy: 0.9814\n",
      "Epoch 3119/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.1040 - val_accuracy: 0.9783\n",
      "Epoch 3120/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0857 - val_accuracy: 0.9845\n",
      "Epoch 3121/3500\n",
      "653/653 [==============================] - 0s 66us/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9814\n",
      "Epoch 3122/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0752 - val_accuracy: 0.9814\n",
      "Epoch 3123/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9845\n",
      "Epoch 3124/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0745 - val_accuracy: 0.9845\n",
      "Epoch 3125/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.0776 - val_accuracy: 0.9876\n",
      "Epoch 3126/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0942 - val_accuracy: 0.9783\n",
      "Epoch 3127/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.0789 - val_accuracy: 0.9876\n",
      "Epoch 3128/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0785 - val_accuracy: 0.9783\n",
      "Epoch 3129/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.0763 - val_accuracy: 0.9845\n",
      "Epoch 3130/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0861 - val_accuracy: 0.9814\n",
      "Epoch 3131/3500\n",
      "653/653 [==============================] - 0s 35us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0870 - val_accuracy: 0.9814\n",
      "Epoch 3132/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9845\n",
      "Epoch 3133/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0813 - val_accuracy: 0.9814\n",
      "Epoch 3134/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0820 - val_accuracy: 0.9845\n",
      "Epoch 3135/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0853 - val_accuracy: 0.9814\n",
      "Epoch 3136/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0801 - val_accuracy: 0.9845\n",
      "Epoch 3137/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9876\n",
      "Epoch 3138/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0817 - val_accuracy: 0.9876\n",
      "Epoch 3139/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0825 - val_accuracy: 0.9876\n",
      "Epoch 3140/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0781 - val_accuracy: 0.9876\n",
      "Epoch 3141/3500\n",
      "653/653 [==============================] - 0s 57us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0800 - val_accuracy: 0.9814\n",
      "Epoch 3142/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0127 - accuracy: 0.9923 - val_loss: 0.0797 - val_accuracy: 0.9845\n",
      "Epoch 3143/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0914 - val_accuracy: 0.9814\n",
      "Epoch 3144/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0830 - val_accuracy: 0.9876\n",
      "Epoch 3145/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0798 - val_accuracy: 0.9845\n",
      "Epoch 3146/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 3147/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0810 - val_accuracy: 0.9876\n",
      "Epoch 3148/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0980 - val_accuracy: 0.9783\n",
      "Epoch 3149/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.0869 - val_accuracy: 0.9845\n",
      "Epoch 3150/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 0.0767 - val_accuracy: 0.9845\n",
      "Epoch 3151/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9845\n",
      "Epoch 3152/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 3153/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0913 - val_accuracy: 0.9845\n",
      "Epoch 3154/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0821 - val_accuracy: 0.9876\n",
      "Epoch 3155/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0742 - val_accuracy: 0.9845\n",
      "Epoch 3156/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0748 - val_accuracy: 0.9845\n",
      "Epoch 3157/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9876\n",
      "Epoch 3158/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0834 - val_accuracy: 0.9876\n",
      "Epoch 3159/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0853 - val_accuracy: 0.9845\n",
      "Epoch 3160/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0794 - val_accuracy: 0.9845\n",
      "Epoch 3161/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9814\n",
      "Epoch 3162/3500\n",
      "653/653 [==============================] - 0s 43us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9845\n",
      "Epoch 3163/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0845 - val_accuracy: 0.9845\n",
      "Epoch 3164/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9876\n",
      "Epoch 3165/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0792 - val_accuracy: 0.9845\n",
      "Epoch 3166/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 3167/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0814 - val_accuracy: 0.9876\n",
      "Epoch 3168/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0800 - val_accuracy: 0.9876\n",
      "Epoch 3169/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 3170/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9845\n",
      "Epoch 3171/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9845\n",
      "Epoch 3172/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9954 - val_loss: 0.0798 - val_accuracy: 0.9845\n",
      "Epoch 3173/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0896 - val_accuracy: 0.9814\n",
      "Epoch 3174/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0890 - val_accuracy: 0.9814\n",
      "Epoch 3175/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0781 - val_accuracy: 0.9876\n",
      "Epoch 3176/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
      "Epoch 3177/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0759 - val_accuracy: 0.9876\n",
      "Epoch 3178/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0774 - val_accuracy: 0.9876\n",
      "Epoch 3179/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 3180/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9876\n",
      "Epoch 3181/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0768 - val_accuracy: 0.9876\n",
      "Epoch 3182/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0771 - val_accuracy: 0.9876\n",
      "Epoch 3183/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9845\n",
      "Epoch 3184/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9845\n",
      "Epoch 3185/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0858 - val_accuracy: 0.9814\n",
      "Epoch 3186/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0923 - val_accuracy: 0.9814\n",
      "Epoch 3187/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9876\n",
      "Epoch 3188/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9814\n",
      "Epoch 3189/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0126 - accuracy: 0.9939 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 3190/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0861 - val_accuracy: 0.9814\n",
      "Epoch 3191/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0838 - val_accuracy: 0.9845\n",
      "Epoch 3192/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9845\n",
      "Epoch 3193/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9814\n",
      "Epoch 3194/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9876\n",
      "Epoch 3195/3500\n",
      "653/653 [==============================] - 0s 25us/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.0880 - val_accuracy: 0.9814\n",
      "Epoch 3196/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9876\n",
      "Epoch 3197/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0760 - val_accuracy: 0.9845\n",
      "Epoch 3198/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9845\n",
      "Epoch 3199/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0855 - val_accuracy: 0.9814\n",
      "Epoch 3200/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0841 - val_accuracy: 0.9876\n",
      "Epoch 3201/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9845\n",
      "Epoch 3202/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9845\n",
      "Epoch 3203/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9876\n",
      "Epoch 3204/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0917 - val_accuracy: 0.9752\n",
      "Epoch 3205/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0786 - val_accuracy: 0.9876\n",
      "Epoch 3206/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0779 - val_accuracy: 0.9845\n",
      "Epoch 3207/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9845\n",
      "Epoch 3208/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0904 - val_accuracy: 0.9814\n",
      "Epoch 3209/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0842 - val_accuracy: 0.9845\n",
      "Epoch 3210/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9845\n",
      "Epoch 3211/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9845\n",
      "Epoch 3212/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0912 - val_accuracy: 0.9845\n",
      "Epoch 3213/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0851 - val_accuracy: 0.9845\n",
      "Epoch 3214/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9814\n",
      "Epoch 3215/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0139 - accuracy: 0.9923 - val_loss: 0.0775 - val_accuracy: 0.9814\n",
      "Epoch 3216/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9939 - val_loss: 0.0833 - val_accuracy: 0.9845\n",
      "Epoch 3217/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0947 - val_accuracy: 0.9814\n",
      "Epoch 3218/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0784 - val_accuracy: 0.9876\n",
      "Epoch 3219/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0694 - val_accuracy: 0.9845\n",
      "Epoch 3220/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0703 - val_accuracy: 0.9845\n",
      "Epoch 3221/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0813 - val_accuracy: 0.9876\n",
      "Epoch 3222/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0898 - val_accuracy: 0.9814\n",
      "Epoch 3223/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0811 - val_accuracy: 0.9876\n",
      "Epoch 3224/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 3225/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9845\n",
      "Epoch 3226/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0814 - val_accuracy: 0.9876\n",
      "Epoch 3227/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9876\n",
      "Epoch 3228/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0754 - val_accuracy: 0.9845\n",
      "Epoch 3229/3500\n",
      "653/653 [==============================] - 0s 22us/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9876\n",
      "Epoch 3230/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0920 - val_accuracy: 0.9814\n",
      "Epoch 3231/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0797 - val_accuracy: 0.9845\n",
      "Epoch 3232/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9814\n",
      "Epoch 3233/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0130 - accuracy: 0.9923 - val_loss: 0.0779 - val_accuracy: 0.9845\n",
      "Epoch 3234/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9876\n",
      "Epoch 3235/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0828 - val_accuracy: 0.9876\n",
      "Epoch 3236/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 3237/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
      "Epoch 3238/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0772 - val_accuracy: 0.9845\n",
      "Epoch 3239/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9845\n",
      "Epoch 3240/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0800 - val_accuracy: 0.9845\n",
      "Epoch 3241/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9845\n",
      "Epoch 3242/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0806 - val_accuracy: 0.9876\n",
      "Epoch 3243/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0790 - val_accuracy: 0.9845\n",
      "Epoch 3244/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0797 - val_accuracy: 0.9845\n",
      "Epoch 3245/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0874 - val_accuracy: 0.9845\n",
      "Epoch 3246/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0911 - val_accuracy: 0.9845\n",
      "Epoch 3247/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9876\n",
      "Epoch 3248/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0759 - val_accuracy: 0.9845\n",
      "Epoch 3249/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 3250/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9876\n",
      "Epoch 3251/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 3252/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9845\n",
      "Epoch 3253/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9845\n",
      "Epoch 3254/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9845\n",
      "Epoch 3255/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0846 - val_accuracy: 0.9876\n",
      "Epoch 3256/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9845\n",
      "Epoch 3257/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9845\n",
      "Epoch 3258/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9876\n",
      "Epoch 3259/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0839 - val_accuracy: 0.9845\n",
      "Epoch 3260/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0798 - val_accuracy: 0.9845\n",
      "Epoch 3261/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9845\n",
      "Epoch 3262/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9876\n",
      "Epoch 3263/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0801 - val_accuracy: 0.9876\n",
      "Epoch 3264/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0784 - val_accuracy: 0.9845\n",
      "Epoch 3265/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 3266/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0793 - val_accuracy: 0.9845\n",
      "Epoch 3267/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0804 - val_accuracy: 0.9845\n",
      "Epoch 3268/3500\n",
      "653/653 [==============================] - 0s 51us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0794 - val_accuracy: 0.9876\n",
      "Epoch 3269/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0772 - val_accuracy: 0.9876\n",
      "Epoch 3270/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0756 - val_accuracy: 0.9876\n",
      "Epoch 3271/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0743 - val_accuracy: 0.9845\n",
      "Epoch 3272/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0737 - val_accuracy: 0.9845\n",
      "Epoch 3273/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9845\n",
      "Epoch 3274/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
      "Epoch 3275/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0807 - val_accuracy: 0.9876\n",
      "Epoch 3276/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0783 - val_accuracy: 0.9845\n",
      "Epoch 3277/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9845\n",
      "Epoch 3278/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9876\n",
      "Epoch 3279/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 3280/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0797 - val_accuracy: 0.9876\n",
      "Epoch 3281/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9845\n",
      "Epoch 3282/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
      "Epoch 3283/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9876\n",
      "Epoch 3284/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0894 - val_accuracy: 0.9845\n",
      "Epoch 3285/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9876\n",
      "Epoch 3286/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0835 - val_accuracy: 0.9814\n",
      "Epoch 3287/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9939 - val_loss: 0.0845 - val_accuracy: 0.9845\n",
      "Epoch 3288/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0899 - val_accuracy: 0.9814\n",
      "Epoch 3289/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0938 - val_accuracy: 0.9814\n",
      "Epoch 3290/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9845\n",
      "Epoch 3291/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 3292/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9876\n",
      "Epoch 3293/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9876\n",
      "Epoch 3294/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9876\n",
      "Epoch 3295/3500\n",
      "653/653 [==============================] - 0s 60us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0718 - val_accuracy: 0.9845\n",
      "Epoch 3296/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9876\n",
      "Epoch 3297/3500\n",
      "653/653 [==============================] - 0s 33us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0822 - val_accuracy: 0.9876\n",
      "Epoch 3298/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0820 - val_accuracy: 0.9845\n",
      "Epoch 3299/3500\n",
      "653/653 [==============================] - 0s 28us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0848 - val_accuracy: 0.9845\n",
      "Epoch 3300/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0112 - accuracy: 0.9939 - val_loss: 0.0861 - val_accuracy: 0.9814\n",
      "Epoch 3301/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0916 - val_accuracy: 0.9814\n",
      "Epoch 3302/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0862 - val_accuracy: 0.9845\n",
      "Epoch 3303/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
      "Epoch 3304/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
      "Epoch 3305/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0161 - accuracy: 0.9923 - val_loss: 0.0783 - val_accuracy: 0.9876\n",
      "Epoch 3306/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0999 - val_accuracy: 0.9752\n",
      "Epoch 3307/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0180 - accuracy: 0.9923 - val_loss: 0.0775 - val_accuracy: 0.9876\n",
      "Epoch 3308/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0814 - val_accuracy: 0.9752\n",
      "Epoch 3309/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0211 - accuracy: 0.9908 - val_loss: 0.0809 - val_accuracy: 0.9814\n",
      "Epoch 3310/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0119 - accuracy: 0.9939 - val_loss: 0.0877 - val_accuracy: 0.9814\n",
      "Epoch 3311/3500\n",
      "653/653 [==============================] - 0s 52us/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0927 - val_accuracy: 0.9814\n",
      "Epoch 3312/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0813 - val_accuracy: 0.9876\n",
      "Epoch 3313/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9845\n",
      "Epoch 3314/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
      "Epoch 3315/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0781 - val_accuracy: 0.9876\n",
      "Epoch 3316/3500\n",
      "653/653 [==============================] - 0s 61us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9845\n",
      "Epoch 3317/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0765 - val_accuracy: 0.9814\n",
      "Epoch 3318/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0154 - accuracy: 0.9923 - val_loss: 0.0783 - val_accuracy: 0.9845\n",
      "Epoch 3319/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0926 - val_accuracy: 0.9814\n",
      "Epoch 3320/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0902 - val_accuracy: 0.9814\n",
      "Epoch 3321/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0819 - val_accuracy: 0.9845\n",
      "Epoch 3322/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0836 - val_accuracy: 0.9814\n",
      "Epoch 3323/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0132 - accuracy: 0.9923 - val_loss: 0.0827 - val_accuracy: 0.9876\n",
      "Epoch 3324/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0868 - val_accuracy: 0.9814\n",
      "Epoch 3325/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0793 - val_accuracy: 0.9845\n",
      "Epoch 3326/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9845\n",
      "Epoch 3327/3500\n",
      "653/653 [==============================] - 0s 21us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0835 - val_accuracy: 0.9845\n",
      "Epoch 3328/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0817 - val_accuracy: 0.9876\n",
      "Epoch 3329/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9845\n",
      "Epoch 3330/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0758 - val_accuracy: 0.9845\n",
      "Epoch 3331/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0819 - val_accuracy: 0.9876\n",
      "Epoch 3332/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0812 - val_accuracy: 0.9876\n",
      "Epoch 3333/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0797 - val_accuracy: 0.9845\n",
      "Epoch 3334/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0113 - accuracy: 0.9939 - val_loss: 0.0801 - val_accuracy: 0.9845\n",
      "Epoch 3335/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0886 - val_accuracy: 0.9845\n",
      "Epoch 3336/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0856 - val_accuracy: 0.9814\n",
      "Epoch 3337/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0735 - val_accuracy: 0.9845\n",
      "Epoch 3338/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9845\n",
      "Epoch 3339/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9876\n",
      "Epoch 3340/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0799 - val_accuracy: 0.9845\n",
      "Epoch 3341/3500\n",
      "653/653 [==============================] - 0s 47us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
      "Epoch 3342/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9814\n",
      "Epoch 3343/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9845\n",
      "Epoch 3344/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0871 - val_accuracy: 0.9814\n",
      "Epoch 3345/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0823 - val_accuracy: 0.9845\n",
      "Epoch 3346/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0821 - val_accuracy: 0.9845\n",
      "Epoch 3347/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0819 - val_accuracy: 0.9845\n",
      "Epoch 3348/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0841 - val_accuracy: 0.9876\n",
      "Epoch 3349/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0837 - val_accuracy: 0.9876\n",
      "Epoch 3350/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0785 - val_accuracy: 0.9845\n",
      "Epoch 3351/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 3352/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9845\n",
      "Epoch 3353/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0818 - val_accuracy: 0.9876\n",
      "Epoch 3354/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9876\n",
      "Epoch 3355/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9845\n",
      "Epoch 3356/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9876\n",
      "Epoch 3357/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0867 - val_accuracy: 0.9876\n",
      "Epoch 3358/3500\n",
      "653/653 [==============================] - 0s 37us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9845\n",
      "Epoch 3359/3500\n",
      "653/653 [==============================] - 0s 49us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0828 - val_accuracy: 0.9814\n",
      "Epoch 3360/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0149 - accuracy: 0.9923 - val_loss: 0.0825 - val_accuracy: 0.9845\n",
      "Epoch 3361/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.1005 - val_accuracy: 0.9814\n",
      "Epoch 3362/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0852 - val_accuracy: 0.9845\n",
      "Epoch 3363/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0725 - val_accuracy: 0.9845\n",
      "Epoch 3364/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0707 - val_accuracy: 0.9845\n",
      "Epoch 3365/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9845\n",
      "Epoch 3366/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0853 - val_accuracy: 0.9845\n",
      "Epoch 3367/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0837 - val_accuracy: 0.9845\n",
      "Epoch 3368/3500\n",
      "653/653 [==============================] - 0s 66us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
      "Epoch 3369/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0836 - val_accuracy: 0.9814\n",
      "Epoch 3370/3500\n",
      "653/653 [==============================] - 0s 29us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0841 - val_accuracy: 0.9845\n",
      "Epoch 3371/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0911 - val_accuracy: 0.9814\n",
      "Epoch 3372/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0922 - val_accuracy: 0.9814\n",
      "Epoch 3373/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0818 - val_accuracy: 0.9845\n",
      "Epoch 3374/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9814\n",
      "Epoch 3375/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.0790 - val_accuracy: 0.9876\n",
      "Epoch 3376/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0995 - val_accuracy: 0.9752\n",
      "Epoch 3377/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0178 - accuracy: 0.9923 - val_loss: 0.0715 - val_accuracy: 0.9845\n",
      "Epoch 3378/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.0817 - val_accuracy: 0.9720\n",
      "Epoch 3379/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0233 - accuracy: 0.9908 - val_loss: 0.0853 - val_accuracy: 0.9814\n",
      "Epoch 3380/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.1090 - val_accuracy: 0.9814\n",
      "Epoch 3381/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.0827 - val_accuracy: 0.9845\n",
      "Epoch 3382/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 3383/3500\n",
      "653/653 [==============================] - 0s 26us/step - loss: 0.0231 - accuracy: 0.9893 - val_loss: 0.0781 - val_accuracy: 0.9876\n",
      "Epoch 3384/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.1328 - val_accuracy: 0.9720\n",
      "Epoch 3385/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.0724 - val_accuracy: 0.9876\n",
      "Epoch 3386/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.0686 - val_accuracy: 0.9783\n",
      "Epoch 3387/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0219 - accuracy: 0.9893 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 3388/3500\n",
      "653/653 [==============================] - 0s 41us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1446 - val_accuracy: 0.9720\n",
      "Epoch 3389/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0486 - accuracy: 0.9801 - val_loss: 0.0847 - val_accuracy: 0.9814\n",
      "Epoch 3390/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 0.0665 - val_accuracy: 0.9752\n",
      "Epoch 3391/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0269 - accuracy: 0.9832 - val_loss: 0.1360 - val_accuracy: 0.9783\n",
      "Epoch 3392/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0890 - accuracy: 0.9770 - val_loss: 0.1354 - val_accuracy: 0.9783\n",
      "Epoch 3393/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0641 - accuracy: 0.9786 - val_loss: 0.0643 - val_accuracy: 0.9814\n",
      "Epoch 3394/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.0842 - val_accuracy: 0.9720\n",
      "Epoch 3395/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0433 - accuracy: 0.9847 - val_loss: 0.1160 - val_accuracy: 0.9814\n",
      "Epoch 3396/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0270 - accuracy: 0.9877 - val_loss: 0.1566 - val_accuracy: 0.9689\n",
      "Epoch 3397/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0451 - accuracy: 0.9816 - val_loss: 0.1057 - val_accuracy: 0.9752\n",
      "Epoch 3398/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0340 - accuracy: 0.9862 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
      "Epoch 3399/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.1005 - val_accuracy: 0.9845\n",
      "Epoch 3400/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.1144 - val_accuracy: 0.9752\n",
      "Epoch 3401/3500\n",
      "653/653 [==============================] - 0s 40us/step - loss: 0.0355 - accuracy: 0.9847 - val_loss: 0.0776 - val_accuracy: 0.9783\n",
      "Epoch 3402/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0198 - accuracy: 0.9923 - val_loss: 0.0665 - val_accuracy: 0.9752\n",
      "Epoch 3403/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0342 - accuracy: 0.9832 - val_loss: 0.0655 - val_accuracy: 0.9845\n",
      "Epoch 3404/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0202 - accuracy: 0.9923 - val_loss: 0.0893 - val_accuracy: 0.9783\n",
      "Epoch 3405/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0210 - accuracy: 0.9908 - val_loss: 0.0991 - val_accuracy: 0.9814\n",
      "Epoch 3406/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0232 - accuracy: 0.9893 - val_loss: 0.0874 - val_accuracy: 0.9845\n",
      "Epoch 3407/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0136 - accuracy: 0.9985 - val_loss: 0.0891 - val_accuracy: 0.9752\n",
      "Epoch 3408/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0178 - accuracy: 0.9908 - val_loss: 0.0876 - val_accuracy: 0.9783\n",
      "Epoch 3409/3500\n",
      "653/653 [==============================] - 0s 13us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0927 - val_accuracy: 0.9783\n",
      "Epoch 3410/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0914 - val_accuracy: 0.9845\n",
      "Epoch 3411/3500\n",
      "653/653 [==============================] - 0s 30us/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9814\n",
      "Epoch 3412/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0713 - val_accuracy: 0.9783\n",
      "Epoch 3413/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9814\n",
      "Epoch 3414/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0667 - val_accuracy: 0.9814\n",
      "Epoch 3415/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0676 - val_accuracy: 0.9814\n",
      "Epoch 3416/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0735 - val_accuracy: 0.9845\n",
      "Epoch 3417/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 3418/3500\n",
      "653/653 [==============================] - 0s 46us/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 3419/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.0752 - val_accuracy: 0.9845\n",
      "Epoch 3420/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9814\n",
      "Epoch 3421/3500\n",
      "653/653 [==============================] - 0s 23us/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0818 - val_accuracy: 0.9845\n",
      "Epoch 3422/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9814\n",
      "Epoch 3423/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 3424/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9814\n",
      "Epoch 3425/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0807 - val_accuracy: 0.9814\n",
      "Epoch 3426/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9814\n",
      "Epoch 3427/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0761 - val_accuracy: 0.9814\n",
      "Epoch 3428/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0862 - val_accuracy: 0.9845\n",
      "Epoch 3429/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 0s 9us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0906 - val_accuracy: 0.9845\n",
      "Epoch 3430/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9845\n",
      "Epoch 3431/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9814\n",
      "Epoch 3432/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9845\n",
      "Epoch 3433/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0846 - val_accuracy: 0.9845\n",
      "Epoch 3434/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0875 - val_accuracy: 0.9845\n",
      "Epoch 3435/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0775 - val_accuracy: 0.9845\n",
      "Epoch 3436/3500\n",
      "653/653 [==============================] - 0s 58us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9814\n",
      "Epoch 3437/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9845\n",
      "Epoch 3438/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0875 - val_accuracy: 0.9845\n",
      "Epoch 3439/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0853 - val_accuracy: 0.9845\n",
      "Epoch 3440/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0800 - val_accuracy: 0.9845\n",
      "Epoch 3441/3500\n",
      "653/653 [==============================] - 0s 24us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9845\n",
      "Epoch 3442/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9845\n",
      "Epoch 3443/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
      "Epoch 3444/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0761 - val_accuracy: 0.9845\n",
      "Epoch 3445/3500\n",
      "653/653 [==============================] - 0s 55us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9845\n",
      "Epoch 3446/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0800 - val_accuracy: 0.9845\n",
      "Epoch 3447/3500\n",
      "653/653 [==============================] - 0s 32us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9845\n",
      "Epoch 3448/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0799 - val_accuracy: 0.9845\n",
      "Epoch 3449/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9845\n",
      "Epoch 3450/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "Epoch 3451/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0791 - val_accuracy: 0.9845\n",
      "Epoch 3452/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0823 - val_accuracy: 0.9845\n",
      "Epoch 3453/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9876\n",
      "Epoch 3454/3500\n",
      "653/653 [==============================] - 0s 50us/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9845\n",
      "Epoch 3455/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0777 - val_accuracy: 0.9845\n",
      "Epoch 3456/3500\n",
      "653/653 [==============================] - 0s 34us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9876\n",
      "Epoch 3457/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0862 - val_accuracy: 0.9876\n",
      "Epoch 3458/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0833 - val_accuracy: 0.9876\n",
      "Epoch 3459/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
      "Epoch 3460/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 3461/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9845\n",
      "Epoch 3462/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0867 - val_accuracy: 0.9845\n",
      "Epoch 3463/3500\n",
      "653/653 [==============================] - 0s 56us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0884 - val_accuracy: 0.9845\n",
      "Epoch 3464/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.0797 - val_accuracy: 0.9876\n",
      "Epoch 3465/3500\n",
      "653/653 [==============================] - 0s 20us/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9814\n",
      "Epoch 3466/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0812 - val_accuracy: 0.9814\n",
      "Epoch 3467/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.0787 - val_accuracy: 0.9845\n",
      "Epoch 3468/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0879 - val_accuracy: 0.9845\n",
      "Epoch 3469/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0794 - val_accuracy: 0.9876\n",
      "Epoch 3470/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0811 - val_accuracy: 0.9814\n",
      "Epoch 3471/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.0806 - val_accuracy: 0.9814\n",
      "Epoch 3472/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 3473/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0855 - val_accuracy: 0.9845\n",
      "Epoch 3474/3500\n",
      "653/653 [==============================] - 0s 15us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0814 - val_accuracy: 0.9876\n",
      "Epoch 3475/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "Epoch 3476/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9845\n",
      "Epoch 3477/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0807 - val_accuracy: 0.9876\n",
      "Epoch 3478/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0864 - val_accuracy: 0.9876\n",
      "Epoch 3479/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9845\n",
      "Epoch 3480/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
      "Epoch 3481/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0797 - val_accuracy: 0.9845\n",
      "Epoch 3482/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0876 - val_accuracy: 0.9876\n",
      "Epoch 3483/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0939 - val_accuracy: 0.9814\n",
      "Epoch 3484/3500\n",
      "653/653 [==============================] - 0s 54us/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0858 - val_accuracy: 0.9876\n",
      "Epoch 3485/3500\n",
      "653/653 [==============================] - 0s 44us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9845\n",
      "Epoch 3486/3500\n",
      "653/653 [==============================] - 0s 17us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
      "Epoch 3487/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0774 - val_accuracy: 0.9845\n",
      "Epoch 3488/3500\n",
      "653/653 [==============================] - 0s 18us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9876\n",
      "Epoch 3489/3500\n",
      "653/653 [==============================] - 0s 9us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9876\n",
      "Epoch 3490/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0766 - val_accuracy: 0.9876\n",
      "Epoch 3491/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0805 - val_accuracy: 0.9876\n",
      "Epoch 3492/3500\n",
      "653/653 [==============================] - 0s 14us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0812 - val_accuracy: 0.9876\n",
      "Epoch 3493/3500\n",
      "653/653 [==============================] - 0s 38us/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0783 - val_accuracy: 0.9876\n",
      "Epoch 3494/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0779 - val_accuracy: 0.9845\n",
      "Epoch 3495/3500\n",
      "653/653 [==============================] - 0s 12us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0786 - val_accuracy: 0.9845\n",
      "Epoch 3496/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.0884 - val_accuracy: 0.9845\n",
      "Epoch 3497/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0887 - val_accuracy: 0.9845\n",
      "Epoch 3498/3500\n",
      "653/653 [==============================] - 0s 8us/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0793 - val_accuracy: 0.9845\n",
      "Epoch 3499/3500\n",
      "653/653 [==============================] - 0s 11us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0814 - val_accuracy: 0.9814\n",
      "Epoch 3500/3500\n",
      "653/653 [==============================] - 0s 10us/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0801 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################그래프로 학습 확인하기#############################\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)  # seed 값 설정\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "df_pre = pd.read_csv(goal_path/'wine.csv', header=None)\n",
    "df = df_pre.sample(frac=0.15)  #rac = 1 지정은 원본 데이터의 100%를 불러오라는 의미\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]\n",
    "\n",
    "model = Sequential() # 모델 설정(4개의 은닉층을 만들어 각각 30, 12, 8, 1개의 노드를 주었습니다)\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',   optimizer='adam',    metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = root_path/'datas/실습/output/12월/31일/model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "#테스트 오차는 케라스 내부에서 val_loss, 학습 정확도는 acc, 테스트셋 정확도는 val_acc, 학습셋 오차는 loss로 각각 기록됩니다\n",
    "# 모델 저장 조건 설정\n",
    "modelpath=MODEL_DIR/\"{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500)\n",
    "\n",
    "# y_vloss에 테스트셋(33%)으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋(67%)으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']\n",
    "\n",
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 780 samples, validate on 195 samples\n",
      "Epoch 1/2000\n",
      "780/780 [==============================] - 1s 858us/step - loss: 0.5458 - accuracy: 0.7654 - val_loss: 0.4857 - val_accuracy: 0.7744\n",
      "Epoch 2/2000\n",
      "780/780 [==============================] - 0s 47us/step - loss: 0.4876 - accuracy: 0.7654 - val_loss: 0.4598 - val_accuracy: 0.7744\n",
      "Epoch 3/2000\n",
      "780/780 [==============================] - 0s 45us/step - loss: 0.4526 - accuracy: 0.7641 - val_loss: 0.4339 - val_accuracy: 0.7744\n",
      "Epoch 4/2000\n",
      "780/780 [==============================] - 0s 38us/step - loss: 0.4226 - accuracy: 0.7654 - val_loss: 0.4204 - val_accuracy: 0.7641\n",
      "Epoch 5/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.4069 - accuracy: 0.7641 - val_loss: 0.4077 - val_accuracy: 0.7692\n",
      "Epoch 6/2000\n",
      "780/780 [==============================] - 0s 37us/step - loss: 0.3882 - accuracy: 0.7692 - val_loss: 0.3945 - val_accuracy: 0.7846\n",
      "Epoch 7/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.3741 - accuracy: 0.7808 - val_loss: 0.3863 - val_accuracy: 0.7846\n",
      "Epoch 8/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.3641 - accuracy: 0.7936 - val_loss: 0.3793 - val_accuracy: 0.7949\n",
      "Epoch 9/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.3562 - accuracy: 0.8064 - val_loss: 0.3726 - val_accuracy: 0.7949\n",
      "Epoch 10/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.3488 - accuracy: 0.8192 - val_loss: 0.3657 - val_accuracy: 0.8103\n",
      "Epoch 11/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.3418 - accuracy: 0.8372 - val_loss: 0.3595 - val_accuracy: 0.8205\n",
      "Epoch 12/2000\n",
      "780/780 [==============================] - 0s 33us/step - loss: 0.3357 - accuracy: 0.8449 - val_loss: 0.3543 - val_accuracy: 0.8308\n",
      "Epoch 13/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.3296 - accuracy: 0.8462 - val_loss: 0.3496 - val_accuracy: 0.8410\n",
      "Epoch 14/2000\n",
      "780/780 [==============================] - 0s 37us/step - loss: 0.3238 - accuracy: 0.8577 - val_loss: 0.3448 - val_accuracy: 0.8410\n",
      "Epoch 15/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.3176 - accuracy: 0.8590 - val_loss: 0.3389 - val_accuracy: 0.8513\n",
      "Epoch 16/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.3120 - accuracy: 0.8654 - val_loss: 0.3335 - val_accuracy: 0.8513\n",
      "Epoch 17/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.3065 - accuracy: 0.8769 - val_loss: 0.3288 - val_accuracy: 0.8513\n",
      "Epoch 18/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.3012 - accuracy: 0.8808 - val_loss: 0.3250 - val_accuracy: 0.8513\n",
      "Epoch 19/2000\n",
      "780/780 [==============================] - 0s 29us/step - loss: 0.2952 - accuracy: 0.8821 - val_loss: 0.3235 - val_accuracy: 0.8513\n",
      "Epoch 20/2000\n",
      "780/780 [==============================] - 0s 72us/step - loss: 0.2924 - accuracy: 0.8833 - val_loss: 0.3196 - val_accuracy: 0.8513\n",
      "Epoch 21/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.2869 - accuracy: 0.8846 - val_loss: 0.3124 - val_accuracy: 0.8615\n",
      "Epoch 22/2000\n",
      "780/780 [==============================] - 0s 20us/step - loss: 0.2810 - accuracy: 0.8962 - val_loss: 0.3077 - val_accuracy: 0.8718\n",
      "Epoch 23/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.2771 - accuracy: 0.9013 - val_loss: 0.3035 - val_accuracy: 0.8769\n",
      "Epoch 24/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.2713 - accuracy: 0.9026 - val_loss: 0.3004 - val_accuracy: 0.8769\n",
      "Epoch 25/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.2665 - accuracy: 0.9064 - val_loss: 0.2983 - val_accuracy: 0.8769\n",
      "Epoch 26/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.2624 - accuracy: 0.9064 - val_loss: 0.2936 - val_accuracy: 0.8821\n",
      "Epoch 27/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.2569 - accuracy: 0.9128 - val_loss: 0.2877 - val_accuracy: 0.8821\n",
      "Epoch 28/2000\n",
      "780/780 [==============================] - 0s 22us/step - loss: 0.2519 - accuracy: 0.9167 - val_loss: 0.2837 - val_accuracy: 0.8923\n",
      "Epoch 29/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2482 - accuracy: 0.9167 - val_loss: 0.2792 - val_accuracy: 0.8974\n",
      "Epoch 30/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.2441 - accuracy: 0.9205 - val_loss: 0.2765 - val_accuracy: 0.8923\n",
      "Epoch 31/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.2397 - accuracy: 0.9205 - val_loss: 0.2724 - val_accuracy: 0.8974\n",
      "Epoch 32/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.2357 - accuracy: 0.9244 - val_loss: 0.2676 - val_accuracy: 0.9077\n",
      "Epoch 33/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2323 - accuracy: 0.9244 - val_loss: 0.2639 - val_accuracy: 0.9026\n",
      "Epoch 34/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.2301 - accuracy: 0.9256 - val_loss: 0.2605 - val_accuracy: 0.9026\n",
      "Epoch 35/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.2275 - accuracy: 0.9295 - val_loss: 0.2588 - val_accuracy: 0.9077\n",
      "Epoch 36/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.2244 - accuracy: 0.9269 - val_loss: 0.2556 - val_accuracy: 0.9026\n",
      "Epoch 37/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.2217 - accuracy: 0.9295 - val_loss: 0.2523 - val_accuracy: 0.9077\n",
      "Epoch 38/2000\n",
      "780/780 [==============================] - 0s 47us/step - loss: 0.2195 - accuracy: 0.9308 - val_loss: 0.2497 - val_accuracy: 0.9231\n",
      "Epoch 39/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.2176 - accuracy: 0.9308 - val_loss: 0.2475 - val_accuracy: 0.9231\n",
      "Epoch 40/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.2159 - accuracy: 0.9295 - val_loss: 0.2456 - val_accuracy: 0.9231\n",
      "Epoch 41/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.2144 - accuracy: 0.9308 - val_loss: 0.2446 - val_accuracy: 0.9179\n",
      "Epoch 42/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.2123 - accuracy: 0.9308 - val_loss: 0.2424 - val_accuracy: 0.9231\n",
      "Epoch 43/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2107 - accuracy: 0.9308 - val_loss: 0.2406 - val_accuracy: 0.9282\n",
      "Epoch 44/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2097 - accuracy: 0.9295 - val_loss: 0.2386 - val_accuracy: 0.9282\n",
      "Epoch 45/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2079 - accuracy: 0.9295 - val_loss: 0.2379 - val_accuracy: 0.9282\n",
      "Epoch 46/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.2066 - accuracy: 0.9295 - val_loss: 0.2377 - val_accuracy: 0.9231\n",
      "Epoch 47/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.2060 - accuracy: 0.9295 - val_loss: 0.2352 - val_accuracy: 0.9282\n",
      "Epoch 48/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2046 - accuracy: 0.9295 - val_loss: 0.2324 - val_accuracy: 0.9333\n",
      "Epoch 49/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2036 - accuracy: 0.9321 - val_loss: 0.2308 - val_accuracy: 0.9333\n",
      "Epoch 50/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.2030 - accuracy: 0.9333 - val_loss: 0.2299 - val_accuracy: 0.9333\n",
      "Epoch 51/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.2013 - accuracy: 0.9308 - val_loss: 0.2281 - val_accuracy: 0.9333\n",
      "Epoch 52/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.2003 - accuracy: 0.9333 - val_loss: 0.2268 - val_accuracy: 0.9333\n",
      "Epoch 53/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1994 - accuracy: 0.9346 - val_loss: 0.2253 - val_accuracy: 0.9333\n",
      "Epoch 54/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1983 - accuracy: 0.9346 - val_loss: 0.2245 - val_accuracy: 0.9333\n",
      "Epoch 55/2000\n",
      "780/780 [==============================] - 0s 35us/step - loss: 0.1974 - accuracy: 0.9333 - val_loss: 0.2234 - val_accuracy: 0.9333\n",
      "Epoch 56/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1963 - accuracy: 0.9346 - val_loss: 0.2215 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1957 - accuracy: 0.9346 - val_loss: 0.2200 - val_accuracy: 0.9333\n",
      "Epoch 58/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1944 - accuracy: 0.9346 - val_loss: 0.2185 - val_accuracy: 0.9333\n",
      "Epoch 59/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.1938 - accuracy: 0.9359 - val_loss: 0.2170 - val_accuracy: 0.9333\n",
      "Epoch 60/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1924 - accuracy: 0.9346 - val_loss: 0.2166 - val_accuracy: 0.9333\n",
      "Epoch 61/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1919 - accuracy: 0.9359 - val_loss: 0.2166 - val_accuracy: 0.9385\n",
      "Epoch 62/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1913 - accuracy: 0.9359 - val_loss: 0.2134 - val_accuracy: 0.9333\n",
      "Epoch 63/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1897 - accuracy: 0.9372 - val_loss: 0.2109 - val_accuracy: 0.9385\n",
      "Epoch 64/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1892 - accuracy: 0.9372 - val_loss: 0.2093 - val_accuracy: 0.9385\n",
      "Epoch 65/2000\n",
      "780/780 [==============================] - 0s 49us/step - loss: 0.1879 - accuracy: 0.9359 - val_loss: 0.2092 - val_accuracy: 0.9385\n",
      "Epoch 66/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1870 - accuracy: 0.9346 - val_loss: 0.2084 - val_accuracy: 0.9385\n",
      "Epoch 67/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1857 - accuracy: 0.9372 - val_loss: 0.2057 - val_accuracy: 0.9385\n",
      "Epoch 68/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.1847 - accuracy: 0.9359 - val_loss: 0.2049 - val_accuracy: 0.9385\n",
      "Epoch 69/2000\n",
      "780/780 [==============================] - 0s 44us/step - loss: 0.1851 - accuracy: 0.9333 - val_loss: 0.2036 - val_accuracy: 0.9385\n",
      "Epoch 70/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1833 - accuracy: 0.9346 - val_loss: 0.2036 - val_accuracy: 0.9385\n",
      "Epoch 71/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1835 - accuracy: 0.9346 - val_loss: 0.2065 - val_accuracy: 0.9385\n",
      "Epoch 72/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1833 - accuracy: 0.9359 - val_loss: 0.2020 - val_accuracy: 0.9385\n",
      "Epoch 73/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1813 - accuracy: 0.9359 - val_loss: 0.1992 - val_accuracy: 0.9385\n",
      "Epoch 74/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1807 - accuracy: 0.9359 - val_loss: 0.1981 - val_accuracy: 0.9385\n",
      "Epoch 75/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1797 - accuracy: 0.9346 - val_loss: 0.1980 - val_accuracy: 0.9385\n",
      "Epoch 76/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1786 - accuracy: 0.9359 - val_loss: 0.1983 - val_accuracy: 0.9385\n",
      "Epoch 77/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1784 - accuracy: 0.9372 - val_loss: 0.1974 - val_accuracy: 0.9385\n",
      "Epoch 78/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.1775 - accuracy: 0.9372 - val_loss: 0.1957 - val_accuracy: 0.9385\n",
      "Epoch 79/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1764 - accuracy: 0.9372 - val_loss: 0.1929 - val_accuracy: 0.9385\n",
      "Epoch 80/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1761 - accuracy: 0.9372 - val_loss: 0.1916 - val_accuracy: 0.9385\n",
      "Epoch 81/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1755 - accuracy: 0.9372 - val_loss: 0.1918 - val_accuracy: 0.9385\n",
      "Epoch 82/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1747 - accuracy: 0.9372 - val_loss: 0.1936 - val_accuracy: 0.9385\n",
      "Epoch 83/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1743 - accuracy: 0.9372 - val_loss: 0.1913 - val_accuracy: 0.9385\n",
      "Epoch 84/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1734 - accuracy: 0.9359 - val_loss: 0.1884 - val_accuracy: 0.9385\n",
      "Epoch 85/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1727 - accuracy: 0.9346 - val_loss: 0.1875 - val_accuracy: 0.9385\n",
      "Epoch 86/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1721 - accuracy: 0.9359 - val_loss: 0.1873 - val_accuracy: 0.9385\n",
      "Epoch 87/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1711 - accuracy: 0.9359 - val_loss: 0.1887 - val_accuracy: 0.9385\n",
      "Epoch 88/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1709 - accuracy: 0.9385 - val_loss: 0.1881 - val_accuracy: 0.9385\n",
      "Epoch 89/2000\n",
      "780/780 [==============================] - 0s 33us/step - loss: 0.1701 - accuracy: 0.9385 - val_loss: 0.1866 - val_accuracy: 0.9385\n",
      "Epoch 90/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1692 - accuracy: 0.9385 - val_loss: 0.1840 - val_accuracy: 0.9385\n",
      "Epoch 91/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1689 - accuracy: 0.9346 - val_loss: 0.1827 - val_accuracy: 0.9385\n",
      "Epoch 92/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1684 - accuracy: 0.9359 - val_loss: 0.1832 - val_accuracy: 0.9385\n",
      "Epoch 93/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.1674 - accuracy: 0.9359 - val_loss: 0.1838 - val_accuracy: 0.9385\n",
      "Epoch 94/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1670 - accuracy: 0.9397 - val_loss: 0.1837 - val_accuracy: 0.9385\n",
      "Epoch 95/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1667 - accuracy: 0.9397 - val_loss: 0.1818 - val_accuracy: 0.9385\n",
      "Epoch 96/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1658 - accuracy: 0.9372 - val_loss: 0.1809 - val_accuracy: 0.9385\n",
      "Epoch 97/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1651 - accuracy: 0.9372 - val_loss: 0.1805 - val_accuracy: 0.9385\n",
      "Epoch 98/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.1648 - accuracy: 0.9385 - val_loss: 0.1795 - val_accuracy: 0.9385\n",
      "Epoch 99/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1639 - accuracy: 0.9385 - val_loss: 0.1793 - val_accuracy: 0.9385\n",
      "Epoch 100/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1634 - accuracy: 0.9385 - val_loss: 0.1777 - val_accuracy: 0.9385\n",
      "Epoch 101/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1632 - accuracy: 0.9397 - val_loss: 0.1763 - val_accuracy: 0.9385\n",
      "Epoch 102/2000\n",
      "780/780 [==============================] - 0s 35us/step - loss: 0.1622 - accuracy: 0.9385 - val_loss: 0.1745 - val_accuracy: 0.9436\n",
      "Epoch 103/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1626 - accuracy: 0.9359 - val_loss: 0.1738 - val_accuracy: 0.9436\n",
      "Epoch 104/2000\n",
      "780/780 [==============================] - 0s 19us/step - loss: 0.1611 - accuracy: 0.9372 - val_loss: 0.1767 - val_accuracy: 0.9385\n",
      "Epoch 105/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1606 - accuracy: 0.9410 - val_loss: 0.1802 - val_accuracy: 0.9385\n",
      "Epoch 106/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1626 - accuracy: 0.9385 - val_loss: 0.1774 - val_accuracy: 0.9385\n",
      "Epoch 107/2000\n",
      "780/780 [==============================] - 0s 20us/step - loss: 0.1594 - accuracy: 0.9410 - val_loss: 0.1703 - val_accuracy: 0.9436\n",
      "Epoch 108/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1609 - accuracy: 0.9385 - val_loss: 0.1696 - val_accuracy: 0.9436\n",
      "Epoch 109/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.1603 - accuracy: 0.9372 - val_loss: 0.1722 - val_accuracy: 0.9385\n",
      "Epoch 110/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1614 - accuracy: 0.9397 - val_loss: 0.1798 - val_accuracy: 0.9333\n",
      "Epoch 111/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1600 - accuracy: 0.9397 - val_loss: 0.1709 - val_accuracy: 0.9385\n",
      "Epoch 112/2000\n",
      "780/780 [==============================] - 0s 29us/step - loss: 0.1564 - accuracy: 0.9397 - val_loss: 0.1669 - val_accuracy: 0.9436\n",
      "Epoch 113/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1582 - accuracy: 0.9359 - val_loss: 0.1663 - val_accuracy: 0.9436\n",
      "Epoch 114/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1571 - accuracy: 0.9359 - val_loss: 0.1690 - val_accuracy: 0.9385\n",
      "Epoch 115/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.1576 - accuracy: 0.9385 - val_loss: 0.1721 - val_accuracy: 0.9385\n",
      "Epoch 116/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1568 - accuracy: 0.9397 - val_loss: 0.1664 - val_accuracy: 0.9436\n",
      "Epoch 117/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1545 - accuracy: 0.9385 - val_loss: 0.1648 - val_accuracy: 0.9436\n",
      "Epoch 118/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1550 - accuracy: 0.9385 - val_loss: 0.1645 - val_accuracy: 0.9436\n",
      "Epoch 119/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1534 - accuracy: 0.9397 - val_loss: 0.1682 - val_accuracy: 0.9436\n",
      "Epoch 120/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.1537 - accuracy: 0.9410 - val_loss: 0.1686 - val_accuracy: 0.9436\n",
      "Epoch 121/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1539 - accuracy: 0.9410 - val_loss: 0.1639 - val_accuracy: 0.9487\n",
      "Epoch 122/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1529 - accuracy: 0.9397 - val_loss: 0.1604 - val_accuracy: 0.9436\n",
      "Epoch 123/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1538 - accuracy: 0.9372 - val_loss: 0.1611 - val_accuracy: 0.9487\n",
      "Epoch 124/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.1510 - accuracy: 0.9397 - val_loss: 0.1678 - val_accuracy: 0.9436\n",
      "Epoch 125/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1521 - accuracy: 0.9385 - val_loss: 0.1687 - val_accuracy: 0.9436\n",
      "Epoch 126/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1517 - accuracy: 0.9385 - val_loss: 0.1619 - val_accuracy: 0.9487\n",
      "Epoch 127/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1512 - accuracy: 0.9372 - val_loss: 0.1580 - val_accuracy: 0.9487\n",
      "Epoch 128/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1504 - accuracy: 0.9385 - val_loss: 0.1593 - val_accuracy: 0.9487\n",
      "Epoch 129/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.1486 - accuracy: 0.9385 - val_loss: 0.1631 - val_accuracy: 0.9436\n",
      "Epoch 130/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1489 - accuracy: 0.9410 - val_loss: 0.1647 - val_accuracy: 0.9436\n",
      "Epoch 131/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1492 - accuracy: 0.9385 - val_loss: 0.1609 - val_accuracy: 0.9487\n",
      "Epoch 132/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1474 - accuracy: 0.9385 - val_loss: 0.1559 - val_accuracy: 0.9487\n",
      "Epoch 133/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.1483 - accuracy: 0.9359 - val_loss: 0.1551 - val_accuracy: 0.9487\n",
      "Epoch 134/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1480 - accuracy: 0.9359 - val_loss: 0.1588 - val_accuracy: 0.9487\n",
      "Epoch 135/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1468 - accuracy: 0.9372 - val_loss: 0.1585 - val_accuracy: 0.9487\n",
      "Epoch 136/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1457 - accuracy: 0.9385 - val_loss: 0.1543 - val_accuracy: 0.9487\n",
      "Epoch 137/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1458 - accuracy: 0.9397 - val_loss: 0.1533 - val_accuracy: 0.9487\n",
      "Epoch 138/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1455 - accuracy: 0.9397 - val_loss: 0.1559 - val_accuracy: 0.9487\n",
      "Epoch 139/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.1453 - accuracy: 0.9385 - val_loss: 0.1562 - val_accuracy: 0.9487\n",
      "Epoch 140/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1438 - accuracy: 0.9385 - val_loss: 0.1522 - val_accuracy: 0.9487\n",
      "Epoch 141/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1441 - accuracy: 0.9397 - val_loss: 0.1511 - val_accuracy: 0.9487\n",
      "Epoch 142/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.1437 - accuracy: 0.9397 - val_loss: 0.1543 - val_accuracy: 0.9487\n",
      "Epoch 143/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1430 - accuracy: 0.9397 - val_loss: 0.1609 - val_accuracy: 0.9436\n",
      "Epoch 144/2000\n",
      "780/780 [==============================] - 0s 22us/step - loss: 0.1442 - accuracy: 0.9410 - val_loss: 0.1552 - val_accuracy: 0.9487\n",
      "Epoch 145/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1422 - accuracy: 0.9397 - val_loss: 0.1490 - val_accuracy: 0.9487\n",
      "Epoch 146/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1422 - accuracy: 0.9397 - val_loss: 0.1486 - val_accuracy: 0.9487\n",
      "Epoch 147/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.1415 - accuracy: 0.9397 - val_loss: 0.1509 - val_accuracy: 0.9487\n",
      "Epoch 148/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1405 - accuracy: 0.9410 - val_loss: 0.1539 - val_accuracy: 0.9487\n",
      "Epoch 149/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1406 - accuracy: 0.9372 - val_loss: 0.1519 - val_accuracy: 0.9487\n",
      "Epoch 150/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1401 - accuracy: 0.9410 - val_loss: 0.1489 - val_accuracy: 0.9487\n",
      "Epoch 151/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1395 - accuracy: 0.9410 - val_loss: 0.1488 - val_accuracy: 0.9487\n",
      "Epoch 152/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.1389 - accuracy: 0.9410 - val_loss: 0.1506 - val_accuracy: 0.9487\n",
      "Epoch 153/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1387 - accuracy: 0.9410 - val_loss: 0.1492 - val_accuracy: 0.9487\n",
      "Epoch 154/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1380 - accuracy: 0.9423 - val_loss: 0.1459 - val_accuracy: 0.9487\n",
      "Epoch 155/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1378 - accuracy: 0.9423 - val_loss: 0.1441 - val_accuracy: 0.9487\n",
      "Epoch 156/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1388 - accuracy: 0.9359 - val_loss: 0.1446 - val_accuracy: 0.9487\n",
      "Epoch 157/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1375 - accuracy: 0.9423 - val_loss: 0.1503 - val_accuracy: 0.9487\n",
      "Epoch 158/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1371 - accuracy: 0.9410 - val_loss: 0.1487 - val_accuracy: 0.9487\n",
      "Epoch 159/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1364 - accuracy: 0.9423 - val_loss: 0.1442 - val_accuracy: 0.9487\n",
      "Epoch 160/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.1357 - accuracy: 0.9423 - val_loss: 0.1431 - val_accuracy: 0.9487\n",
      "Epoch 161/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1354 - accuracy: 0.9423 - val_loss: 0.1440 - val_accuracy: 0.9487\n",
      "Epoch 162/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1350 - accuracy: 0.9410 - val_loss: 0.1449 - val_accuracy: 0.9487\n",
      "Epoch 163/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1347 - accuracy: 0.9423 - val_loss: 0.1426 - val_accuracy: 0.9487\n",
      "Epoch 164/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1340 - accuracy: 0.9410 - val_loss: 0.1405 - val_accuracy: 0.9487\n",
      "Epoch 165/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1343 - accuracy: 0.9410 - val_loss: 0.1428 - val_accuracy: 0.9487\n",
      "Epoch 166/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1329 - accuracy: 0.9423 - val_loss: 0.1482 - val_accuracy: 0.9487\n",
      "Epoch 167/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1341 - accuracy: 0.9410 - val_loss: 0.1459 - val_accuracy: 0.9487\n",
      "Epoch 168/2000\n",
      "780/780 [==============================] - 0s 33us/step - loss: 0.1324 - accuracy: 0.9410 - val_loss: 0.1393 - val_accuracy: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1332 - accuracy: 0.9423 - val_loss: 0.1383 - val_accuracy: 0.9487\n",
      "Epoch 170/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1323 - accuracy: 0.9410 - val_loss: 0.1436 - val_accuracy: 0.9487\n",
      "Epoch 171/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.1316 - accuracy: 0.9410 - val_loss: 0.1457 - val_accuracy: 0.9487\n",
      "Epoch 172/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1318 - accuracy: 0.9462 - val_loss: 0.1409 - val_accuracy: 0.9487\n",
      "Epoch 173/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1310 - accuracy: 0.9410 - val_loss: 0.1394 - val_accuracy: 0.9487\n",
      "Epoch 174/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1299 - accuracy: 0.9410 - val_loss: 0.1420 - val_accuracy: 0.9487\n",
      "Epoch 175/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1301 - accuracy: 0.9423 - val_loss: 0.1400 - val_accuracy: 0.9487\n",
      "Epoch 176/2000\n",
      "780/780 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - 0s 31us/step - loss: 0.1287 - accuracy: 0.9423 - val_loss: 0.1361 - val_accuracy: 0.9487\n",
      "Epoch 177/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1301 - accuracy: 0.9410 - val_loss: 0.1363 - val_accuracy: 0.9487\n",
      "Epoch 178/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1288 - accuracy: 0.9410 - val_loss: 0.1384 - val_accuracy: 0.9487\n",
      "Epoch 179/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.1279 - accuracy: 0.9423 - val_loss: 0.1429 - val_accuracy: 0.9487\n",
      "Epoch 180/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.1283 - accuracy: 0.9436 - val_loss: 0.1387 - val_accuracy: 0.9487\n",
      "Epoch 181/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1265 - accuracy: 0.9436 - val_loss: 0.1338 - val_accuracy: 0.9487\n",
      "Epoch 182/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1287 - accuracy: 0.9423 - val_loss: 0.1344 - val_accuracy: 0.9487\n",
      "Epoch 183/2000\n",
      "780/780 [==============================] - 0s 42us/step - loss: 0.1258 - accuracy: 0.9436 - val_loss: 0.1442 - val_accuracy: 0.9487\n",
      "Epoch 184/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1285 - accuracy: 0.9423 - val_loss: 0.1459 - val_accuracy: 0.9436\n",
      "Epoch 185/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.1282 - accuracy: 0.9410 - val_loss: 0.1342 - val_accuracy: 0.9487\n",
      "Epoch 186/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1276 - accuracy: 0.9410 - val_loss: 0.1333 - val_accuracy: 0.9487\n",
      "Epoch 187/2000\n",
      "780/780 [==============================] - 0s 45us/step - loss: 0.1242 - accuracy: 0.9423 - val_loss: 0.1433 - val_accuracy: 0.9487\n",
      "Epoch 188/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.1271 - accuracy: 0.9423 - val_loss: 0.1474 - val_accuracy: 0.9436\n",
      "Epoch 189/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1267 - accuracy: 0.9436 - val_loss: 0.1335 - val_accuracy: 0.9487\n",
      "Epoch 190/2000\n",
      "780/780 [==============================] - 0s 20us/step - loss: 0.1258 - accuracy: 0.9423 - val_loss: 0.1305 - val_accuracy: 0.9487\n",
      "Epoch 191/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1251 - accuracy: 0.9410 - val_loss: 0.1375 - val_accuracy: 0.9487\n",
      "Epoch 192/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1266 - accuracy: 0.9449 - val_loss: 0.1433 - val_accuracy: 0.9436\n",
      "Epoch 193/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1239 - accuracy: 0.9423 - val_loss: 0.1314 - val_accuracy: 0.9487\n",
      "Epoch 194/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1263 - accuracy: 0.9410 - val_loss: 0.1301 - val_accuracy: 0.9487\n",
      "Epoch 195/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.1222 - accuracy: 0.9449 - val_loss: 0.1420 - val_accuracy: 0.9436\n",
      "Epoch 196/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1247 - accuracy: 0.9449 - val_loss: 0.1441 - val_accuracy: 0.9436\n",
      "Epoch 197/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1233 - accuracy: 0.9449 - val_loss: 0.1302 - val_accuracy: 0.9487\n",
      "Epoch 198/2000\n",
      "780/780 [==============================] - 0s 37us/step - loss: 0.1240 - accuracy: 0.9449 - val_loss: 0.1278 - val_accuracy: 0.9487\n",
      "Epoch 199/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1222 - accuracy: 0.9474 - val_loss: 0.1368 - val_accuracy: 0.9487\n",
      "Epoch 200/2000\n",
      "780/780 [==============================] - 0s 29us/step - loss: 0.1233 - accuracy: 0.9449 - val_loss: 0.1474 - val_accuracy: 0.9436\n",
      "Epoch 201/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1245 - accuracy: 0.9436 - val_loss: 0.1320 - val_accuracy: 0.9487\n",
      "Epoch 202/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1203 - accuracy: 0.9449 - val_loss: 0.1270 - val_accuracy: 0.9487\n",
      "Epoch 203/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1231 - accuracy: 0.9513 - val_loss: 0.1316 - val_accuracy: 0.9487\n",
      "Epoch 204/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1210 - accuracy: 0.9436 - val_loss: 0.1469 - val_accuracy: 0.9385\n",
      "Epoch 205/2000\n",
      "780/780 [==============================] - 0s 33us/step - loss: 0.1236 - accuracy: 0.9423 - val_loss: 0.1351 - val_accuracy: 0.9487\n",
      "Epoch 206/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.1196 - accuracy: 0.9410 - val_loss: 0.1264 - val_accuracy: 0.9487\n",
      "Epoch 207/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1201 - accuracy: 0.9474 - val_loss: 0.1279 - val_accuracy: 0.9487\n",
      "Epoch 208/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1171 - accuracy: 0.9436 - val_loss: 0.1367 - val_accuracy: 0.9487\n",
      "Epoch 209/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.1203 - accuracy: 0.9449 - val_loss: 0.1390 - val_accuracy: 0.9487\n",
      "Epoch 210/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.1195 - accuracy: 0.9449 - val_loss: 0.1268 - val_accuracy: 0.9487\n",
      "Epoch 211/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1178 - accuracy: 0.9449 - val_loss: 0.1256 - val_accuracy: 0.9487\n",
      "Epoch 212/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1175 - accuracy: 0.9423 - val_loss: 0.1307 - val_accuracy: 0.9487\n",
      "Epoch 213/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1168 - accuracy: 0.9474 - val_loss: 0.1313 - val_accuracy: 0.9487\n",
      "Epoch 214/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.1157 - accuracy: 0.9462 - val_loss: 0.1255 - val_accuracy: 0.9487\n",
      "Epoch 215/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1158 - accuracy: 0.9449 - val_loss: 0.1241 - val_accuracy: 0.9487\n",
      "Epoch 216/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1162 - accuracy: 0.9462 - val_loss: 0.1257 - val_accuracy: 0.9487\n",
      "Epoch 217/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1151 - accuracy: 0.9436 - val_loss: 0.1288 - val_accuracy: 0.9487\n",
      "Epoch 218/2000\n",
      "780/780 [==============================] - 0s 43us/step - loss: 0.1146 - accuracy: 0.9474 - val_loss: 0.1273 - val_accuracy: 0.9487\n",
      "Epoch 219/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1141 - accuracy: 0.9436 - val_loss: 0.1254 - val_accuracy: 0.9487\n",
      "Epoch 220/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1140 - accuracy: 0.9436 - val_loss: 0.1252 - val_accuracy: 0.9487\n",
      "Epoch 221/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1137 - accuracy: 0.9436 - val_loss: 0.1256 - val_accuracy: 0.9487\n",
      "Epoch 222/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1132 - accuracy: 0.9436 - val_loss: 0.1275 - val_accuracy: 0.9487\n",
      "Epoch 223/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1129 - accuracy: 0.9462 - val_loss: 0.1259 - val_accuracy: 0.9487\n",
      "Epoch 224/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.1136 - accuracy: 0.9436 - val_loss: 0.1246 - val_accuracy: 0.9487\n",
      "Epoch 225/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1121 - accuracy: 0.9449 - val_loss: 0.1283 - val_accuracy: 0.9487\n",
      "Epoch 226/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1123 - accuracy: 0.9462 - val_loss: 0.1261 - val_accuracy: 0.9487\n",
      "Epoch 227/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1116 - accuracy: 0.9462 - val_loss: 0.1222 - val_accuracy: 0.9487\n",
      "Epoch 228/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.1123 - accuracy: 0.9462 - val_loss: 0.1231 - val_accuracy: 0.9487\n",
      "Epoch 229/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1134 - accuracy: 0.9474 - val_loss: 0.1281 - val_accuracy: 0.9487\n",
      "Epoch 230/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1110 - accuracy: 0.9462 - val_loss: 0.1208 - val_accuracy: 0.9487\n",
      "Epoch 231/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1109 - accuracy: 0.9474 - val_loss: 0.1195 - val_accuracy: 0.9487\n",
      "Epoch 232/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1105 - accuracy: 0.9526 - val_loss: 0.1253 - val_accuracy: 0.9487\n",
      "Epoch 233/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1140 - accuracy: 0.9462 - val_loss: 0.1291 - val_accuracy: 0.9487\n",
      "Epoch 234/2000\n",
      "780/780 [==============================] - 0s 19us/step - loss: 0.1110 - accuracy: 0.9449 - val_loss: 0.1187 - val_accuracy: 0.9487\n",
      "Epoch 235/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1112 - accuracy: 0.9538 - val_loss: 0.1199 - val_accuracy: 0.9487\n",
      "Epoch 236/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1105 - accuracy: 0.9474 - val_loss: 0.1277 - val_accuracy: 0.9487\n",
      "Epoch 237/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1097 - accuracy: 0.9449 - val_loss: 0.1225 - val_accuracy: 0.9487\n",
      "Epoch 238/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1084 - accuracy: 0.9487 - val_loss: 0.1177 - val_accuracy: 0.9487\n",
      "Epoch 239/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.1090 - accuracy: 0.9526 - val_loss: 0.1190 - val_accuracy: 0.9487\n",
      "Epoch 240/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1076 - accuracy: 0.9487 - val_loss: 0.1209 - val_accuracy: 0.9487\n",
      "Epoch 241/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.1085 - accuracy: 0.9474 - val_loss: 0.1193 - val_accuracy: 0.9487\n",
      "Epoch 242/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1067 - accuracy: 0.9500 - val_loss: 0.1157 - val_accuracy: 0.9487\n",
      "Epoch 243/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1081 - accuracy: 0.9526 - val_loss: 0.1181 - val_accuracy: 0.9487\n",
      "Epoch 244/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.1076 - accuracy: 0.9449 - val_loss: 0.1234 - val_accuracy: 0.9487\n",
      "Epoch 245/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1065 - accuracy: 0.9474 - val_loss: 0.1183 - val_accuracy: 0.9487\n",
      "Epoch 246/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1057 - accuracy: 0.9500 - val_loss: 0.1164 - val_accuracy: 0.9487\n",
      "Epoch 247/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1057 - accuracy: 0.9513 - val_loss: 0.1186 - val_accuracy: 0.9487\n",
      "Epoch 248/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1055 - accuracy: 0.9513 - val_loss: 0.1207 - val_accuracy: 0.9487\n",
      "Epoch 249/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.1054 - accuracy: 0.9487 - val_loss: 0.1156 - val_accuracy: 0.9487\n",
      "Epoch 250/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.1058 - accuracy: 0.9551 - val_loss: 0.1133 - val_accuracy: 0.9538\n",
      "Epoch 251/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1049 - accuracy: 0.9526 - val_loss: 0.1207 - val_accuracy: 0.9487\n",
      "Epoch 252/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.1054 - accuracy: 0.9449 - val_loss: 0.1243 - val_accuracy: 0.9487\n",
      "Epoch 253/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1055 - accuracy: 0.9500 - val_loss: 0.1146 - val_accuracy: 0.9487\n",
      "Epoch 254/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1036 - accuracy: 0.9526 - val_loss: 0.1132 - val_accuracy: 0.9487\n",
      "Epoch 255/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.1036 - accuracy: 0.9513 - val_loss: 0.1172 - val_accuracy: 0.9487\n",
      "Epoch 256/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1029 - accuracy: 0.9500 - val_loss: 0.1202 - val_accuracy: 0.9487\n",
      "Epoch 257/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1038 - accuracy: 0.9474 - val_loss: 0.1182 - val_accuracy: 0.9487\n",
      "Epoch 258/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.1052 - accuracy: 0.9500 - val_loss: 0.1127 - val_accuracy: 0.9487\n",
      "Epoch 259/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.1020 - accuracy: 0.9526 - val_loss: 0.1198 - val_accuracy: 0.9487\n",
      "Epoch 260/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1037 - accuracy: 0.9487 - val_loss: 0.1232 - val_accuracy: 0.9487\n",
      "Epoch 261/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1031 - accuracy: 0.9462 - val_loss: 0.1124 - val_accuracy: 0.9487\n",
      "Epoch 262/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.1015 - accuracy: 0.9526 - val_loss: 0.1116 - val_accuracy: 0.9538\n",
      "Epoch 263/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.1013 - accuracy: 0.9513 - val_loss: 0.1165 - val_accuracy: 0.9487\n",
      "Epoch 264/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1006 - accuracy: 0.9513 - val_loss: 0.1208 - val_accuracy: 0.9487\n",
      "Epoch 265/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.1028 - accuracy: 0.9449 - val_loss: 0.1164 - val_accuracy: 0.9487\n",
      "Epoch 266/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0990 - accuracy: 0.9513 - val_loss: 0.1085 - val_accuracy: 0.9538\n",
      "Epoch 267/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1039 - accuracy: 0.9603 - val_loss: 0.1097 - val_accuracy: 0.9538\n",
      "Epoch 268/2000\n",
      "780/780 [==============================] - 0s 18us/step - loss: 0.1006 - accuracy: 0.9487 - val_loss: 0.1231 - val_accuracy: 0.9487\n",
      "Epoch 269/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.1021 - accuracy: 0.9449 - val_loss: 0.1180 - val_accuracy: 0.9538\n",
      "Epoch 270/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0994 - accuracy: 0.9513 - val_loss: 0.1088 - val_accuracy: 0.9538\n",
      "Epoch 271/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.1002 - accuracy: 0.9538 - val_loss: 0.1089 - val_accuracy: 0.9538\n",
      "Epoch 272/2000\n",
      "780/780 [==============================] - 0s 37us/step - loss: 0.0995 - accuracy: 0.9526 - val_loss: 0.1164 - val_accuracy: 0.9487\n",
      "Epoch 273/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0988 - accuracy: 0.9500 - val_loss: 0.1139 - val_accuracy: 0.9487\n",
      "Epoch 274/2000\n",
      "780/780 [==============================] - 0s 21us/step - loss: 0.0989 - accuracy: 0.9513 - val_loss: 0.1097 - val_accuracy: 0.9538\n",
      "Epoch 275/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0983 - accuracy: 0.9526 - val_loss: 0.1118 - val_accuracy: 0.9487\n",
      "Epoch 276/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0973 - accuracy: 0.9551 - val_loss: 0.1103 - val_accuracy: 0.9487\n",
      "Epoch 277/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0969 - accuracy: 0.9538 - val_loss: 0.1106 - val_accuracy: 0.9487\n",
      "Epoch 278/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.0967 - accuracy: 0.9526 - val_loss: 0.1098 - val_accuracy: 0.9487\n",
      "Epoch 279/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0963 - accuracy: 0.9564 - val_loss: 0.1080 - val_accuracy: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0962 - accuracy: 0.9564 - val_loss: 0.1085 - val_accuracy: 0.9487\n",
      "Epoch 281/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0959 - accuracy: 0.9590 - val_loss: 0.1105 - val_accuracy: 0.9487\n",
      "Epoch 282/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0958 - accuracy: 0.9551 - val_loss: 0.1121 - val_accuracy: 0.9487\n",
      "Epoch 283/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0957 - accuracy: 0.9538 - val_loss: 0.1114 - val_accuracy: 0.9487\n",
      "Epoch 284/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0956 - accuracy: 0.9526 - val_loss: 0.1084 - val_accuracy: 0.9538\n",
      "Epoch 285/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0952 - accuracy: 0.9577 - val_loss: 0.1093 - val_accuracy: 0.9487\n",
      "Epoch 286/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0950 - accuracy: 0.9551 - val_loss: 0.1110 - val_accuracy: 0.9487\n",
      "Epoch 287/2000\n",
      "780/780 [==============================] - 0s 38us/step - loss: 0.0948 - accuracy: 0.9538 - val_loss: 0.1063 - val_accuracy: 0.9538\n",
      "Epoch 288/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0942 - accuracy: 0.9564 - val_loss: 0.1064 - val_accuracy: 0.9538\n",
      "Epoch 289/2000\n",
      "780/780 [==============================] - 0s 22us/step - loss: 0.0938 - accuracy: 0.9577 - val_loss: 0.1067 - val_accuracy: 0.9538\n",
      "Epoch 290/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0935 - accuracy: 0.9577 - val_loss: 0.1077 - val_accuracy: 0.9487\n",
      "Epoch 291/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0938 - accuracy: 0.9564 - val_loss: 0.1080 - val_accuracy: 0.9487\n",
      "Epoch 292/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0929 - accuracy: 0.9564 - val_loss: 0.1040 - val_accuracy: 0.9538\n",
      "Epoch 293/2000\n",
      "780/780 [==============================] - 0s 19us/step - loss: 0.0933 - accuracy: 0.9603 - val_loss: 0.1050 - val_accuracy: 0.9538\n",
      "Epoch 294/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0933 - accuracy: 0.9538 - val_loss: 0.1077 - val_accuracy: 0.9487\n",
      "Epoch 295/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0923 - accuracy: 0.9577 - val_loss: 0.1046 - val_accuracy: 0.9538\n",
      "Epoch 296/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0932 - accuracy: 0.9603 - val_loss: 0.1059 - val_accuracy: 0.9487\n",
      "Epoch 297/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0916 - accuracy: 0.9590 - val_loss: 0.1124 - val_accuracy: 0.9538\n",
      "Epoch 298/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0934 - accuracy: 0.9513 - val_loss: 0.1066 - val_accuracy: 0.9538\n",
      "Epoch 299/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0913 - accuracy: 0.9615 - val_loss: 0.1003 - val_accuracy: 0.9538\n",
      "Epoch 300/2000\n",
      "780/780 [==============================] - 0s 44us/step - loss: 0.0928 - accuracy: 0.9654 - val_loss: 0.1038 - val_accuracy: 0.9538\n",
      "Epoch 301/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0907 - accuracy: 0.9603 - val_loss: 0.1094 - val_accuracy: 0.9538\n",
      "Epoch 302/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.0914 - accuracy: 0.9538 - val_loss: 0.1046 - val_accuracy: 0.9590\n",
      "Epoch 303/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0909 - accuracy: 0.9603 - val_loss: 0.1006 - val_accuracy: 0.9538\n",
      "Epoch 304/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0908 - accuracy: 0.9641 - val_loss: 0.1069 - val_accuracy: 0.9538\n",
      "Epoch 305/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0943 - accuracy: 0.9526 - val_loss: 0.1101 - val_accuracy: 0.9538\n",
      "Epoch 306/2000\n",
      "780/780 [==============================] - 0s 45us/step - loss: 0.0935 - accuracy: 0.9526 - val_loss: 0.0992 - val_accuracy: 0.9538\n",
      "Epoch 307/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0906 - accuracy: 0.9654 - val_loss: 0.1045 - val_accuracy: 0.9590\n",
      "Epoch 308/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0890 - accuracy: 0.9590 - val_loss: 0.1115 - val_accuracy: 0.9487\n",
      "Epoch 309/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0911 - accuracy: 0.9551 - val_loss: 0.1039 - val_accuracy: 0.9590\n",
      "Epoch 310/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0886 - accuracy: 0.9615 - val_loss: 0.0987 - val_accuracy: 0.9538\n",
      "Epoch 311/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0893 - accuracy: 0.9654 - val_loss: 0.0998 - val_accuracy: 0.9538\n",
      "Epoch 312/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.0884 - accuracy: 0.9603 - val_loss: 0.1053 - val_accuracy: 0.9538\n",
      "Epoch 313/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0882 - accuracy: 0.9603 - val_loss: 0.1037 - val_accuracy: 0.9590\n",
      "Epoch 314/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.0877 - accuracy: 0.9590 - val_loss: 0.1002 - val_accuracy: 0.9538\n",
      "Epoch 315/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0877 - accuracy: 0.9679 - val_loss: 0.1012 - val_accuracy: 0.9590\n",
      "Epoch 316/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0873 - accuracy: 0.9679 - val_loss: 0.1035 - val_accuracy: 0.9590\n",
      "Epoch 317/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0871 - accuracy: 0.9590 - val_loss: 0.1053 - val_accuracy: 0.9590\n",
      "Epoch 318/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0885 - accuracy: 0.9590 - val_loss: 0.1014 - val_accuracy: 0.9590\n",
      "Epoch 319/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0878 - accuracy: 0.9590 - val_loss: 0.1013 - val_accuracy: 0.9590\n",
      "Epoch 320/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0877 - accuracy: 0.9603 - val_loss: 0.0978 - val_accuracy: 0.9538\n",
      "Epoch 321/2000\n",
      "780/780 [==============================] - 0s 35us/step - loss: 0.0866 - accuracy: 0.9628 - val_loss: 0.1037 - val_accuracy: 0.9590\n",
      "Epoch 322/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0870 - accuracy: 0.9615 - val_loss: 0.1011 - val_accuracy: 0.9590\n",
      "Epoch 323/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0851 - accuracy: 0.9667 - val_loss: 0.0959 - val_accuracy: 0.9538\n",
      "Epoch 324/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0879 - accuracy: 0.9641 - val_loss: 0.1005 - val_accuracy: 0.9590\n",
      "Epoch 325/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.0892 - accuracy: 0.9603 - val_loss: 0.1106 - val_accuracy: 0.9487\n",
      "Epoch 326/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0880 - accuracy: 0.9564 - val_loss: 0.0964 - val_accuracy: 0.9590\n",
      "Epoch 327/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.0855 - accuracy: 0.9692 - val_loss: 0.0963 - val_accuracy: 0.9590\n",
      "Epoch 328/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0847 - accuracy: 0.9692 - val_loss: 0.1034 - val_accuracy: 0.9538\n",
      "Epoch 329/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0859 - accuracy: 0.9590 - val_loss: 0.1009 - val_accuracy: 0.9590\n",
      "Epoch 330/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.0943 - val_accuracy: 0.9538\n",
      "Epoch 331/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0859 - accuracy: 0.9654 - val_loss: 0.0978 - val_accuracy: 0.9590\n",
      "Epoch 332/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0845 - accuracy: 0.9628 - val_loss: 0.1056 - val_accuracy: 0.9487\n",
      "Epoch 333/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0846 - accuracy: 0.9577 - val_loss: 0.0962 - val_accuracy: 0.9590\n",
      "Epoch 334/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0857 - accuracy: 0.9667 - val_loss: 0.0936 - val_accuracy: 0.9538\n",
      "Epoch 335/2000\n",
      "780/780 [==============================] - 0s 29us/step - loss: 0.0838 - accuracy: 0.9692 - val_loss: 0.1047 - val_accuracy: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0870 - accuracy: 0.9564 - val_loss: 0.1003 - val_accuracy: 0.9538\n",
      "Epoch 337/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0827 - accuracy: 0.9641 - val_loss: 0.0917 - val_accuracy: 0.9692\n",
      "Epoch 338/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0871 - accuracy: 0.9654 - val_loss: 0.0962 - val_accuracy: 0.9590\n",
      "Epoch 339/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0825 - accuracy: 0.9628 - val_loss: 0.1050 - val_accuracy: 0.9487\n",
      "Epoch 340/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0838 - accuracy: 0.9603 - val_loss: 0.0967 - val_accuracy: 0.9590\n",
      "Epoch 341/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0813 - accuracy: 0.9705 - val_loss: 0.0935 - val_accuracy: 0.9590\n",
      "Epoch 342/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0823 - accuracy: 0.9692 - val_loss: 0.0971 - val_accuracy: 0.9590\n",
      "Epoch 343/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0809 - accuracy: 0.9692 - val_loss: 0.1052 - val_accuracy: 0.9538\n",
      "Epoch 344/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0831 - accuracy: 0.9577 - val_loss: 0.0970 - val_accuracy: 0.9590\n",
      "Epoch 345/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0828 - accuracy: 0.9705 - val_loss: 0.0932 - val_accuracy: 0.9590\n",
      "Epoch 346/2000\n",
      "780/780 [==============================] - 0s 50us/step - loss: 0.0814 - accuracy: 0.9679 - val_loss: 0.0988 - val_accuracy: 0.9538\n",
      "Epoch 347/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0805 - accuracy: 0.9667 - val_loss: 0.0958 - val_accuracy: 0.9590\n",
      "Epoch 348/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0797 - accuracy: 0.9718 - val_loss: 0.0938 - val_accuracy: 0.9590\n",
      "Epoch 349/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0795 - accuracy: 0.9718 - val_loss: 0.0928 - val_accuracy: 0.9590\n",
      "Epoch 350/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0794 - accuracy: 0.9718 - val_loss: 0.0948 - val_accuracy: 0.9538\n",
      "Epoch 351/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0791 - accuracy: 0.9705 - val_loss: 0.0964 - val_accuracy: 0.9538\n",
      "Epoch 352/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0792 - accuracy: 0.9679 - val_loss: 0.0961 - val_accuracy: 0.9538\n",
      "Epoch 353/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0787 - accuracy: 0.9692 - val_loss: 0.0951 - val_accuracy: 0.9538\n",
      "Epoch 354/2000\n",
      "780/780 [==============================] - 0s 30us/step - loss: 0.0784 - accuracy: 0.9705 - val_loss: 0.0937 - val_accuracy: 0.9538\n",
      "Epoch 355/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0785 - accuracy: 0.9718 - val_loss: 0.0926 - val_accuracy: 0.9590\n",
      "Epoch 356/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0780 - accuracy: 0.9731 - val_loss: 0.0910 - val_accuracy: 0.9590\n",
      "Epoch 357/2000\n",
      "780/780 [==============================] - 0s 51us/step - loss: 0.0783 - accuracy: 0.9692 - val_loss: 0.0930 - val_accuracy: 0.9590\n",
      "Epoch 358/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0779 - accuracy: 0.9718 - val_loss: 0.0952 - val_accuracy: 0.9538\n",
      "Epoch 359/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0782 - accuracy: 0.9705 - val_loss: 0.0933 - val_accuracy: 0.9590\n",
      "Epoch 360/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0772 - accuracy: 0.9744 - val_loss: 0.0945 - val_accuracy: 0.9538\n",
      "Epoch 361/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 0.0911 - val_accuracy: 0.9590\n",
      "Epoch 362/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0769 - accuracy: 0.9705 - val_loss: 0.0894 - val_accuracy: 0.9641\n",
      "Epoch 363/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0770 - accuracy: 0.9705 - val_loss: 0.0930 - val_accuracy: 0.9590\n",
      "Epoch 364/2000\n",
      "780/780 [==============================] - 0s 36us/step - loss: 0.0763 - accuracy: 0.9718 - val_loss: 0.0944 - val_accuracy: 0.9538\n",
      "Epoch 365/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0764 - accuracy: 0.9692 - val_loss: 0.0911 - val_accuracy: 0.9590\n",
      "Epoch 366/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.0760 - accuracy: 0.9731 - val_loss: 0.0900 - val_accuracy: 0.9590\n",
      "Epoch 367/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0760 - accuracy: 0.9705 - val_loss: 0.0896 - val_accuracy: 0.9590\n",
      "Epoch 368/2000\n",
      "780/780 [==============================] - 0s 21us/step - loss: 0.0754 - accuracy: 0.9731 - val_loss: 0.0933 - val_accuracy: 0.9538\n",
      "Epoch 369/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0755 - accuracy: 0.9705 - val_loss: 0.0900 - val_accuracy: 0.9590\n",
      "Epoch 370/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0748 - accuracy: 0.9718 - val_loss: 0.0868 - val_accuracy: 0.9641\n",
      "Epoch 371/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0755 - accuracy: 0.9692 - val_loss: 0.0893 - val_accuracy: 0.9590\n",
      "Epoch 372/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0744 - accuracy: 0.9744 - val_loss: 0.0945 - val_accuracy: 0.9538\n",
      "Epoch 373/2000\n",
      "780/780 [==============================] - 0s 29us/step - loss: 0.0754 - accuracy: 0.9679 - val_loss: 0.0911 - val_accuracy: 0.9590\n",
      "Epoch 374/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0742 - accuracy: 0.9718 - val_loss: 0.0855 - val_accuracy: 0.9692\n",
      "Epoch 375/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0749 - accuracy: 0.9705 - val_loss: 0.0889 - val_accuracy: 0.9590\n",
      "Epoch 376/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0734 - accuracy: 0.9744 - val_loss: 0.0943 - val_accuracy: 0.9538\n",
      "Epoch 377/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0746 - accuracy: 0.9692 - val_loss: 0.0917 - val_accuracy: 0.9538\n",
      "Epoch 378/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0731 - accuracy: 0.9705 - val_loss: 0.0849 - val_accuracy: 0.9641\n",
      "Epoch 379/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0743 - accuracy: 0.9705 - val_loss: 0.0864 - val_accuracy: 0.9641\n",
      "Epoch 380/2000\n",
      "780/780 [==============================] - 0s 36us/step - loss: 0.0727 - accuracy: 0.9705 - val_loss: 0.0927 - val_accuracy: 0.9538\n",
      "Epoch 381/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0739 - accuracy: 0.9705 - val_loss: 0.0922 - val_accuracy: 0.9538\n",
      "Epoch 382/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0731 - accuracy: 0.9692 - val_loss: 0.0849 - val_accuracy: 0.9744\n",
      "Epoch 383/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0737 - accuracy: 0.9718 - val_loss: 0.0883 - val_accuracy: 0.9641\n",
      "Epoch 384/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0730 - accuracy: 0.9705 - val_loss: 0.0958 - val_accuracy: 0.9538\n",
      "Epoch 385/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0735 - accuracy: 0.9705 - val_loss: 0.0859 - val_accuracy: 0.9641\n",
      "Epoch 386/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0719 - accuracy: 0.9692 - val_loss: 0.0840 - val_accuracy: 0.9641\n",
      "Epoch 387/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0716 - accuracy: 0.9731 - val_loss: 0.0908 - val_accuracy: 0.9538\n",
      "Epoch 388/2000\n",
      "780/780 [==============================] - 0s 22us/step - loss: 0.0718 - accuracy: 0.9718 - val_loss: 0.0943 - val_accuracy: 0.9538\n",
      "Epoch 389/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0726 - accuracy: 0.9705 - val_loss: 0.0861 - val_accuracy: 0.9641\n",
      "Epoch 390/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0729 - accuracy: 0.9718 - val_loss: 0.0833 - val_accuracy: 0.9795\n",
      "Epoch 391/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0720 - accuracy: 0.9756 - val_loss: 0.0911 - val_accuracy: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.0718 - accuracy: 0.9756 - val_loss: 0.0886 - val_accuracy: 0.9590\n",
      "Epoch 393/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 0.0857 - val_accuracy: 0.9641\n",
      "Epoch 394/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.0719 - accuracy: 0.9718 - val_loss: 0.0837 - val_accuracy: 0.9692\n",
      "Epoch 395/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0697 - accuracy: 0.9756 - val_loss: 0.0929 - val_accuracy: 0.9538\n",
      "Epoch 396/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0718 - accuracy: 0.9667 - val_loss: 0.0884 - val_accuracy: 0.9590\n",
      "Epoch 397/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0700 - accuracy: 0.9744 - val_loss: 0.0810 - val_accuracy: 0.9795\n",
      "Epoch 398/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0717 - accuracy: 0.9692 - val_loss: 0.0859 - val_accuracy: 0.9590\n",
      "Epoch 399/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0694 - accuracy: 0.9756 - val_loss: 0.0877 - val_accuracy: 0.9590\n",
      "Epoch 400/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0690 - accuracy: 0.9744 - val_loss: 0.0830 - val_accuracy: 0.9641\n",
      "Epoch 401/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0690 - accuracy: 0.9731 - val_loss: 0.0846 - val_accuracy: 0.9590\n",
      "Epoch 402/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0693 - accuracy: 0.9756 - val_loss: 0.0876 - val_accuracy: 0.9590\n",
      "Epoch 403/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0682 - accuracy: 0.9769 - val_loss: 0.0813 - val_accuracy: 0.9795\n",
      "Epoch 404/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0710 - accuracy: 0.9705 - val_loss: 0.0820 - val_accuracy: 0.9692\n",
      "Epoch 405/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0700 - accuracy: 0.9692 - val_loss: 0.0923 - val_accuracy: 0.9538\n",
      "Epoch 406/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0691 - accuracy: 0.9718 - val_loss: 0.0817 - val_accuracy: 0.9641\n",
      "Epoch 407/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0681 - accuracy: 0.9731 - val_loss: 0.0798 - val_accuracy: 0.9795\n",
      "Epoch 408/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.0689 - accuracy: 0.9731 - val_loss: 0.0868 - val_accuracy: 0.9590\n",
      "Epoch 409/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.0850 - val_accuracy: 0.9590\n",
      "Epoch 410/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0668 - accuracy: 0.9756 - val_loss: 0.0815 - val_accuracy: 0.9795\n",
      "Epoch 411/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0667 - accuracy: 0.9744 - val_loss: 0.0818 - val_accuracy: 0.9641\n",
      "Epoch 412/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0665 - accuracy: 0.9769 - val_loss: 0.0836 - val_accuracy: 0.9590\n",
      "Epoch 413/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0663 - accuracy: 0.9756 - val_loss: 0.0837 - val_accuracy: 0.9590\n",
      "Epoch 414/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0663 - accuracy: 0.9769 - val_loss: 0.0833 - val_accuracy: 0.9590\n",
      "Epoch 415/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0675 - accuracy: 0.9769 - val_loss: 0.0817 - val_accuracy: 0.9641\n",
      "Epoch 416/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0661 - accuracy: 0.9744 - val_loss: 0.0864 - val_accuracy: 0.9590\n",
      "Epoch 417/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0660 - accuracy: 0.9769 - val_loss: 0.0807 - val_accuracy: 0.9641\n",
      "Epoch 418/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0666 - accuracy: 0.9744 - val_loss: 0.0794 - val_accuracy: 0.9795\n",
      "Epoch 419/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.0655 - accuracy: 0.9744 - val_loss: 0.0872 - val_accuracy: 0.9590\n",
      "Epoch 420/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0661 - accuracy: 0.9769 - val_loss: 0.0822 - val_accuracy: 0.9590\n",
      "Epoch 421/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.0769 - val_accuracy: 0.9795\n",
      "Epoch 422/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0669 - accuracy: 0.9756 - val_loss: 0.0793 - val_accuracy: 0.9795\n",
      "Epoch 423/2000\n",
      "780/780 [==============================] - 0s 35us/step - loss: 0.0640 - accuracy: 0.9744 - val_loss: 0.0889 - val_accuracy: 0.9590\n",
      "Epoch 424/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0668 - accuracy: 0.9744 - val_loss: 0.0826 - val_accuracy: 0.9590\n",
      "Epoch 425/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.0654 - accuracy: 0.9731 - val_loss: 0.0764 - val_accuracy: 0.9795\n",
      "Epoch 426/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0657 - accuracy: 0.9756 - val_loss: 0.0852 - val_accuracy: 0.9590\n",
      "Epoch 427/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0653 - accuracy: 0.9756 - val_loss: 0.0922 - val_accuracy: 0.9538\n",
      "Epoch 428/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0660 - accuracy: 0.9705 - val_loss: 0.0776 - val_accuracy: 0.9795\n",
      "Epoch 429/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.0638 - accuracy: 0.9744 - val_loss: 0.0760 - val_accuracy: 0.9795\n",
      "Epoch 430/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0646 - accuracy: 0.9756 - val_loss: 0.0834 - val_accuracy: 0.9590\n",
      "Epoch 431/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0658 - accuracy: 0.9744 - val_loss: 0.0859 - val_accuracy: 0.9590\n",
      "Epoch 432/2000\n",
      "780/780 [==============================] - 0s 21us/step - loss: 0.0628 - accuracy: 0.9769 - val_loss: 0.0756 - val_accuracy: 0.9795\n",
      "Epoch 433/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0672 - accuracy: 0.9756 - val_loss: 0.0793 - val_accuracy: 0.9744\n",
      "Epoch 434/2000\n",
      "780/780 [==============================] - 0s 18us/step - loss: 0.0662 - accuracy: 0.9718 - val_loss: 0.0934 - val_accuracy: 0.9538\n",
      "Epoch 435/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0676 - accuracy: 0.9718 - val_loss: 0.0769 - val_accuracy: 0.9795\n",
      "Epoch 436/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.0757 - val_accuracy: 0.9795\n",
      "Epoch 437/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 0.0805 - val_accuracy: 0.9590\n",
      "Epoch 438/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0626 - accuracy: 0.9795 - val_loss: 0.0788 - val_accuracy: 0.9641\n",
      "Epoch 439/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.0749 - val_accuracy: 0.9795\n",
      "Epoch 440/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0621 - accuracy: 0.9808 - val_loss: 0.0795 - val_accuracy: 0.9641\n",
      "Epoch 441/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0611 - accuracy: 0.9795 - val_loss: 0.0815 - val_accuracy: 0.9590\n",
      "Epoch 442/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0614 - accuracy: 0.9795 - val_loss: 0.0785 - val_accuracy: 0.9744\n",
      "Epoch 443/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.0762 - val_accuracy: 0.9795\n",
      "Epoch 444/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.0607 - accuracy: 0.9808 - val_loss: 0.0777 - val_accuracy: 0.9795\n",
      "Epoch 445/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0608 - accuracy: 0.9795 - val_loss: 0.0785 - val_accuracy: 0.9641\n",
      "Epoch 446/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0601 - accuracy: 0.9795 - val_loss: 0.0810 - val_accuracy: 0.9590\n",
      "Epoch 447/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0604 - accuracy: 0.9808 - val_loss: 0.0760 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0597 - accuracy: 0.9795 - val_loss: 0.0733 - val_accuracy: 0.9795\n",
      "Epoch 449/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0608 - accuracy: 0.9808 - val_loss: 0.0770 - val_accuracy: 0.9795\n",
      "Epoch 450/2000\n",
      "780/780 [==============================] - 0s 47us/step - loss: 0.0600 - accuracy: 0.9795 - val_loss: 0.0825 - val_accuracy: 0.9590\n",
      "Epoch 451/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0601 - accuracy: 0.9795 - val_loss: 0.0746 - val_accuracy: 0.9795\n",
      "Epoch 452/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0600 - accuracy: 0.9821 - val_loss: 0.0732 - val_accuracy: 0.9795\n",
      "Epoch 453/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0595 - accuracy: 0.9795 - val_loss: 0.0808 - val_accuracy: 0.9590\n",
      "Epoch 454/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0802 - val_accuracy: 0.9590\n",
      "Epoch 455/2000\n",
      "780/780 [==============================] - 0s 43us/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.0748 - val_accuracy: 0.9795\n",
      "Epoch 456/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.0740 - val_accuracy: 0.9795\n",
      "Epoch 457/2000\n",
      "780/780 [==============================] - 0s 18us/step - loss: 0.0586 - accuracy: 0.9846 - val_loss: 0.0770 - val_accuracy: 0.9795\n",
      "Epoch 458/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0598 - accuracy: 0.9769 - val_loss: 0.0783 - val_accuracy: 0.9641\n",
      "Epoch 459/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0575 - accuracy: 0.9808 - val_loss: 0.0719 - val_accuracy: 0.9795\n",
      "Epoch 460/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0594 - accuracy: 0.9821 - val_loss: 0.0727 - val_accuracy: 0.9795\n",
      "Epoch 461/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0579 - accuracy: 0.9821 - val_loss: 0.0782 - val_accuracy: 0.9641\n",
      "Epoch 462/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0577 - accuracy: 0.9808 - val_loss: 0.0781 - val_accuracy: 0.9641\n",
      "Epoch 463/2000\n",
      "780/780 [==============================] - 0s 22us/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.0743 - val_accuracy: 0.9795\n",
      "Epoch 464/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0571 - accuracy: 0.9833 - val_loss: 0.0762 - val_accuracy: 0.9795\n",
      "Epoch 465/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0571 - accuracy: 0.9795 - val_loss: 0.0745 - val_accuracy: 0.9795\n",
      "Epoch 466/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.0726 - val_accuracy: 0.9795\n",
      "Epoch 467/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0568 - accuracy: 0.9859 - val_loss: 0.0763 - val_accuracy: 0.9692\n",
      "Epoch 468/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0567 - accuracy: 0.9795 - val_loss: 0.0744 - val_accuracy: 0.9795\n",
      "Epoch 469/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 0.0719 - val_accuracy: 0.9795\n",
      "Epoch 470/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.0759 - val_accuracy: 0.9795\n",
      "Epoch 471/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.0773 - val_accuracy: 0.9641\n",
      "Epoch 472/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.0728 - val_accuracy: 0.9795\n",
      "Epoch 473/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.0728 - val_accuracy: 0.9795\n",
      "Epoch 474/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0573 - accuracy: 0.9859 - val_loss: 0.0737 - val_accuracy: 0.9795\n",
      "Epoch 475/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0553 - accuracy: 0.9846 - val_loss: 0.0700 - val_accuracy: 0.9795\n",
      "Epoch 476/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0566 - accuracy: 0.9833 - val_loss: 0.0717 - val_accuracy: 0.9795\n",
      "Epoch 477/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.0747 - val_accuracy: 0.9795\n",
      "Epoch 478/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0554 - accuracy: 0.9859 - val_loss: 0.0731 - val_accuracy: 0.9795\n",
      "Epoch 479/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0766 - val_accuracy: 0.9692\n",
      "Epoch 480/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0552 - accuracy: 0.9808 - val_loss: 0.0745 - val_accuracy: 0.9795\n",
      "Epoch 481/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0561 - accuracy: 0.9859 - val_loss: 0.0722 - val_accuracy: 0.9795\n",
      "Epoch 482/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0539 - accuracy: 0.9846 - val_loss: 0.0794 - val_accuracy: 0.9590\n",
      "Epoch 483/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.0766 - val_accuracy: 0.9641\n",
      "Epoch 484/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.0714 - val_accuracy: 0.9795\n",
      "Epoch 485/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0542 - accuracy: 0.9846 - val_loss: 0.0725 - val_accuracy: 0.9795\n",
      "Epoch 486/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0536 - accuracy: 0.9859 - val_loss: 0.0726 - val_accuracy: 0.9744\n",
      "Epoch 487/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0534 - accuracy: 0.9859 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "Epoch 488/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0706 - val_accuracy: 0.9795\n",
      "Epoch 489/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0540 - accuracy: 0.9846 - val_loss: 0.0714 - val_accuracy: 0.9795\n",
      "Epoch 490/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0529 - accuracy: 0.9859 - val_loss: 0.0789 - val_accuracy: 0.9641\n",
      "Epoch 491/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0540 - accuracy: 0.9821 - val_loss: 0.0752 - val_accuracy: 0.9795\n",
      "Epoch 492/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0528 - accuracy: 0.9846 - val_loss: 0.0709 - val_accuracy: 0.9795\n",
      "Epoch 493/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0527 - accuracy: 0.9859 - val_loss: 0.0721 - val_accuracy: 0.9795\n",
      "Epoch 494/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0721 - val_accuracy: 0.9795\n",
      "Epoch 495/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0524 - accuracy: 0.9846 - val_loss: 0.0697 - val_accuracy: 0.9795\n",
      "Epoch 496/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.0739 - val_accuracy: 0.9744\n",
      "Epoch 497/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 0.0729 - val_accuracy: 0.9744\n",
      "Epoch 498/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0518 - accuracy: 0.9846 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
      "Epoch 499/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 0.0729 - val_accuracy: 0.9795\n",
      "Epoch 500/2000\n",
      "780/780 [==============================] - 0s 47us/step - loss: 0.0511 - accuracy: 0.9859 - val_loss: 0.0784 - val_accuracy: 0.9641\n",
      "Epoch 501/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 0.0733 - val_accuracy: 0.9795\n",
      "Epoch 502/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.0514 - accuracy: 0.9846 - val_loss: 0.0686 - val_accuracy: 0.9846\n",
      "Epoch 503/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.0762 - val_accuracy: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9590\n",
      "Epoch 505/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0546 - accuracy: 0.9769 - val_loss: 0.0710 - val_accuracy: 0.9795\n",
      "Epoch 506/2000\n",
      "780/780 [==============================] - 0s 44us/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "Epoch 507/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0519 - accuracy: 0.9846 - val_loss: 0.0741 - val_accuracy: 0.9692\n",
      "Epoch 508/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0764 - val_accuracy: 0.9641\n",
      "Epoch 509/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0503 - accuracy: 0.9885 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
      "Epoch 510/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0517 - accuracy: 0.9859 - val_loss: 0.0709 - val_accuracy: 0.9744\n",
      "Epoch 511/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0491 - accuracy: 0.9872 - val_loss: 0.0795 - val_accuracy: 0.9641\n",
      "Epoch 512/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0518 - accuracy: 0.9808 - val_loss: 0.0745 - val_accuracy: 0.9744\n",
      "Epoch 513/2000\n",
      "780/780 [==============================] - 0s 36us/step - loss: 0.0503 - accuracy: 0.9872 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "Epoch 514/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0509 - accuracy: 0.9872 - val_loss: 0.0715 - val_accuracy: 0.9744\n",
      "Epoch 515/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0501 - accuracy: 0.9872 - val_loss: 0.0717 - val_accuracy: 0.9744\n",
      "Epoch 516/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0489 - accuracy: 0.9872 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
      "Epoch 517/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0507 - accuracy: 0.9859 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
      "Epoch 518/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0498 - accuracy: 0.9872 - val_loss: 0.0773 - val_accuracy: 0.9692\n",
      "Epoch 519/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
      "Epoch 520/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0485 - accuracy: 0.9872 - val_loss: 0.0708 - val_accuracy: 0.9846\n",
      "Epoch 521/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0482 - accuracy: 0.9885 - val_loss: 0.0731 - val_accuracy: 0.9744\n",
      "Epoch 522/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0499 - accuracy: 0.9846 - val_loss: 0.0709 - val_accuracy: 0.9846\n",
      "Epoch 523/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0474 - accuracy: 0.9885 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "Epoch 524/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
      "Epoch 525/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.0800 - val_accuracy: 0.9641\n",
      "Epoch 526/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "Epoch 527/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
      "Epoch 528/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.0819 - val_accuracy: 0.9641\n",
      "Epoch 529/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0514 - accuracy: 0.9821 - val_loss: 0.0741 - val_accuracy: 0.9795\n",
      "Epoch 530/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
      "Epoch 531/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "Epoch 532/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 0.0791 - val_accuracy: 0.9641\n",
      "Epoch 533/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0493 - accuracy: 0.9821 - val_loss: 0.0714 - val_accuracy: 0.9846\n",
      "Epoch 534/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "Epoch 535/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0470 - accuracy: 0.9859 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
      "Epoch 536/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
      "Epoch 537/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "Epoch 538/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0458 - accuracy: 0.9872 - val_loss: 0.0728 - val_accuracy: 0.9795\n",
      "Epoch 539/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.0693 - val_accuracy: 0.9846\n",
      "Epoch 540/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0463 - accuracy: 0.9859 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "Epoch 541/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0457 - accuracy: 0.9872 - val_loss: 0.0709 - val_accuracy: 0.9846\n",
      "Epoch 542/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0457 - accuracy: 0.9872 - val_loss: 0.0695 - val_accuracy: 0.9846\n",
      "Epoch 543/2000\n",
      "780/780 [==============================] - 0s 30us/step - loss: 0.0456 - accuracy: 0.9872 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "Epoch 544/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0454 - accuracy: 0.9872 - val_loss: 0.0697 - val_accuracy: 0.9846\n",
      "Epoch 545/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.0724 - val_accuracy: 0.9795\n",
      "Epoch 546/2000\n",
      "780/780 [==============================] - 0s 18us/step - loss: 0.0454 - accuracy: 0.9872 - val_loss: 0.0691 - val_accuracy: 0.9846\n",
      "Epoch 547/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0458 - accuracy: 0.9872 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "Epoch 548/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 0.0728 - val_accuracy: 0.9846\n",
      "Epoch 549/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 0.0686 - val_accuracy: 0.9846\n",
      "Epoch 550/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 0.0674 - val_accuracy: 0.9846\n",
      "Epoch 551/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0440 - accuracy: 0.9885 - val_loss: 0.0725 - val_accuracy: 0.9795\n",
      "Epoch 552/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.0700 - val_accuracy: 0.9846\n",
      "Epoch 553/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "Epoch 554/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "Epoch 555/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0449 - accuracy: 0.9885 - val_loss: 0.0726 - val_accuracy: 0.9795\n",
      "Epoch 556/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.0671 - val_accuracy: 0.9846\n",
      "Epoch 557/2000\n",
      "780/780 [==============================] - 0s 42us/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
      "Epoch 558/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.0722 - val_accuracy: 0.9795\n",
      "Epoch 559/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.0688 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0434 - accuracy: 0.9872 - val_loss: 0.0666 - val_accuracy: 0.9846\n",
      "Epoch 561/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.0699 - val_accuracy: 0.9846\n",
      "Epoch 562/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 0.0676 - val_accuracy: 0.9846\n",
      "Epoch 563/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0426 - accuracy: 0.9885 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "Epoch 564/2000\n",
      "780/780 [==============================] - 0s 42us/step - loss: 0.0425 - accuracy: 0.9885 - val_loss: 0.0685 - val_accuracy: 0.9846\n",
      "Epoch 565/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "Epoch 566/2000\n",
      "780/780 [==============================] - 0s 22us/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "Epoch 567/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0697 - val_accuracy: 0.9846\n",
      "Epoch 568/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
      "Epoch 569/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.0702 - val_accuracy: 0.9846\n",
      "Epoch 570/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0419 - accuracy: 0.9872 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "Epoch 571/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "Epoch 572/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
      "Epoch 573/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.0686 - val_accuracy: 0.9846\n",
      "Epoch 574/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0411 - accuracy: 0.9872 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
      "Epoch 575/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0421 - accuracy: 0.9859 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
      "Epoch 576/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0699 - val_accuracy: 0.9795\n",
      "Epoch 577/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0409 - accuracy: 0.9885 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "Epoch 578/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0412 - accuracy: 0.9885 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "Epoch 579/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0425 - accuracy: 0.9885 - val_loss: 0.0702 - val_accuracy: 0.9795\n",
      "Epoch 580/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "Epoch 581/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 0.0667 - val_accuracy: 0.9846\n",
      "Epoch 582/2000\n",
      "780/780 [==============================] - 0s 20us/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "Epoch 583/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "Epoch 584/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "Epoch 585/2000\n",
      "780/780 [==============================] - 0s 47us/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 0.0673 - val_accuracy: 0.9846\n",
      "Epoch 586/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "Epoch 587/2000\n",
      "780/780 [==============================] - 0s 33us/step - loss: 0.0396 - accuracy: 0.9885 - val_loss: 0.0696 - val_accuracy: 0.9846\n",
      "Epoch 588/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0396 - accuracy: 0.9885 - val_loss: 0.0669 - val_accuracy: 0.9846\n",
      "Epoch 589/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0394 - accuracy: 0.9885 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "Epoch 590/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "Epoch 591/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.0713 - val_accuracy: 0.9795\n",
      "Epoch 592/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
      "Epoch 593/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "Epoch 594/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.0685 - val_accuracy: 0.9846\n",
      "Epoch 595/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0678 - val_accuracy: 0.9846\n",
      "Epoch 596/2000\n",
      "780/780 [==============================] - 0s 19us/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "Epoch 597/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0695 - val_accuracy: 0.9846\n",
      "Epoch 598/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0383 - accuracy: 0.9885 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
      "Epoch 599/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0388 - accuracy: 0.9859 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "Epoch 600/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.0670 - val_accuracy: 0.9846\n",
      "Epoch 601/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
      "Epoch 602/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0684 - val_accuracy: 0.9795\n",
      "Epoch 603/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.0380 - accuracy: 0.9885 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "Epoch 604/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
      "Epoch 605/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.0662 - val_accuracy: 0.9846\n",
      "Epoch 606/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0680 - val_accuracy: 0.9795\n",
      "Epoch 607/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0646 - val_accuracy: 0.9846\n",
      "Epoch 608/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
      "Epoch 609/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 0.0740 - val_accuracy: 0.9744\n",
      "Epoch 610/2000\n",
      "780/780 [==============================] - 0s 42us/step - loss: 0.0390 - accuracy: 0.9885 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
      "Epoch 611/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0633 - val_accuracy: 0.9846\n",
      "Epoch 612/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
      "Epoch 613/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0389 - accuracy: 0.9885 - val_loss: 0.0715 - val_accuracy: 0.9795\n",
      "Epoch 614/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0629 - val_accuracy: 0.9846\n",
      "Epoch 615/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.0673 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.0733 - val_accuracy: 0.9744\n",
      "Epoch 617/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "Epoch 618/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
      "Epoch 619/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0367 - accuracy: 0.9872 - val_loss: 0.0685 - val_accuracy: 0.9795\n",
      "Epoch 620/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0693 - val_accuracy: 0.9795\n",
      "Epoch 621/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0639 - val_accuracy: 0.9846\n",
      "Epoch 622/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0372 - accuracy: 0.9872 - val_loss: 0.0639 - val_accuracy: 0.9846\n",
      "Epoch 623/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.0718 - val_accuracy: 0.9795\n",
      "Epoch 624/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
      "Epoch 625/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.0622 - val_accuracy: 0.9846\n",
      "Epoch 626/2000\n",
      "780/780 [==============================] - 0s 28us/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 0.0709 - val_accuracy: 0.9795\n",
      "Epoch 627/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "Epoch 628/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.0622 - val_accuracy: 0.9846\n",
      "Epoch 629/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0380 - accuracy: 0.9885 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
      "Epoch 630/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0347 - accuracy: 0.9910 - val_loss: 0.0713 - val_accuracy: 0.9795\n",
      "Epoch 631/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0364 - accuracy: 0.9859 - val_loss: 0.0692 - val_accuracy: 0.9795\n",
      "Epoch 632/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0625 - val_accuracy: 0.9846\n",
      "Epoch 633/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.0645 - val_accuracy: 0.9846\n",
      "Epoch 634/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0704 - val_accuracy: 0.9795\n",
      "Epoch 635/2000\n",
      "780/780 [==============================] - 0s 19us/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 0.0643 - val_accuracy: 0.9846\n",
      "Epoch 636/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0357 - accuracy: 0.9910 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
      "Epoch 637/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0350 - accuracy: 0.9910 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
      "Epoch 638/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0357 - accuracy: 0.9897 - val_loss: 0.0642 - val_accuracy: 0.9846\n",
      "Epoch 639/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 0.0666 - val_accuracy: 0.9846\n",
      "Epoch 640/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 0.0733 - val_accuracy: 0.9744\n",
      "Epoch 641/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.0640 - val_accuracy: 0.9846\n",
      "Epoch 642/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0345 - accuracy: 0.9910 - val_loss: 0.0617 - val_accuracy: 0.9846\n",
      "Epoch 643/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "Epoch 644/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "Epoch 645/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0341 - accuracy: 0.9910 - val_loss: 0.0613 - val_accuracy: 0.9846\n",
      "Epoch 646/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0342 - accuracy: 0.9897 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
      "Epoch 647/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "Epoch 648/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.0627 - val_accuracy: 0.9846\n",
      "Epoch 649/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0335 - accuracy: 0.9910 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "Epoch 650/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0704 - val_accuracy: 0.9744\n",
      "Epoch 651/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
      "Epoch 652/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.0628 - val_accuracy: 0.9846\n",
      "Epoch 653/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0637 - val_accuracy: 0.9846\n",
      "Epoch 654/2000\n",
      "780/780 [==============================] - 0s 50us/step - loss: 0.0325 - accuracy: 0.9910 - val_loss: 0.0676 - val_accuracy: 0.9795\n",
      "Epoch 655/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0630 - val_accuracy: 0.9846\n",
      "Epoch 656/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0324 - accuracy: 0.9910 - val_loss: 0.0611 - val_accuracy: 0.9846\n",
      "Epoch 657/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "Epoch 658/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0324 - accuracy: 0.9910 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "Epoch 659/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0327 - accuracy: 0.9910 - val_loss: 0.0617 - val_accuracy: 0.9846\n",
      "Epoch 660/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0645 - val_accuracy: 0.9846\n",
      "Epoch 661/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.0636 - val_accuracy: 0.9846\n",
      "Epoch 662/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.0595 - val_accuracy: 0.9846\n",
      "Epoch 663/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0329 - accuracy: 0.9923 - val_loss: 0.0633 - val_accuracy: 0.9846\n",
      "Epoch 664/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.0647 - val_accuracy: 0.9846\n",
      "Epoch 665/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0317 - accuracy: 0.9923 - val_loss: 0.0608 - val_accuracy: 0.9846\n",
      "Epoch 666/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0625 - val_accuracy: 0.9846\n",
      "Epoch 667/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0308 - accuracy: 0.9936 - val_loss: 0.0667 - val_accuracy: 0.9846\n",
      "Epoch 668/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0586 - val_accuracy: 0.9846\n",
      "Epoch 669/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 670/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.0597 - val_accuracy: 0.9846\n",
      "Epoch 671/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.0577 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/2000\n",
      "780/780 [==============================] - 0s 35us/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 673/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.0604 - val_accuracy: 0.9846\n",
      "Epoch 674/2000\n",
      "780/780 [==============================] - 0s 23us/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
      "Epoch 675/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0577 - val_accuracy: 0.9846\n",
      "Epoch 676/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
      "Epoch 677/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
      "Epoch 678/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.0640 - val_accuracy: 0.9846\n",
      "Epoch 679/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0680 - val_accuracy: 0.9795\n",
      "Epoch 680/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0557 - val_accuracy: 0.9795\n",
      "Epoch 681/2000\n",
      "780/780 [==============================] - 0s 20us/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 0.0627 - val_accuracy: 0.9795\n",
      "Epoch 682/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.0603 - val_accuracy: 0.9795\n",
      "Epoch 683/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0531 - val_accuracy: 0.9795\n",
      "Epoch 684/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.0561 - val_accuracy: 0.9846\n",
      "Epoch 685/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0593 - val_accuracy: 0.9795\n",
      "Epoch 686/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
      "Epoch 687/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0576 - val_accuracy: 0.9846\n",
      "Epoch 688/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
      "Epoch 689/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
      "Epoch 690/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.0593 - val_accuracy: 0.9846\n",
      "Epoch 691/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0591 - val_accuracy: 0.9846\n",
      "Epoch 692/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
      "Epoch 693/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 694/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
      "Epoch 695/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
      "Epoch 696/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
      "Epoch 697/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
      "Epoch 698/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0582 - val_accuracy: 0.9846\n",
      "Epoch 699/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0570 - val_accuracy: 0.9795\n",
      "Epoch 700/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0248 - accuracy: 0.9897 - val_loss: 0.0597 - val_accuracy: 0.9846\n",
      "Epoch 701/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
      "Epoch 702/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0233 - accuracy: 0.9910 - val_loss: 0.0617 - val_accuracy: 0.9846\n",
      "Epoch 703/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "Epoch 704/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
      "Epoch 705/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0608 - val_accuracy: 0.9795\n",
      "Epoch 706/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0231 - accuracy: 0.9910 - val_loss: 0.0626 - val_accuracy: 0.9846\n",
      "Epoch 707/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
      "Epoch 708/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0251 - accuracy: 0.9897 - val_loss: 0.0652 - val_accuracy: 0.9846\n",
      "Epoch 709/2000\n",
      "780/780 [==============================] - 0s 36us/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "Epoch 710/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0614 - val_accuracy: 0.9795\n",
      "Epoch 711/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
      "Epoch 712/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "Epoch 713/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0619 - val_accuracy: 0.9795\n",
      "Epoch 714/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "Epoch 715/2000\n",
      "780/780 [==============================] - 0s 40us/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0627 - val_accuracy: 0.9795\n",
      "Epoch 716/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "Epoch 717/2000\n",
      "780/780 [==============================] - 0s 26us/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
      "Epoch 718/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.0624 - val_accuracy: 0.9795\n",
      "Epoch 719/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
      "Epoch 720/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "Epoch 721/2000\n",
      "780/780 [==============================] - 0s 41us/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "Epoch 722/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0245 - accuracy: 0.9949 - val_loss: 0.0704 - val_accuracy: 0.9846\n",
      "Epoch 723/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "Epoch 724/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0633 - val_accuracy: 0.9795\n",
      "Epoch 725/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.0718 - val_accuracy: 0.9846\n",
      "Epoch 726/2000\n",
      "780/780 [==============================] - 0s 8us/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "Epoch 727/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0633 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
      "Epoch 729/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
      "Epoch 730/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.0625 - val_accuracy: 0.9795\n",
      "Epoch 731/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0681 - val_accuracy: 0.9846\n",
      "Epoch 732/2000\n",
      "780/780 [==============================] - 0s 32us/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0656 - val_accuracy: 0.9846\n",
      "Epoch 733/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0205 - accuracy: 0.9974 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
      "Epoch 734/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "Epoch 735/2000\n",
      "780/780 [==============================] - 0s 14us/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 736/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0648 - val_accuracy: 0.9846\n",
      "Epoch 737/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "Epoch 738/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "Epoch 739/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0636 - val_accuracy: 0.9795\n",
      "Epoch 740/2000\n",
      "780/780 [==============================] - 0s 29us/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
      "Epoch 741/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0700 - val_accuracy: 0.9795\n",
      "Epoch 742/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0219 - accuracy: 0.9949 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 743/2000\n",
      "780/780 [==============================] - 0s 17us/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0710 - val_accuracy: 0.9846\n",
      "Epoch 744/2000\n",
      "780/780 [==============================] - 0s 38us/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0678 - val_accuracy: 0.9846\n",
      "Epoch 745/2000\n",
      "780/780 [==============================] - 0s 37us/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 746/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
      "Epoch 747/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0718 - val_accuracy: 0.9795\n",
      "Epoch 748/2000\n",
      "780/780 [==============================] - 0s 21us/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "Epoch 749/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "Epoch 750/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0664 - val_accuracy: 0.9846\n",
      "Epoch 751/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0650 - val_accuracy: 0.9846\n",
      "Epoch 752/2000\n",
      "780/780 [==============================] - 0s 44us/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
      "Epoch 753/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0689 - val_accuracy: 0.9846\n",
      "Epoch 754/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
      "Epoch 755/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0653 - val_accuracy: 0.9795\n",
      "Epoch 756/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
      "Epoch 757/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0702 - val_accuracy: 0.9795\n",
      "Epoch 758/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0655 - val_accuracy: 0.9795\n",
      "Epoch 759/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0185 - accuracy: 0.9974 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "Epoch 760/2000\n",
      "780/780 [==============================] - 0s 31us/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0675 - val_accuracy: 0.9846\n",
      "Epoch 761/2000\n",
      "780/780 [==============================] - 0s 12us/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.0660 - val_accuracy: 0.9795\n",
      "Epoch 762/2000\n",
      "780/780 [==============================] - 0s 15us/step - loss: 0.0184 - accuracy: 0.9974 - val_loss: 0.0700 - val_accuracy: 0.9846\n",
      "Epoch 763/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.0717 - val_accuracy: 0.9795\n",
      "Epoch 764/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0699 - val_accuracy: 0.9846\n",
      "Epoch 765/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.0666 - val_accuracy: 0.9795\n",
      "Epoch 766/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.0677 - val_accuracy: 0.9846\n",
      "Epoch 767/2000\n",
      "780/780 [==============================] - 0s 13us/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0691 - val_accuracy: 0.9846\n",
      "Epoch 768/2000\n",
      "780/780 [==============================] - 0s 27us/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0682 - val_accuracy: 0.9846\n",
      "Epoch 769/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0661 - val_accuracy: 0.9795\n",
      "Epoch 770/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0738 - val_accuracy: 0.9795\n",
      "Epoch 771/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0661 - val_accuracy: 0.9795\n",
      "Epoch 772/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0662 - val_accuracy: 0.9795\n",
      "Epoch 773/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.0756 - val_accuracy: 0.9795\n",
      "Epoch 774/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0680 - val_accuracy: 0.9795\n",
      "Epoch 775/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.0668 - val_accuracy: 0.9795\n",
      "Epoch 776/2000\n",
      "780/780 [==============================] - 0s 11us/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.0753 - val_accuracy: 0.9795\n",
      "Epoch 777/2000\n",
      "780/780 [==============================] - 0s 24us/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0664 - val_accuracy: 0.9795\n",
      "Epoch 778/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0688 - val_accuracy: 0.9846\n",
      "Epoch 779/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0812 - val_accuracy: 0.9795\n",
      "Epoch 780/2000\n",
      "780/780 [==============================] - 0s 9us/step - loss: 0.0233 - accuracy: 0.9910 - val_loss: 0.0660 - val_accuracy: 0.9795\n",
      "Epoch 781/2000\n",
      "780/780 [==============================] - 0s 10us/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "Epoch 782/2000\n",
      "780/780 [==============================] - 0s 46us/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.0739 - val_accuracy: 0.9795\n",
      "Epoch 783/2000\n",
      "780/780 [==============================] - 0s 33us/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0668 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 [==============================] - 0s 22us/step\n",
      "\n",
      " Accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)  # seed 값 설정\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "df_pre = pd.read_csv(goal_path/'wine.csv', header=None)\n",
    "df = df_pre.sample(frac=0.15)  #rac = 1 지정은 원본 데이터의 100%를 불러오라는 의미\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]\n",
    "\n",
    "model = Sequential() # 모델 설정(4개의 은닉층을 만들어 각각 30, 12, 8, 1개의 노드를 주었습니다)\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',   optimizer='adam',    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "#테스트 오차는 케라스 내부에서 val_loss, 학습 정확도는 acc, 테스트셋 정확도는 val_acc, 학습셋 오차는 loss로 각각 기록됩니다\n",
    "# 모델 저장 조건 설정\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 자동 중단 설정(EarlyStopping() 함수에 모니터할 값과 테스트 오차가 좋아지지 않아도 몇 번까지 기다릴지를 정합니다.)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(X, Y, validation_split=0.2, epochs=2000, batch_size=500, callbacks=[early_stopping_callback])\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6306d37957a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_acc' is not defined"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
